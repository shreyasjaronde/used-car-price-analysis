{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2ce608f-80f3-47ae-94f6-cae2b4c1224f",
   "metadata": {},
   "source": [
    "1st stage of getting scrap dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d14f61-148c-4352-bd22-8e4957ccf01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected total_listings=600, per_page_guess=64, total_pages=10\n",
      "Scanned page 10; collected rows so far: 517\n",
      "Collected 517 card-level rows, discovered 504 detail links.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_7052\\918957214.py:316: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_7052\\918957214.py:332: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 detail pages...\n",
      "Processed 200 detail pages...\n",
      "Processed 300 detail pages...\n",
      "Processed 400 detail pages...\n",
      "Processed 500 detail pages...\n",
      "Done. Collected 505 rows. Saved to cardekho_used_cars_nagpur_with_mileage.csv and cardekho_used_cars_nagpur_with_mileage.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "cardekho_used_nagpur_scraper_with_mileage.py\n",
    "\n",
    "Scrapes https://www.cardekho.com/used-cars+in+nagpur and writes CSV + Excel.\n",
    "Extracted columns:\n",
    "Car_name, brand, model, kms_driven, mileage, transmission, fuel_type, year_of_manufacture, price, detail_page\n",
    "\n",
    "Requires: selenium, beautifulsoup4, pandas, openpyxl, webdriver-manager\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# -------- CONFIG ----------\n",
    "# START_URL = \"https://www.cardekho.com/used-cars+in+hyderabad\"\n",
    "START_URL = \"https://www.cardekho.com/used-cars+in+nagpur\"   # URL for nagpur\n",
    "OUTPUT_CSV = \"cardekho_used_cars_nagpur_with_mileage.csv\"\n",
    "OUTPUT_XLSX = \"cardekho_used_cars_nagpur_with_mileage.xlsx\"\n",
    "\n",
    "HEADLESS = True                 # Set False to watch browser\n",
    "MAX_PAGES_OVERRIDE = None       # Set to int to force how many result pages to scan; None -> auto-detect\n",
    "MAX_SCROLLS = 40                # scroll rounds per search-result page\n",
    "SCROLL_PAUSE = 0.7\n",
    "PAGE_PAUSE = (0.6, 1.4)\n",
    "VISIT_DETAIL_PAGES = True       # True -> open each listing detail page for mileage/transmission accuracy\n",
    "DETAIL_PAUSE = (0.6, 1.2)\n",
    "MAX_DETAIL_RETRIES = 1         # retry detail page once on failure\n",
    "# Brands to help split brand/model\n",
    "BRANDS = [\n",
    "    \"Maruti\", \"Hyundai\", \"Tata\", \"Honda\", \"Toyota\", \"Mahindra\", \"Kia\",\n",
    "    \"BMW\", \"Audi\", \"Mercedes-Benz\", \"Mercedes\", \"Renault\", \"MG\", \"Skoda\",\n",
    "    \"Volkswagen\", \"Ford\", \"Nissan\", \"Jeep\", \"Volvo\", \"Land Rover\", \"Jaguar\",\n",
    "    \"Isuzu\", \"Datsun\", \"Chevrolet\", \"Opel\"\n",
    "]\n",
    "# --------------------------\n",
    "\n",
    "# Helper parsers\n",
    "def guess_brand_and_model(name):\n",
    "    if not name:\n",
    "        return \"\", \"\"\n",
    "    for b in BRANDS:\n",
    "        if b.lower() in name.lower():\n",
    "            model = re.sub(re.escape(b), \"\", name, flags=re.IGNORECASE).strip()\n",
    "            model = re.sub(r'^[\\-\\:\\–\\—\\s]+', '', model)\n",
    "            return b, model or name\n",
    "    parts = name.split()\n",
    "    return (parts[0], \" \".join(parts[1:]) if len(parts) > 1 else \"\") if parts else (\"\",\"\")\n",
    "\n",
    "def extract_kms(text):\n",
    "    m = re.search(r'([\\d,\\.]+)\\s*(?:kms|km)\\b', text, flags=re.I)\n",
    "    if m:\n",
    "        return m.group(1).replace(\",\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "def extract_fuel(text):\n",
    "    for f in [\"Petrol\", \"Diesel\", \"CNG\", \"LPG\", \"Electric\", \"Hybrid\"]:\n",
    "        if re.search(r'\\b' + re.escape(f) + r'\\b', text, flags=re.I):\n",
    "            return f\n",
    "    return \"\"\n",
    "\n",
    "def extract_price(text):\n",
    "    m = re.search(r'₹\\s*[\\d\\.,\\sA-Za-z]+', text)\n",
    "    if m:\n",
    "        return m.group(0).strip()\n",
    "    m2 = re.search(r'[\\d\\.,]+\\s*(Lakh|lakh|Lakhs|lakhs|Crore|crore|Cr)\\b', text)\n",
    "    if m2:\n",
    "        return m2.group(0)\n",
    "    return \"\"\n",
    "\n",
    "def extract_year(text):\n",
    "    m = re.search(r'\\b(19|20)\\d{2}\\b', text)\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    "# mileage pattern examples:\n",
    "# 18.5 kmpl, 22 km/kg, 120 km/kWh, 18 kmpl (ARAI), 25.6 kmpl\n",
    "MILEAGE_REGEXES = [\n",
    "    re.compile(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|km/kg|km/kwh|km/l|kmperlitre|km/gal|km/100km|kml|kpl)\\b', flags=re.I),\n",
    "    re.compile(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(km(?:/kwh|/kg|pl)?)\\b', flags=re.I),\n",
    "    re.compile(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(mpg|mpg\\;)', flags=re.I)\n",
    "]\n",
    "\n",
    "def extract_mileage(text):\n",
    "    txt = text.replace(\"\\xa0\",\" \").strip()\n",
    "    for rx in MILEAGE_REGEXES:\n",
    "        m = rx.search(txt)\n",
    "        if m:\n",
    "            val = m.group(1)\n",
    "            unit = m.group(2)\n",
    "            return f\"{val} {unit}\".strip()\n",
    "    # sometimes written like \"Mileage: 18.5 kmpl\" or \"18.5kmpl\"\n",
    "    m2 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|km/kg|km/kwh|km|kpl|km/l)\\b', txt, flags=re.I)\n",
    "    if m2:\n",
    "        return f\"{m2.group(1)} {m2.group(2)}\"\n",
    "    return \"\"\n",
    "\n",
    "# transmission extraction\n",
    "def extract_transmission(text):\n",
    "    for t in [\"Manual\", \"Automatic\", \"CVT\", \"AMT\", \"DCT\", \"AT\", \"MT\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', text, flags=re.I):\n",
    "            # normalize common variants\n",
    "            if t.upper() in (\"AT\",\"AMT\",\"CVT\",\"DCT\",\"MT\"):\n",
    "                return t.upper()\n",
    "            return t.title()\n",
    "    return \"\"\n",
    "\n",
    "# safe text extractor for BeautifulSoup element\n",
    "def text_of(elem):\n",
    "    return elem.get_text(\" \", strip=True) if elem else \"\"\n",
    "\n",
    "# ---------- main ----------\n",
    "def main():\n",
    "    # Setup Selenium Chrome\n",
    "    chrome_opts = Options()\n",
    "    if HEADLESS:\n",
    "        chrome_opts.add_argument(\"--headless=new\")\n",
    "    chrome_opts.add_argument(\"--no-sandbox\")\n",
    "    chrome_opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_opts.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_opts.add_argument(\"--disable-gpu\")\n",
    "    chrome_opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_opts)\n",
    "\n",
    "    try:\n",
    "        # load first page and detect pages count\n",
    "        driver.get(START_URL)\n",
    "        time.sleep(2.0)\n",
    "        soup0 = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        page_text = soup0.get_text(\" \", strip=True)\n",
    "\n",
    "        total_listings = None\n",
    "        m = re.search(r'([\\d,]{2,})\\s+Second Hand Cars in Nagpur', page_text, flags=re.I)\n",
    "        if not m:\n",
    "            m = re.search(r'of\\s+([\\d,]+)\\s+results', page_text, flags=re.I)\n",
    "        if m:\n",
    "            total_listings = int(m.group(1).replace(\",\", \"\"))\n",
    "\n",
    "        per_page_guess = max(1, len(soup0.find_all(\"h3\")))\n",
    "        estimated_pages = math.ceil(total_listings / per_page_guess) if total_listings else None\n",
    "        total_pages = int(estimated_pages) if estimated_pages else 200\n",
    "        if MAX_PAGES_OVERRIDE:\n",
    "            total_pages = MAX_PAGES_OVERRIDE\n",
    "\n",
    "        print(f\"Detected total_listings={total_listings}, per_page_guess={per_page_guess}, total_pages={total_pages}\")\n",
    "\n",
    "        rows = []\n",
    "        seen_keys = set()\n",
    "        detail_links = []\n",
    "\n",
    "        # iterate search result pages\n",
    "        for p in range(1, total_pages + 1):\n",
    "            page_url = START_URL.rstrip(\"/\") + \"?page=\" + str(p)\n",
    "            try:\n",
    "                driver.get(page_url)\n",
    "            except Exception:\n",
    "                time.sleep(1.0)\n",
    "                driver.get(page_url)\n",
    "\n",
    "            # aggressively scroll to let lazy content load\n",
    "            last_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            scroll_count = 0\n",
    "            while scroll_count < MAX_SCROLLS:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(SCROLL_PAUSE)\n",
    "                new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_h == last_h:\n",
    "                    # wiggle\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight-400);\")\n",
    "                    time.sleep(0.4)\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    time.sleep(0.4)\n",
    "                    new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                    if new_h == last_h:\n",
    "                        break\n",
    "                last_h = new_h\n",
    "                scroll_count += 1\n",
    "\n",
    "            page_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "            # find title nodes (h3) and extract card container text\n",
    "            titles = page_soup.find_all(\"h3\")\n",
    "            for h in titles:\n",
    "                title = text_of(h)\n",
    "                if not title:\n",
    "                    continue\n",
    "\n",
    "                # climb up to find a container with price or kms present\n",
    "                container = h\n",
    "                card_text = \"\"\n",
    "                link = \"\"\n",
    "                for _ in range(6):\n",
    "                    if container is None:\n",
    "                        break\n",
    "                    card_text = text_of(container)\n",
    "                    if \"₹\" in card_text or re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I):\n",
    "                        # find anchor inside container for detail link if present\n",
    "                        a = container.find(\"a\", href=True)\n",
    "                        if a:\n",
    "                            href = a[\"href\"]\n",
    "                            link = href if \"cardekho.com\" in href else urljoin(page_url, href)\n",
    "                            link = link.split(\"#\")[0].split(\"?utm\")[0]\n",
    "                        break\n",
    "                    container = container.parent\n",
    "\n",
    "                if not card_text:\n",
    "                    # fallback to grabbing parent text\n",
    "                    parent = h.parent\n",
    "                    card_text = text_of(parent) if parent else title\n",
    "\n",
    "                # check minimal heuristics: price or kms exist\n",
    "                if (\"₹\" not in card_text) and (re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I) is None):\n",
    "                    continue\n",
    "\n",
    "                # dedupe by title+price\n",
    "                price_snip = extract_price(card_text)\n",
    "                key = (title + \"||\" + price_snip).strip()\n",
    "                if key in seen_keys:\n",
    "                    continue\n",
    "                seen_keys.add(key)\n",
    "\n",
    "                kms = extract_kms(card_text)\n",
    "                fuel = extract_fuel(card_text)\n",
    "                year = extract_year(title) or extract_year(card_text)\n",
    "                brand, model = guess_brand_and_model(title)\n",
    "                price = price_snip\n",
    "\n",
    "                # prepare base row (mileage/transmission may be blank now; fill from detail page if VISIT_DETAIL_PAGES)\n",
    "                rows.append({\n",
    "                    \"Car_name\": title,\n",
    "                    \"brand\": brand,\n",
    "                    \"model\": model,\n",
    "                    \"kms_driven\": kms,\n",
    "                    \"mileage\": \"\",             # to fill\n",
    "                    \"transmission\": \"\",       # to fill\n",
    "                    \"fuel_type\": fuel,\n",
    "                    \"year_of_manufacture\": year,\n",
    "                    \"price\": price,\n",
    "                    \"detail_page\": link\n",
    "                })\n",
    "\n",
    "                if link:\n",
    "                    detail_links.append(link)\n",
    "\n",
    "            # jitter between pages\n",
    "            time.sleep(random.uniform(*PAGE_PAUSE))\n",
    "\n",
    "            # early stop if found >= total_listings\n",
    "            if total_listings and len(seen_keys) >= total_listings:\n",
    "                print(\"Reached detected total listings; stopping page scan.\")\n",
    "                break\n",
    "\n",
    "            # small progress print\n",
    "            if p % 10 == 0:\n",
    "                print(f\"Scanned page {p}; collected rows so far: {len(rows)}\")\n",
    "\n",
    "        print(f\"Collected {len(rows)} card-level rows, discovered {len(set(detail_links))} detail links.\")\n",
    "\n",
    "        # Optionally visit detail pages for mileage + transmission (more accurate)\n",
    "        if VISIT_DETAIL_PAGES and detail_links:\n",
    "            unique_detail_links = []\n",
    "            seen_dl = set()\n",
    "            for u in detail_links:\n",
    "                if u and u not in seen_dl:\n",
    "                    seen_dl.add(u)\n",
    "                    unique_detail_links.append(u)\n",
    "\n",
    "            # map detail_link -> parsed fields\n",
    "            detail_map = {}\n",
    "\n",
    "            for i, dl in enumerate(unique_detail_links):\n",
    "                # small polite wait\n",
    "                if i > 0:\n",
    "                    time.sleep(random.uniform(*DETAIL_PAUSE))\n",
    "\n",
    "                # retry loop\n",
    "                attempt = 0\n",
    "                success = False\n",
    "                while attempt <= MAX_DETAIL_RETRIES and not success:\n",
    "                    try:\n",
    "                        driver.get(dl)\n",
    "                        time.sleep(1.0 + random.random()*0.8)  # allow JS\n",
    "                        dsoup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                        page_text = dsoup.get_text(\" \", strip=True)\n",
    "\n",
    "                        # Try structured lookups:\n",
    "                        # 1) meta-line near the H1/H2 (often contains \"kms • Petrol • 2019 • 18.5 kmpl • Automatic\")\n",
    "                        h_tag = dsoup.find([\"h1\",\"h2\"])\n",
    "                        meta_line = \"\"\n",
    "                        if h_tag:\n",
    "                            nxt = h_tag.find_next()\n",
    "                            checks = 0\n",
    "                            while nxt and checks < 8:\n",
    "                                t = text_of(nxt)\n",
    "                                if t and ((\"kms\" in t.lower()) or (\"₹\" in t) or re.search(r'\\b\\d+\\s*(?:kmpl|km/kg|km/kwh|km/l|kpl)\\b', t, flags=re.I)):\n",
    "                                    meta_line = t\n",
    "                                    break\n",
    "                                nxt = nxt.find_next()\n",
    "                                checks += 1\n",
    "\n",
    "                        # 2) labeled field lookup: look for text nodes like 'Mileage' or 'Transmission' and read siblings\n",
    "                        # Mileage\n",
    "                        mileage_val = \"\"\n",
    "                        # find text nodes \"Mileage\" or \"Avg. Mileage\" etc.\n",
    "                        mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
    "                        if mnode:\n",
    "                            try:\n",
    "                                # sibling / next element may contain value\n",
    "                                parent = mnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    mileage_val = text_of(sib)\n",
    "                            except:\n",
    "                                mileage_val = \"\"\n",
    "                        if not mileage_val:\n",
    "                            # try meta_line and page_text\n",
    "                            mileage_val = extract_mileage(meta_line or page_text) or extract_mileage(page_text)\n",
    "\n",
    "                        # Transmission\n",
    "                        trans_val = \"\"\n",
    "                        tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n",
    "                        if tnode:\n",
    "                            try:\n",
    "                                parent = tnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    trans_val = text_of(sib)\n",
    "                            except:\n",
    "                                trans_val = \"\"\n",
    "                        if not trans_val:\n",
    "                            trans_val = extract_transmission(meta_line or page_text)\n",
    "\n",
    "                        # Normalize/massage values\n",
    "                        mileage_clean = extract_mileage(mileage_val or \"\")\n",
    "                        transmission_clean = extract_transmission(trans_val or \"\")\n",
    "\n",
    "                        # fallback: sometimes card-level has mileage like '18 kmpl' in small text — try to extract from page text\n",
    "                        if not mileage_clean:\n",
    "                            mileage_clean = extract_mileage(page_text)\n",
    "\n",
    "                        # store\n",
    "                        detail_map[dl] = {\n",
    "                            \"mileage\": mileage_clean,\n",
    "                            \"transmission\": transmission_clean\n",
    "                        }\n",
    "                        success = True\n",
    "                    except Exception as e:\n",
    "                        attempt += 1\n",
    "                        if attempt > MAX_DETAIL_RETRIES:\n",
    "                            # give empty values on failure\n",
    "                            detail_map[dl] = {\"mileage\": \"\", \"transmission\": \"\"}\n",
    "                            success = True\n",
    "                        else:\n",
    "                            time.sleep(0.8)\n",
    "\n",
    "                # progress print occasionally\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print(f\"Processed {i+1} detail pages...\")\n",
    "\n",
    "            # Now merge detail_map into rows\n",
    "            for r in rows:\n",
    "                link = r.get(\"detail_page\", \"\")\n",
    "                if link and link in detail_map:\n",
    "                    r[\"mileage\"] = detail_map[link][\"mileage\"]\n",
    "                    r[\"transmission\"] = detail_map[link][\"transmission\"]\n",
    "                else:\n",
    "                    # attempt to find mileage/trans in the card text (already tried earlier)\n",
    "                    # leave empty if not found\n",
    "                    if not r[\"mileage\"]:\n",
    "                        # try to infer from model/name\n",
    "                        r[\"mileage\"] = \"\"\n",
    "                    if not r[\"transmission\"]:\n",
    "                        r[\"transmission\"] = \"\"\n",
    "\n",
    "        # build DataFrame and clean\n",
    "        df = pd.DataFrame(rows, columns=[\n",
    "            \"Car_name\", \"brand\", \"model\", \"kms_driven\", \"mileage\", \"transmission\",\n",
    "            \"fuel_type\", \"year_of_manufacture\", \"price\", \"detail_page\"\n",
    "        ])\n",
    "\n",
    "        # normalize\n",
    "        df[\"kms_driven\"] = df[\"kms_driven\"].fillna(\"\").astype(str).apply(lambda x: re.sub(r'[^\\d\\.]', '', x))\n",
    "        df[\"mileage\"] = df[\"mileage\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"transmission\"] = df[\"transmission\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "        df[\"year_of_manufacture\"] = df[\"year_of_manufacture\"].fillna(\"\").astype(str).apply(lambda x: (re.search(r'\\b(19|20)\\d{2}\\b', x).group(0) if re.search(r'\\b(19|20)\\d{2}\\b', x) else \"\"))\n",
    "        df[\"price\"] = df[\"price\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"fuel_type\"] = df[\"fuel_type\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "\n",
    "        # dedupe by detail_link if present else by Car_name+price\n",
    "        if df[\"detail_page\"].notnull().sum() > 0:\n",
    "            df = df.drop_duplicates(subset=[\"detail_page\"]).reset_index(drop=True)\n",
    "        else:\n",
    "            df = df.drop_duplicates(subset=[\"Car_name\", \"price\"]).reset_index(drop=True)\n",
    "\n",
    "        # save\n",
    "        df.to_csv(OUTPUT_CSV, index=False)\n",
    "        df.to_excel(OUTPUT_XLSX, index=False)\n",
    "        print(f\"Done. Collected {len(df)} rows. Saved to {OUTPUT_CSV} and {OUTPUT_XLSX}\")\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a077c-26ef-4492-ba6a-c3b1f05070aa",
   "metadata": {},
   "source": [
    "2nd Stage of Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "315f92d6-a03e-4223-b818-edb3cfe30f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected total_listings=601, per_page_guess=64, total_pages=10\n",
      "Scanned page 10; rows so far: 533\n",
      "Collected 533 card-level rows, detail links: 516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_7052\\2808381624.py:339: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_7052\\2808381624.py:354: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 detail pages...\n",
      "Processed 200 detail pages...\n",
      "Processed 300 detail pages...\n",
      "Processed 400 detail pages...\n",
      "Processed 500 detail pages...\n",
      "Saved 517 rows to cardekho_used_cars_nagpur_price_fixed.csv and cardekho_used_cars_nagpur_price_fixed.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "cardekho_with_price_fix.py\n",
    "\n",
    "Improved scraper for CarDekho used cars (Nagpur) with robust price extraction.\n",
    "Requires: selenium, webdriver-manager, beautifulsoup4, pandas, openpyxl\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# -------- CONFIG ----------\n",
    "START_URL = \"https://www.cardekho.com/used-cars+in+nagpur\"\n",
    "OUTPUT_CSV = \"cardekho_used_cars_nagpur_price_fixed.csv\"\n",
    "OUTPUT_XLSX = \"cardekho_used_cars_nagpur_price_fixed.xlsx\"\n",
    "\n",
    "HEADLESS = True\n",
    "MAX_PAGES_OVERRIDE = None\n",
    "MAX_SCROLLS = 40\n",
    "SCROLL_PAUSE = 0.7\n",
    "PAGE_PAUSE = (0.6, 1.4)\n",
    "VISIT_DETAIL_PAGES = True\n",
    "DETAIL_PAUSE = (0.6, 1.2)\n",
    "MAX_DETAIL_RETRIES = 1\n",
    "\n",
    "BRANDS = [\n",
    "    \"Maruti\", \"Hyundai\", \"Tata\", \"Honda\", \"Toyota\", \"Mahindra\", \"Kia\",\n",
    "    \"BMW\", \"Audi\", \"Mercedes-Benz\", \"Mercedes\", \"Renault\", \"MG\", \"Skoda\",\n",
    "    \"Volkswagen\", \"Ford\", \"Nissan\", \"Jeep\", \"Volvo\", \"Land Rover\", \"Jaguar\",\n",
    "    \"Isuzu\", \"Datsun\", \"Chevrolet\", \"Opel\"\n",
    "]\n",
    "# --------------------------\n",
    "\n",
    "def text_of(elem):\n",
    "    return elem.get_text(\" \", strip=True) if elem else \"\"\n",
    "\n",
    "def guess_brand_and_model(name):\n",
    "    if not name:\n",
    "        return \"\", \"\"\n",
    "    for b in BRANDS:\n",
    "        if b.lower() in name.lower():\n",
    "            model = re.sub(re.escape(b), \"\", name, flags=re.IGNORECASE).strip()\n",
    "            model = re.sub(r'^[\\-\\:\\–\\—\\s]+', '', model)\n",
    "            return b, model or name\n",
    "    parts = name.split()\n",
    "    return (parts[0], \" \".join(parts[1:]) if len(parts) > 1 else \"\") if parts else (\"\",\"\")\n",
    "\n",
    "def extract_kms(text):\n",
    "    m = re.search(r'([\\d,\\.]+)\\s*(?:kms|km)\\b', text, flags=re.I)\n",
    "    if m:\n",
    "        return m.group(1).replace(\",\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "def extract_fuel(text):\n",
    "    for f in [\"Petrol\", \"Diesel\", \"CNG\", \"LPG\", \"Electric\", \"Hybrid\"]:\n",
    "        if re.search(r'\\b' + re.escape(f) + r'\\b', text, flags=re.I):\n",
    "            return f\n",
    "    return \"\"\n",
    "\n",
    "# NEW: robust price extraction from soup and raw text\n",
    "def extract_price_from_soup(soup):\n",
    "    # 1. meta tags\n",
    "    meta_selectors = [\n",
    "        ('meta', {'property': 'og:price:amount'}),\n",
    "        ('meta', {'itemprop': 'price'}),\n",
    "        ('meta', {'name': 'price'}),\n",
    "    ]\n",
    "    for tag, attrs in meta_selectors:\n",
    "        mtag = soup.find(tag, attrs=attrs)\n",
    "        if mtag:\n",
    "            val = mtag.get('content') or mtag.get('value') or \"\"\n",
    "            if val:\n",
    "                # normalize: prepend ₹ if numeric and no symbol\n",
    "                if re.search(r'[\\d]', val) and '₹' not in val:\n",
    "                    return \"₹ \" + val.strip()\n",
    "                return val.strip()\n",
    "\n",
    "    # 2. attributes that often store price\n",
    "    for attr in ('data-price', 'data-offer-price', 'data-srp', 'data-amount', 'data-price-value'):\n",
    "        el = soup.find(attrs={attr: True})\n",
    "        if el:\n",
    "            val = el.get(attr)\n",
    "            if val:\n",
    "                if re.search(r'[\\d]', val) and '₹' not in val:\n",
    "                    return \"₹ \" + val.strip()\n",
    "                return val.strip()\n",
    "\n",
    "    # 3. elements with class or id containing 'price' or 'amount'\n",
    "    px = soup.find(lambda tag: tag.name in (\"div\",\"span\",\"p\",\"strong\") and (\n",
    "        tag.get(\"class\") or tag.get(\"id\")\n",
    "    ) and re.search(r'price|amount|selling|srp|finalPrice|carPrice|actual-price', \" \".join((tag.get(\"class\") or []) + [tag.get(\"id\") or \"\"]), flags=re.I))\n",
    "    if px:\n",
    "        txt = text_of(px)\n",
    "        pr = find_rupee_in_text(txt)\n",
    "        if pr:\n",
    "            return pr\n",
    "        if txt:\n",
    "            return txt.strip()\n",
    "\n",
    "    # 4. any visible text near top with rupee sign\n",
    "    top_region = \"\"\n",
    "    # try header / top sections\n",
    "    head_candidates = soup.find_all([\"header\", \"section\", \"div\"], limit=6)\n",
    "    for c in head_candidates:\n",
    "        t = text_of(c)\n",
    "        if '₹' in t:\n",
    "            top_region = t\n",
    "            break\n",
    "    if not top_region:\n",
    "        # fallback full page text (takes last resort)\n",
    "        top_region = soup.get_text(\" \", strip=True)\n",
    "\n",
    "    pr = find_rupee_in_text(top_region)\n",
    "    if pr:\n",
    "        return pr\n",
    "\n",
    "    # 5. fallback regex on whole page (Lakh/Crore)\n",
    "    p2 = re.search(r'[\\d\\.,]+\\s*(?:Lakh|lakh|Lakhs|lakhs|Crore|crore|Cr)\\b', soup.get_text(\" \", strip=True))\n",
    "    if p2:\n",
    "        return p2.group(0).strip()\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def find_rupee_in_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    m = re.search(r'₹\\s*[\\d\\.,\\sA-Za-z]+', text)\n",
    "    if m:\n",
    "        return m.group(0).strip()\n",
    "    # sometimes rupee symbol is missing but values use lakh/crore\n",
    "    m2 = re.search(r'[\\d\\.,]+\\s*(Lakh|lakh|Lakhs|lakhs|Crore|crore|Cr)\\b', text)\n",
    "    if m2:\n",
    "        return m2.group(0).strip()\n",
    "    return \"\"\n",
    "\n",
    "def extract_price_from_text(text):\n",
    "    # ensures same fallback when only raw text available\n",
    "    p = find_rupee_in_text(text)\n",
    "    return p\n",
    "\n",
    "def extract_year(text):\n",
    "    m = re.search(r'\\b(19|20)\\d{2}\\b', text)\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    "# main\n",
    "def main():\n",
    "    chrome_opts = Options()\n",
    "    if HEADLESS:\n",
    "        chrome_opts.add_argument(\"--headless=new\")\n",
    "    chrome_opts.add_argument(\"--no-sandbox\")\n",
    "    chrome_opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_opts.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_opts)\n",
    "\n",
    "    try:\n",
    "        driver.get(START_URL)\n",
    "        time.sleep(2.0)\n",
    "        soup0 = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        text0 = soup0.get_text(\" \", strip=True)\n",
    "\n",
    "        total_listings = None\n",
    "        m = re.search(r'([\\d,]{2,})\\s+Second Hand Cars in Nagpur', text0, flags=re.I)\n",
    "        if not m:\n",
    "            m = re.search(r'of\\s+([\\d,]+)\\s+results', text0, flags=re.I)\n",
    "        if m:\n",
    "            total_listings = int(m.group(1).replace(\",\", \"\"))\n",
    "\n",
    "        per_page_guess = max(1, len(soup0.find_all(\"h3\")))\n",
    "        estimated_pages = math.ceil(total_listings / per_page_guess) if total_listings else None\n",
    "        total_pages = int(estimated_pages) if estimated_pages else 200\n",
    "        if MAX_PAGES_OVERRIDE:\n",
    "            total_pages = MAX_PAGES_OVERRIDE\n",
    "\n",
    "        print(f\"Detected total_listings={total_listings}, per_page_guess={per_page_guess}, total_pages={total_pages}\")\n",
    "\n",
    "        rows = []\n",
    "        seen_keys = set()\n",
    "        detail_links = []\n",
    "\n",
    "        for p in range(1, total_pages + 1):\n",
    "            page_url = START_URL.rstrip(\"/\") + \"?page=\" + str(p)\n",
    "            try:\n",
    "                driver.get(page_url)\n",
    "            except Exception:\n",
    "                time.sleep(1.0)\n",
    "                driver.get(page_url)\n",
    "\n",
    "            # scroll aggressively\n",
    "            last_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            sc = 0\n",
    "            while sc < MAX_SCROLLS:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(SCROLL_PAUSE)\n",
    "                new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_h == last_h:\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight-400);\")\n",
    "                    time.sleep(0.4)\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    time.sleep(0.4)\n",
    "                    new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                    if new_h == last_h:\n",
    "                        break\n",
    "                last_h = new_h\n",
    "                sc += 1\n",
    "\n",
    "            page_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            titles = page_soup.find_all(\"h3\")\n",
    "            for h in titles:\n",
    "                title = text_of(h)\n",
    "                if not title:\n",
    "                    continue\n",
    "\n",
    "                container = h\n",
    "                card_text = \"\"\n",
    "                link = \"\"\n",
    "                for _ in range(6):\n",
    "                    if container is None:\n",
    "                        break\n",
    "                    card_text = text_of(container)\n",
    "                    if \"₹\" in card_text or re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I):\n",
    "                        a = container.find(\"a\", href=True)\n",
    "                        if a:\n",
    "                            href = a[\"href\"]\n",
    "                            link = href if \"cardekho.com\" in href else urljoin(page_url, href)\n",
    "                            link = link.split(\"#\")[0].split(\"?utm\")[0]\n",
    "                        break\n",
    "                    container = container.parent\n",
    "\n",
    "                if not card_text:\n",
    "                    parent = h.parent\n",
    "                    card_text = text_of(parent) if parent else title\n",
    "\n",
    "                if (\"₹\" not in card_text) and (re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I) is None):\n",
    "                    continue\n",
    "\n",
    "                price_card = extract_price_from_text(card_text)\n",
    "                key = (title + \"||\" + (price_card or \"\")).strip()\n",
    "                if key in seen_keys:\n",
    "                    continue\n",
    "                seen_keys.add(key)\n",
    "\n",
    "                kms = extract_kms(card_text)\n",
    "                fuel = extract_fuel(card_text)\n",
    "                year = extract_year(title) or extract_year(card_text)\n",
    "                brand = \"\"\n",
    "                model = \"\"\n",
    "                try:\n",
    "                    brand, model = guess_brand_and_model(title)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                rows.append({\n",
    "                    \"Car_name\": title,\n",
    "                    \"brand\": brand,\n",
    "                    \"model\": model,\n",
    "                    \"kms_driven\": kms,\n",
    "                    \"mileage\": \"\",\n",
    "                    \"transmission\": \"\",\n",
    "                    \"fuel_type\": fuel,\n",
    "                    \"year_of_manufacture\": year,\n",
    "                    \"price\": price_card,\n",
    "                    \"detail_page\": link\n",
    "                })\n",
    "\n",
    "                if link:\n",
    "                    detail_links.append(link)\n",
    "\n",
    "            time.sleep(random.uniform(*PAGE_PAUSE))\n",
    "\n",
    "            if total_listings and len(seen_keys) >= total_listings:\n",
    "                print(\"Reached detected total listings; stopping page scan.\")\n",
    "                break\n",
    "\n",
    "            if p % 10 == 0:\n",
    "                print(f\"Scanned page {p}; rows so far: {len(rows)}\")\n",
    "\n",
    "        print(f\"Collected {len(rows)} card-level rows, detail links: {len(set(detail_links))}\")\n",
    "\n",
    "        # Now ensure price is filled: visit detail pages for any row missing price\n",
    "        if VISIT_DETAIL_PAGES and detail_links:\n",
    "            unique_detail_links = []\n",
    "            seen_dl = set()\n",
    "            for u in detail_links:\n",
    "                if u and u not in seen_dl:\n",
    "                    seen_dl.add(u)\n",
    "                    unique_detail_links.append(u)\n",
    "\n",
    "            # map link -> price (and optionally mileage/transmission)\n",
    "            detail_map = {}\n",
    "\n",
    "            for i, dl in enumerate(unique_detail_links):\n",
    "                # polite pause\n",
    "                if i > 0:\n",
    "                    time.sleep(random.uniform(*DETAIL_PAUSE))\n",
    "                attempt = 0\n",
    "                success = False\n",
    "                while attempt <= MAX_DETAIL_RETRIES and not success:\n",
    "                    try:\n",
    "                        driver.get(dl)\n",
    "                        time.sleep(1.0 + random.random()*0.8)\n",
    "                        dsoup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "                        # price from many possible places\n",
    "                        price_val = extract_price_from_soup(dsoup)\n",
    "                        # fallback to regex on page text\n",
    "                        if not price_val:\n",
    "                            price_val = extract_price_from_text(dsoup.get_text(\" \", strip=True))\n",
    "\n",
    "                        # mileage and transmission extraction as before\n",
    "                        page_text = dsoup.get_text(\" \", strip=True)\n",
    "                        # try meta-line near title for quick values\n",
    "                        h_tag = dsoup.find([\"h1\",\"h2\"])\n",
    "                        meta_line = \"\"\n",
    "                        if h_tag:\n",
    "                            nxt = h_tag.find_next()\n",
    "                            checks = 0\n",
    "                            while nxt and checks < 8:\n",
    "                                t = text_of(nxt)\n",
    "                                if t and ((\"kms\" in t.lower()) or (\"₹\" in t) or re.search(r'\\b\\d+\\s*(?:kmpl|km/kg|km/kwh|km/l|kpl)\\b', t, flags=re.I)):\n",
    "                                    meta_line = t\n",
    "                                    break\n",
    "                                nxt = nxt.find_next()\n",
    "                                checks += 1\n",
    "\n",
    "                        # mileage\n",
    "                        mileage_val = \"\"\n",
    "                        mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
    "                        if mnode:\n",
    "                            try:\n",
    "                                parent = mnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    mileage_val = text_of(sib)\n",
    "                            except:\n",
    "                                mileage_val = \"\"\n",
    "                        if not mileage_val:\n",
    "                            # check meta_line then page_text\n",
    "                            mileage_val = extract_mileage(meta_line or page_text) or extract_mileage(page_text)\n",
    "\n",
    "                        # transmission\n",
    "                        trans_val = \"\"\n",
    "                        tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n",
    "                        if tnode:\n",
    "                            try:\n",
    "                                parent = tnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    trans_val = text_of(sib)\n",
    "                            except:\n",
    "                                trans_val = \"\"\n",
    "                        if not trans_val:\n",
    "                            trans_val = extract_transmission(meta_line or page_text)\n",
    "\n",
    "                        detail_map[dl] = {\n",
    "                            \"price\": price_val or \"\",\n",
    "                            \"mileage\": mileage_val or \"\",\n",
    "                            \"transmission\": trans_val or \"\"\n",
    "                        }\n",
    "                        success = True\n",
    "                    except Exception as e:\n",
    "                        attempt += 1\n",
    "                        if attempt > MAX_DETAIL_RETRIES:\n",
    "                            detail_map[dl] = {\"price\": \"\", \"mileage\": \"\", \"transmission\": \"\"}\n",
    "                            success = True\n",
    "                        else:\n",
    "                            time.sleep(0.8)\n",
    "\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print(f\"Processed {i+1} detail pages...\")\n",
    "\n",
    "            # merge into rows\n",
    "            for r in rows:\n",
    "                link = r.get(\"detail_page\", \"\")\n",
    "                if link and link in detail_map:\n",
    "                    # prefer detail price if card-level empty\n",
    "                    if not r.get(\"price\"):\n",
    "                        r[\"price\"] = detail_map[link][\"price\"]\n",
    "                    # always try to fill mileage/trans if available\n",
    "                    if not r.get(\"mileage\"):\n",
    "                        r[\"mileage\"] = detail_map[link][\"mileage\"]\n",
    "                    if not r.get(\"transmission\"):\n",
    "                        r[\"transmission\"] = detail_map[link][\"transmission\"]\n",
    "\n",
    "        # final normalization\n",
    "        df = pd.DataFrame(rows, columns=[\n",
    "            \"Car_name\",\"brand\",\"model\",\"kms_driven\",\"mileage\",\"transmission\",\"fuel_type\",\"year_of_manufacture\",\"price\",\"detail_page\"\n",
    "        ])\n",
    "        df[\"kms_driven\"] = df[\"kms_driven\"].fillna(\"\").astype(str).apply(lambda x: re.sub(r'[^\\d\\.]', '', x))\n",
    "        df[\"mileage\"] = df[\"mileage\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"transmission\"] = df[\"transmission\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "        df[\"year_of_manufacture\"] = df[\"year_of_manufacture\"].fillna(\"\").astype(str).apply(lambda x: (re.search(r'\\b(19|20)\\d{2}\\b', x).group(0) if re.search(r'\\b(19|20)\\d{2}\\b', x) else \"\"))\n",
    "        df[\"price\"] = df[\"price\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"fuel_type\"] = df[\"fuel_type\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "\n",
    "        # dedupe\n",
    "        if \"detail_page\" in df.columns and df[\"detail_page\"].str.len().sum() > 0:\n",
    "            df = df.drop_duplicates(subset=[\"detail_page\"]).reset_index(drop=True)\n",
    "        else:\n",
    "            df = df.drop_duplicates(subset=[\"Car_name\",\"price\"]).reset_index(drop=True)\n",
    "\n",
    "        # save\n",
    "        df.to_csv(OUTPUT_CSV, index=False)\n",
    "        df.to_excel(OUTPUT_XLSX, index=False)\n",
    "        print(f\"Saved {len(df)} rows to {OUTPUT_CSV} and {OUTPUT_XLSX}\")\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# helpers used in detail extraction (mileage/transmission)\n",
    "def extract_mileage(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # reuse a robust regex set (common patterns)\n",
    "    m = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|km/kg|km/kwh|km/l|kpl|km)', text, flags=re.I)\n",
    "    if m:\n",
    "        return f\"{m.group(1)} {m.group(2)}\".strip()\n",
    "    m2 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(mpg)\\b', text, flags=re.I)\n",
    "    if m2:\n",
    "        return f\"{m2.group(1)} {m2.group(2)}\"\n",
    "    return \"\"\n",
    "\n",
    "def extract_transmission(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    for t in [\"Manual\",\"Automatic\",\"CVT\",\"AMT\",\"DCT\",\"AT\",\"MT\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', text, flags=re.I):\n",
    "            if t.upper() in (\"AT\",\"AMT\",\"CVT\",\"DCT\",\"MT\"):\n",
    "                return t.upper()\n",
    "            return t.title()\n",
    "    return \"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af6b44c-8d22-47ad-92fd-f9a1d5fddc7d",
   "metadata": {},
   "source": [
    "3rd Stage of Web Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd81cd6e-e226-435c-9299-c76bf836ef18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected total_listings=603, per_page_guess=64, total_pages_to_try=10\n",
      "Scanned page 10; collected cards so far: 535\n",
      "Initial collection done: 535 card rows, detail links discovered: 518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_7052\\1847608782.py:285: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  label_kms = dsoup.find(text=re.compile(r'Kms\\s*Driven|Kms|Odometer', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_7052\\1847608782.py:302: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  label_fuel = dsoup.find(text=re.compile(r'Fuel\\s*Type|Fuel', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_7052\\1847608782.py:316: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  label_year = dsoup.find(text=re.compile(r'Year\\s*of\\s*Manufacture|Registration\\s*Year|Year', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_7052\\1847608782.py:339: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved after 200 detail visits: 196 rows.\n",
      "Checkpoint saved after 400 detail visits: 396 rows.\n",
      "Saved cleaned output: cardekho_used_cars_nagpur_clean_fixed.csv and cardekho_used_cars_nagpur_clean_fixed.xlsx\n",
      "Total rows collected: 519\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_name</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>kms_driven</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>year_of_manufacture</th>\n",
       "      <th>price</th>\n",
       "      <th>mileage</th>\n",
       "      <th>detail_page</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015 Maruti Swift VXI</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2015  Swift VXI</td>\n",
       "      <td>2015425201520142021470000151324148839646561565</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2015</td>\n",
       "      <td>₹4.25 Lakh</td>\n",
       "      <td>47,000 kms • Petrol • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023 MG Astor Super MT</td>\n",
       "      <td>MG</td>\n",
       "      <td>2023  Astor Super MT</td>\n",
       "      <td>202314987552023147007557916718429285435931</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2023</td>\n",
       "      <td>₹7.55 Lakh with Less Driven</td>\n",
       "      <td>14,725 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018 Hyundai Xcent 1.2 VTVT S</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2018  Xcent 1.2 VTVT S</td>\n",
       "      <td>2025119743020251251000430126442497385495362216</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2018</td>\n",
       "      <td>₹4.30 Lakh with Almost New</td>\n",
       "      <td>51,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57 Used Cars Under 2 Lakh in Nagpur</td>\n",
       "      <td>57</td>\n",
       "      <td>Used Cars Under 2 Lakh in Nagpur</td>\n",
       "      <td>572202</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2012</td>\n",
       "      <td>₹1 Lakh</td>\n",
       "      <td>57 used cars Under 2 Lakh are available for sa...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+0-lakh-to-2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81 Used Cars Under 3 Lakh in Nagpur</td>\n",
       "      <td>81</td>\n",
       "      <td>Used Cars Under 3 Lakh in Nagpur</td>\n",
       "      <td>813323</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2015</td>\n",
       "      <td>₹2.89 Lakh</td>\n",
       "      <td>81 used cars Under 3 Lakh are available for sa...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+2-lakh-to-3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>228 Used Cars Under 5 Lakh in Nagpur</td>\n",
       "      <td>228</td>\n",
       "      <td>Used Cars Under 5 Lakh in Nagpur</td>\n",
       "      <td>2285535</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2017</td>\n",
       "      <td>₹3.25 Lakh</td>\n",
       "      <td>228 used cars Under 5 Lakh are available for s...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+3-lakh-to-5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>135 Used Cars Under 8 Lakh in Nagpur</td>\n",
       "      <td>135</td>\n",
       "      <td>Used Cars Under 8 Lakh in Nagpur</td>\n",
       "      <td>1358858</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2023</td>\n",
       "      <td>₹6.95 Lakh</td>\n",
       "      <td>135 used cars Under 8 Lakh are available for s...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+5-lakh-to-8...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34 Used Cars Under 10 Lakh in Nagpur</td>\n",
       "      <td>34</td>\n",
       "      <td>Used Cars Under 10 Lakh in Nagpur</td>\n",
       "      <td>341010810</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹8.50 Lakh</td>\n",
       "      <td>34 used cars Under 10 Lakh are available for s...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+8-lakh-to-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>68 Used Cars Above 10 Lakh in Nagpur</td>\n",
       "      <td>68</td>\n",
       "      <td>Used Cars Above 10 Lakh in Nagpur</td>\n",
       "      <td>681010105</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹12 Lakh</td>\n",
       "      <td>68 used cars Above 10 Lakh are available for s...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+10-lakh-to-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014 Ford Ecosport 1.5 DV5 MT Titanium Optional</td>\n",
       "      <td>Ford</td>\n",
       "      <td>2014  Ecosport 1.5 DV5 MT Titanium Optional</td>\n",
       "      <td>2014370201420132015155120000155684875414007812...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2014</td>\n",
       "      <td>₹3.70 Lakh</td>\n",
       "      <td>1,20,000 kms • Diesel • Manual • 3rd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022 Renault Kiger RXE</td>\n",
       "      <td>Renault</td>\n",
       "      <td>2022  Kiger RXE</td>\n",
       "      <td>2022999549202220212023608005493186732005433230...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2022</td>\n",
       "      <td>₹5.49 Lakh</td>\n",
       "      <td>60,765 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014 Hyundai Xcent 1.2 Kappa SX</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2014  Xcent 1.2 Kappa SX</td>\n",
       "      <td>2014119738020142014201612700003801217236150542...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2014</td>\n",
       "      <td>₹3.80 Lakh</td>\n",
       "      <td>70,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012 Honda Brio V MT</td>\n",
       "      <td>Honda</td>\n",
       "      <td>2012  Brio V MT</td>\n",
       "      <td>2012119815020122011201372000150271242145415290...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2012</td>\n",
       "      <td>₹1.50 Lakh</td>\n",
       "      <td>72,000 kms • Petrol • Manual • 3rd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018 Honda WR-V i-VTEC S</td>\n",
       "      <td>Honda</td>\n",
       "      <td>2018  WR-V i-VTEC S</td>\n",
       "      <td>20185202018201720206000052125078924963571</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2018</td>\n",
       "      <td>₹5.20 Lakh</td>\n",
       "      <td>60,000 kms • Petrol • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016 Mercedes-Benz CLA 200 CDI Sport</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>2016  CLA 200 CDI Sport</td>\n",
       "      <td>201615502016200620002001007499114093312981422</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2016</td>\n",
       "      <td>₹15.50 Lakh</td>\n",
       "      <td>62,000 kms • Diesel • Automatic • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014 Mahindra Xylo D4</td>\n",
       "      <td>Mahindra</td>\n",
       "      <td>2014  Xylo D4</td>\n",
       "      <td>20144202014437000042168470977743849424265469</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2014</td>\n",
       "      <td>₹4.20 Lakh</td>\n",
       "      <td>3,70,000 kms • Diesel • Manual • 4th Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015 Mahindra TUV 300 T8</td>\n",
       "      <td>Mahindra</td>\n",
       "      <td>2015  TUV 300 T8</td>\n",
       "      <td>2015300520153002015201981600003008595056465411...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2015</td>\n",
       "      <td>₹5 Lakh</td>\n",
       "      <td>1,60,000 kms • Diesel • Manual • 3rd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014 Ford Ecosport 1.5 DV5 MT Titanium</td>\n",
       "      <td>Ford</td>\n",
       "      <td>2014  Ecosport 1.5 DV5 MT Titanium</td>\n",
       "      <td>2014440201420132015155120000155364048411655948...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2014</td>\n",
       "      <td>₹4.40 Lakh</td>\n",
       "      <td>1,20,000 kms • Diesel • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2008 Mahindra Scorpio DX 2.6 Turbo 9Str</td>\n",
       "      <td>Mahindra</td>\n",
       "      <td>2008  Scorpio DX 2.6 Turbo 9Str</td>\n",
       "      <td>2008250200820062009269356000269551316472850135...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2008</td>\n",
       "      <td>₹2.50 Lakh</td>\n",
       "      <td>3,56,000 kms • Diesel • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013 Chevrolet Beat LS</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>2013  Beat LS</td>\n",
       "      <td>201317020132009201370000777804819459928263738</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2013</td>\n",
       "      <td>₹1.70 Lakh</td>\n",
       "      <td>70,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2011 Mahindra Xylo E4</td>\n",
       "      <td>Mahindra</td>\n",
       "      <td>2011  Xylo E4</td>\n",
       "      <td>201123020112008201141600004124130428013123974834</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2011</td>\n",
       "      <td>₹2.30 Lakh</td>\n",
       "      <td>1,60,000 kms • Diesel • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>228 Used Cars Under 5 Lakh in Nagpur</td>\n",
       "      <td>228</td>\n",
       "      <td>Used Cars Under 5 Lakh in Nagpur</td>\n",
       "      <td>2285535</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2015</td>\n",
       "      <td>₹3.25 Lakh</td>\n",
       "      <td>228 used cars Under 5 Lakh are available for s...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+2-lakh-to-5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33 Used Cars in Nagpur With Search Options</td>\n",
       "      <td>33</td>\n",
       "      <td>Used Cars in Nagpur With Search Options</td>\n",
       "      <td>020000</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2023</td>\n",
       "      <td>₹1.70 Lakh in Nagpur. The most popular used ca...</td>\n",
       "      <td>000 km</td>\n",
       "      <td>https://www.cardekho.com/used-cars+0-20000-km+...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021 Kia Sonet HTK Plus BSVI</td>\n",
       "      <td>Kia</td>\n",
       "      <td>2021  Sonet HTK Plus BSVI</td>\n",
       "      <td>202511978202520202024510008298346455904360310</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹8 Lakh with Almost New</td>\n",
       "      <td>51,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020 Kia Seltos HTK Plus AT D</td>\n",
       "      <td>Kia</td>\n",
       "      <td>2020  Seltos HTK Plus AT D</td>\n",
       "      <td>2020149312202020192023650001269423992374288292...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2020</td>\n",
       "      <td>₹12 Lakh</td>\n",
       "      <td>65,000 kms • Diesel • Automatic • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021 Renault Kiger RXZ</td>\n",
       "      <td>Renault</td>\n",
       "      <td>2021  Kiger RXZ</td>\n",
       "      <td>2021999639202120212023190006393124918295036155</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹6.39 Lakh</td>\n",
       "      <td>19,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020 Skoda Rapid 1.5 TDI Style BSIV</td>\n",
       "      <td>Skoda</td>\n",
       "      <td>2020  Rapid 1.5 TDI Style BSIV</td>\n",
       "      <td>202067520201510000015645596545579213378941</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2020</td>\n",
       "      <td>₹6.75 Lakh</td>\n",
       "      <td>1,00,000 kms • Diesel • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019 Hyundai Venue E BSIV</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2019  Venue E BSIV</td>\n",
       "      <td>2019119760520192019202236000605310654641155015...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2019</td>\n",
       "      <td>₹6.05 Lakh</td>\n",
       "      <td>36,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019 Hyundai Creta 1.4 E Plus CRDi</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2019  Creta 1.4 E Plus CRDi</td>\n",
       "      <td>2019139692520192015202014103000925140153824788...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2019</td>\n",
       "      <td>₹9.25 Lakh</td>\n",
       "      <td>1,03,000 kms • Diesel • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2009 Toyota Innova 2.5 G (Diesel) 7 Seater BS III</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>2009  Innova 2.5 G (Diesel) 7 Seater BS III</td>\n",
       "      <td>2009249432520092004201125792800325257826047950...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2009</td>\n",
       "      <td>₹3.25 Lakh</td>\n",
       "      <td>92,800 kms • Diesel • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2017 BMW 5 Series 520d Luxury Line</td>\n",
       "      <td>BMW</td>\n",
       "      <td>2017  5 Series 520d Luxury Line</td>\n",
       "      <td>2017527201752013201752030000552082221241397774487</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2017</td>\n",
       "      <td>₹27 Lakh</td>\n",
       "      <td>30,000 kms • Diesel • Automatic • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020 Kia Seltos HTK Diesel</td>\n",
       "      <td>Kia</td>\n",
       "      <td>2020  Seltos HTK Diesel</td>\n",
       "      <td>2020149310252020201920231105001025252624164685...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2020</td>\n",
       "      <td>₹10.25 Lakh</td>\n",
       "      <td>1,10,459 kms • Diesel • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2015 Ford Ecosport 1.5 Ti VCT MT Titanium</td>\n",
       "      <td>Ford</td>\n",
       "      <td>2015  Ecosport 1.5 Ti VCT MT Titanium</td>\n",
       "      <td>2015149942520152013201515430004251594276184210...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2015</td>\n",
       "      <td>₹4.25 Lakh</td>\n",
       "      <td>43,000 kms • Petrol • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2017 Ford Aspire 1.2 Ti-VCT Trend</td>\n",
       "      <td>Ford</td>\n",
       "      <td>2017  Aspire 1.2 Ti-VCT Trend</td>\n",
       "      <td>2017119634020171265000340129577760842428839458...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2017</td>\n",
       "      <td>₹3.40 Lakh</td>\n",
       "      <td>65,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2018 Honda Amaze S i-DTEC</td>\n",
       "      <td>Honda</td>\n",
       "      <td>2018  Amaze S i-DTEC</td>\n",
       "      <td>2018570201820162021100000101146327649784401038...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2018</td>\n",
       "      <td>₹5.70 Lakh</td>\n",
       "      <td>1,00,000 kms • Diesel • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2015 Maruti Alto K10 VXI</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2015  Alto K10 VXI</td>\n",
       "      <td>2015109982902015102014202079000290107878904425...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2015</td>\n",
       "      <td>₹2.90 Lakh</td>\n",
       "      <td>79,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2018 Honda City i-DTEC SV</td>\n",
       "      <td>Honda</td>\n",
       "      <td>2018  City i-DTEC SV</td>\n",
       "      <td>201841498750201847600075078319733448641680011468</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2018</td>\n",
       "      <td>₹7.50 Lakh with RC Transfer</td>\n",
       "      <td>76,000 kms • Diesel • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2017 Mahindra XUV500 R W10 FWD</td>\n",
       "      <td>Mahindra</td>\n",
       "      <td>2017  XUV500 R W10 FWD</td>\n",
       "      <td>2017500217982520175001072000825500109791282854...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2017</td>\n",
       "      <td>₹8.25 Lakh</td>\n",
       "      <td>72,000 kms • Diesel • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2014 Toyota Etios GD</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>2014  Etios GD</td>\n",
       "      <td>2025136439020252013201474000390840062727549489...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2014</td>\n",
       "      <td>₹3.90 Lakh with Almost New</td>\n",
       "      <td>74,000 kms • Diesel • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2021 Hyundai Creta SX Diesel BSVI</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2021  Creta SX Diesel BSVI</td>\n",
       "      <td>2021125020212020202480000433334399707396161</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹12.50 Lakh</td>\n",
       "      <td>80,000 kms • Diesel • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Car_name          brand  \\\n",
       "0                               2015 Maruti Swift VXI         Maruti   \n",
       "1                              2023 MG Astor Super MT             MG   \n",
       "2                       2018 Hyundai Xcent 1.2 VTVT S        Hyundai   \n",
       "3                 57 Used Cars Under 2 Lakh in Nagpur             57   \n",
       "4                 81 Used Cars Under 3 Lakh in Nagpur             81   \n",
       "5                228 Used Cars Under 5 Lakh in Nagpur            228   \n",
       "6                135 Used Cars Under 8 Lakh in Nagpur            135   \n",
       "7                34 Used Cars Under 10 Lakh in Nagpur             34   \n",
       "8                68 Used Cars Above 10 Lakh in Nagpur             68   \n",
       "9     2014 Ford Ecosport 1.5 DV5 MT Titanium Optional           Ford   \n",
       "10                             2022 Renault Kiger RXE        Renault   \n",
       "11                    2014 Hyundai Xcent 1.2 Kappa SX        Hyundai   \n",
       "12                               2012 Honda Brio V MT          Honda   \n",
       "13                           2018 Honda WR-V i-VTEC S          Honda   \n",
       "14               2016 Mercedes-Benz CLA 200 CDI Sport  Mercedes-Benz   \n",
       "15                              2014 Mahindra Xylo D4       Mahindra   \n",
       "16                           2015 Mahindra TUV 300 T8       Mahindra   \n",
       "17             2014 Ford Ecosport 1.5 DV5 MT Titanium           Ford   \n",
       "18            2008 Mahindra Scorpio DX 2.6 Turbo 9Str       Mahindra   \n",
       "19                             2013 Chevrolet Beat LS      Chevrolet   \n",
       "20                              2011 Mahindra Xylo E4       Mahindra   \n",
       "21               228 Used Cars Under 5 Lakh in Nagpur            228   \n",
       "22         33 Used Cars in Nagpur With Search Options             33   \n",
       "23                       2021 Kia Sonet HTK Plus BSVI            Kia   \n",
       "24                      2020 Kia Seltos HTK Plus AT D            Kia   \n",
       "25                             2021 Renault Kiger RXZ        Renault   \n",
       "26                2020 Skoda Rapid 1.5 TDI Style BSIV          Skoda   \n",
       "27                          2019 Hyundai Venue E BSIV        Hyundai   \n",
       "28                 2019 Hyundai Creta 1.4 E Plus CRDi        Hyundai   \n",
       "29  2009 Toyota Innova 2.5 G (Diesel) 7 Seater BS III         Toyota   \n",
       "30                 2017 BMW 5 Series 520d Luxury Line            BMW   \n",
       "31                         2020 Kia Seltos HTK Diesel            Kia   \n",
       "32          2015 Ford Ecosport 1.5 Ti VCT MT Titanium           Ford   \n",
       "33                  2017 Ford Aspire 1.2 Ti-VCT Trend           Ford   \n",
       "34                          2018 Honda Amaze S i-DTEC          Honda   \n",
       "35                           2015 Maruti Alto K10 VXI         Maruti   \n",
       "36                          2018 Honda City i-DTEC SV          Honda   \n",
       "37                     2017 Mahindra XUV500 R W10 FWD       Mahindra   \n",
       "38                               2014 Toyota Etios GD         Toyota   \n",
       "39                  2021 Hyundai Creta SX Diesel BSVI        Hyundai   \n",
       "\n",
       "                                          model  \\\n",
       "0                               2015  Swift VXI   \n",
       "1                          2023  Astor Super MT   \n",
       "2                        2018  Xcent 1.2 VTVT S   \n",
       "3              Used Cars Under 2 Lakh in Nagpur   \n",
       "4              Used Cars Under 3 Lakh in Nagpur   \n",
       "5              Used Cars Under 5 Lakh in Nagpur   \n",
       "6              Used Cars Under 8 Lakh in Nagpur   \n",
       "7             Used Cars Under 10 Lakh in Nagpur   \n",
       "8             Used Cars Above 10 Lakh in Nagpur   \n",
       "9   2014  Ecosport 1.5 DV5 MT Titanium Optional   \n",
       "10                              2022  Kiger RXE   \n",
       "11                     2014  Xcent 1.2 Kappa SX   \n",
       "12                              2012  Brio V MT   \n",
       "13                          2018  WR-V i-VTEC S   \n",
       "14                      2016  CLA 200 CDI Sport   \n",
       "15                                2014  Xylo D4   \n",
       "16                             2015  TUV 300 T8   \n",
       "17           2014  Ecosport 1.5 DV5 MT Titanium   \n",
       "18              2008  Scorpio DX 2.6 Turbo 9Str   \n",
       "19                                2013  Beat LS   \n",
       "20                                2011  Xylo E4   \n",
       "21             Used Cars Under 5 Lakh in Nagpur   \n",
       "22      Used Cars in Nagpur With Search Options   \n",
       "23                    2021  Sonet HTK Plus BSVI   \n",
       "24                   2020  Seltos HTK Plus AT D   \n",
       "25                              2021  Kiger RXZ   \n",
       "26               2020  Rapid 1.5 TDI Style BSIV   \n",
       "27                           2019  Venue E BSIV   \n",
       "28                  2019  Creta 1.4 E Plus CRDi   \n",
       "29  2009  Innova 2.5 G (Diesel) 7 Seater BS III   \n",
       "30              2017  5 Series 520d Luxury Line   \n",
       "31                      2020  Seltos HTK Diesel   \n",
       "32        2015  Ecosport 1.5 Ti VCT MT Titanium   \n",
       "33                2017  Aspire 1.2 Ti-VCT Trend   \n",
       "34                         2018  Amaze S i-DTEC   \n",
       "35                           2015  Alto K10 VXI   \n",
       "36                         2018  City i-DTEC SV   \n",
       "37                       2017  XUV500 R W10 FWD   \n",
       "38                               2014  Etios GD   \n",
       "39                   2021  Creta SX Diesel BSVI   \n",
       "\n",
       "                                           kms_driven  \\\n",
       "0      2015425201520142021470000151324148839646561565   \n",
       "1          202314987552023147007557916718429285435931   \n",
       "2      2025119743020251251000430126442497385495362216   \n",
       "3                                              572202   \n",
       "4                                              813323   \n",
       "5                                             2285535   \n",
       "6                                             1358858   \n",
       "7                                           341010810   \n",
       "8                                           681010105   \n",
       "9   2014370201420132015155120000155684875414007812...   \n",
       "10  2022999549202220212023608005493186732005433230...   \n",
       "11  2014119738020142014201612700003801217236150542...   \n",
       "12  2012119815020122011201372000150271242145415290...   \n",
       "13          20185202018201720206000052125078924963571   \n",
       "14      201615502016200620002001007499114093312981422   \n",
       "15       20144202014437000042168470977743849424265469   \n",
       "16  2015300520153002015201981600003008595056465411...   \n",
       "17  2014440201420132015155120000155364048411655948...   \n",
       "18  2008250200820062009269356000269551316472850135...   \n",
       "19      201317020132009201370000777804819459928263738   \n",
       "20   201123020112008201141600004124130428013123974834   \n",
       "21                                            2285535   \n",
       "22                                             020000   \n",
       "23      202511978202520202024510008298346455904360310   \n",
       "24  2020149312202020192023650001269423992374288292...   \n",
       "25     2021999639202120212023190006393124918295036155   \n",
       "26         202067520201510000015645596545579213378941   \n",
       "27  2019119760520192019202236000605310654641155015...   \n",
       "28  2019139692520192015202014103000925140153824788...   \n",
       "29  2009249432520092004201125792800325257826047950...   \n",
       "30  2017527201752013201752030000552082221241397774487   \n",
       "31  2020149310252020201920231105001025252624164685...   \n",
       "32  2015149942520152013201515430004251594276184210...   \n",
       "33  2017119634020171265000340129577760842428839458...   \n",
       "34  2018570201820162021100000101146327649784401038...   \n",
       "35  2015109982902015102014202079000290107878904425...   \n",
       "36   201841498750201847600075078319733448641680011468   \n",
       "37  2017500217982520175001072000825500109791282854...   \n",
       "38  2025136439020252013201474000390840062727549489...   \n",
       "39        2021125020212020202480000433334399707396161   \n",
       "\n",
       "                                            fuel_type year_of_manufacture  \\\n",
       "0   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2015   \n",
       "1   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2023   \n",
       "2   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2018   \n",
       "3   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2012   \n",
       "4   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2015   \n",
       "5   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2017   \n",
       "6   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2023   \n",
       "7   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "8   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "9   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2014   \n",
       "10  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2022   \n",
       "11  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2014   \n",
       "12  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2012   \n",
       "13  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2018   \n",
       "14  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2016   \n",
       "15  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2014   \n",
       "16  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2015   \n",
       "17  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2014   \n",
       "18  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2008   \n",
       "19  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2013   \n",
       "20  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2011   \n",
       "21  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2015   \n",
       "22  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2023   \n",
       "23  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "24  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2020   \n",
       "25  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "26  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2020   \n",
       "27  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2019   \n",
       "28  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2019   \n",
       "29  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2009   \n",
       "30  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2017   \n",
       "31  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2020   \n",
       "32  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2015   \n",
       "33  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2017   \n",
       "34  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2018   \n",
       "35  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2015   \n",
       "36  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2018   \n",
       "37  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2017   \n",
       "38  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2014   \n",
       "39  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "\n",
       "                                                price  \\\n",
       "0                                          ₹4.25 Lakh   \n",
       "1                         ₹7.55 Lakh with Less Driven   \n",
       "2                          ₹4.30 Lakh with Almost New   \n",
       "3                                             ₹1 Lakh   \n",
       "4                                          ₹2.89 Lakh   \n",
       "5                                          ₹3.25 Lakh   \n",
       "6                                          ₹6.95 Lakh   \n",
       "7                                          ₹8.50 Lakh   \n",
       "8                                            ₹12 Lakh   \n",
       "9                                          ₹3.70 Lakh   \n",
       "10                                         ₹5.49 Lakh   \n",
       "11                                         ₹3.80 Lakh   \n",
       "12                                         ₹1.50 Lakh   \n",
       "13                                         ₹5.20 Lakh   \n",
       "14                                        ₹15.50 Lakh   \n",
       "15                                         ₹4.20 Lakh   \n",
       "16                                            ₹5 Lakh   \n",
       "17                                         ₹4.40 Lakh   \n",
       "18                                         ₹2.50 Lakh   \n",
       "19                                         ₹1.70 Lakh   \n",
       "20                                         ₹2.30 Lakh   \n",
       "21                                         ₹3.25 Lakh   \n",
       "22  ₹1.70 Lakh in Nagpur. The most popular used ca...   \n",
       "23                            ₹8 Lakh with Almost New   \n",
       "24                                           ₹12 Lakh   \n",
       "25                                         ₹6.39 Lakh   \n",
       "26                                         ₹6.75 Lakh   \n",
       "27                                         ₹6.05 Lakh   \n",
       "28                                         ₹9.25 Lakh   \n",
       "29                                         ₹3.25 Lakh   \n",
       "30                                           ₹27 Lakh   \n",
       "31                                        ₹10.25 Lakh   \n",
       "32                                         ₹4.25 Lakh   \n",
       "33                                         ₹3.40 Lakh   \n",
       "34                                         ₹5.70 Lakh   \n",
       "35                                         ₹2.90 Lakh   \n",
       "36                        ₹7.50 Lakh with RC Transfer   \n",
       "37                                         ₹8.25 Lakh   \n",
       "38                         ₹3.90 Lakh with Almost New   \n",
       "39                                        ₹12.50 Lakh   \n",
       "\n",
       "                                              mileage  \\\n",
       "0            47,000 kms • Petrol • Manual • 2nd Owner   \n",
       "1            14,725 kms • Petrol • Manual • 1st Owner   \n",
       "2            51,000 kms • Petrol • Manual • 1st Owner   \n",
       "3   57 used cars Under 2 Lakh are available for sa...   \n",
       "4   81 used cars Under 3 Lakh are available for sa...   \n",
       "5   228 used cars Under 5 Lakh are available for s...   \n",
       "6   135 used cars Under 8 Lakh are available for s...   \n",
       "7   34 used cars Under 10 Lakh are available for s...   \n",
       "8   68 used cars Above 10 Lakh are available for s...   \n",
       "9          1,20,000 kms • Diesel • Manual • 3rd Owner   \n",
       "10           60,765 kms • Petrol • Manual • 1st Owner   \n",
       "11           70,000 kms • Petrol • Manual • 1st Owner   \n",
       "12           72,000 kms • Petrol • Manual • 3rd Owner   \n",
       "13           60,000 kms • Petrol • Manual • 2nd Owner   \n",
       "14        62,000 kms • Diesel • Automatic • 2nd Owner   \n",
       "15         3,70,000 kms • Diesel • Manual • 4th Owner   \n",
       "16         1,60,000 kms • Diesel • Manual • 3rd Owner   \n",
       "17         1,20,000 kms • Diesel • Manual • 2nd Owner   \n",
       "18         3,56,000 kms • Diesel • Manual • 2nd Owner   \n",
       "19           70,000 kms • Petrol • Manual • 1st Owner   \n",
       "20         1,60,000 kms • Diesel • Manual • 2nd Owner   \n",
       "21  228 used cars Under 5 Lakh are available for s...   \n",
       "22                                             000 km   \n",
       "23           51,000 kms • Petrol • Manual • 1st Owner   \n",
       "24        65,000 kms • Diesel • Automatic • 1st Owner   \n",
       "25           19,000 kms • Petrol • Manual • 1st Owner   \n",
       "26         1,00,000 kms • Diesel • Manual • 2nd Owner   \n",
       "27           36,000 kms • Petrol • Manual • 1st Owner   \n",
       "28         1,03,000 kms • Diesel • Manual • 1st Owner   \n",
       "29           92,800 kms • Diesel • Manual • 1st Owner   \n",
       "30        30,000 kms • Diesel • Automatic • 2nd Owner   \n",
       "31         1,10,459 kms • Diesel • Manual • 1st Owner   \n",
       "32           43,000 kms • Petrol • Manual • 2nd Owner   \n",
       "33           65,000 kms • Petrol • Manual • 1st Owner   \n",
       "34         1,00,000 kms • Diesel • Manual • 2nd Owner   \n",
       "35           79,000 kms • Petrol • Manual • 1st Owner   \n",
       "36           76,000 kms • Diesel • Manual • 1st Owner   \n",
       "37           72,000 kms • Diesel • Manual • 2nd Owner   \n",
       "38           74,000 kms • Diesel • Manual • 1st Owner   \n",
       "39           80,000 kms • Diesel • Manual • 1st Owner   \n",
       "\n",
       "                                          detail_page  page  \n",
       "0   https://www.cardekho.com/used-car-details/used...     1  \n",
       "1   https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "2   https://www.cardekho.com/used-car-details/used...     1  \n",
       "3   https://www.cardekho.com/used-cars+0-lakh-to-2...     1  \n",
       "4   https://www.cardekho.com/used-cars+2-lakh-to-3...     1  \n",
       "5   https://www.cardekho.com/used-cars+3-lakh-to-5...     1  \n",
       "6   https://www.cardekho.com/used-cars+5-lakh-to-8...     1  \n",
       "7   https://www.cardekho.com/used-cars+8-lakh-to-1...     1  \n",
       "8   https://www.cardekho.com/used-cars+10-lakh-to-...     1  \n",
       "9   https://www.cardekho.com/used-car-details/used...     1  \n",
       "10  https://www.cardekho.com/used-car-details/used...     1  \n",
       "11  https://www.cardekho.com/used-car-details/used...     1  \n",
       "12  https://www.cardekho.com/used-car-details/used...     1  \n",
       "13  https://www.cardekho.com/used-car-details/used...     1  \n",
       "14  https://www.cardekho.com/used-car-details/used...     1  \n",
       "15  https://www.cardekho.com/used-car-details/used...     1  \n",
       "16  https://www.cardekho.com/used-car-details/used...     1  \n",
       "17  https://www.cardekho.com/used-car-details/used...     1  \n",
       "18  https://www.cardekho.com/used-car-details/used...     1  \n",
       "19  https://www.cardekho.com/used-car-details/used...     1  \n",
       "20  https://www.cardekho.com/used-car-details/used...     1  \n",
       "21  https://www.cardekho.com/used-cars+2-lakh-to-5...     1  \n",
       "22  https://www.cardekho.com/used-cars+0-20000-km+...     1  \n",
       "23  https://www.cardekho.com/used-car-details/used...     1  \n",
       "24  https://www.cardekho.com/used-car-details/used...     1  \n",
       "25  https://www.cardekho.com/used-car-details/used...     1  \n",
       "26  https://www.cardekho.com/used-car-details/used...     1  \n",
       "27  https://www.cardekho.com/used-car-details/used...     1  \n",
       "28  https://www.cardekho.com/used-car-details/used...     1  \n",
       "29  https://www.cardekho.com/used-car-details/used...     1  \n",
       "30  https://www.cardekho.com/used-car-details/used...     1  \n",
       "31  https://www.cardekho.com/used-car-details/used...     1  \n",
       "32  https://www.cardekho.com/used-car-details/used...     1  \n",
       "33  https://www.cardekho.com/used-car-details/used...     1  \n",
       "34  https://www.cardekho.com/used-car-details/used...     1  \n",
       "35  https://www.cardekho.com/used-car-details/used...     1  \n",
       "36  https://www.cardekho.com/used-car-details/used...     1  \n",
       "37  https://www.cardekho.com/used-car-details/used...     1  \n",
       "38  https://www.cardekho.com/used-car-details/used...     1  \n",
       "39  https://www.cardekho.com/used-car-details/used...     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Jupyter cell: Clean Selenium scraper (improved from your first working script) + mileage extraction\n",
    "# Produces: Car_name, brand, model, kms_driven, fuel_type, year_of_manufacture, price, mileage, detail_page\n",
    "# Saves to cardekho_used_cars_hyderabad_clean_fixed.csv and .xlsx\n",
    "# Requirements: selenium, webdriver-manager, beautifulsoup4, pandas, openpyxl\n",
    "\n",
    "import re, time, random, math\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# -------------- CONFIG --------------\n",
    "START_URL = \"https://www.cardekho.com/used-cars+in+nagpur\"\n",
    "OUTPUT_CSV = \"cardekho_used_cars_nagpur_clean_fixed.csv\"\n",
    "OUTPUT_XLSX = \"cardekho_used_cars_nagpur_clean_fixed.xlsx\"\n",
    "HEADLESS = True               # set False to see browser for debugging\n",
    "MAX_PAGES_OVERRIDE = None     # set an int to force more pages, else auto-detect\n",
    "MAX_SCROLL_ROUNDS = 60        # number of scroll attempts per page (increase to load more)\n",
    "SCROLL_PAUSE = 0.6            # seconds between scrolls\n",
    "PAGE_PAUSE = (0.8, 1.6)       # jitter after loading a page\n",
    "# Basic brand list to split brand/model (optional)\n",
    "BRANDS = [\"Maruti\",\"Hyundai\",\"Tata\",\"Honda\",\"Toyota\",\"Mahindra\",\"Kia\",\"BMW\",\"Audi\",\"Mercedes-Benz\",\n",
    "          \"Renault\",\"MG\",\"Skoda\",\"Volkswagen\",\"Ford\",\"Nissan\",\"Jeep\",\"Volvo\",\"Land Rover\",\"Jaguar\",\n",
    "          \"Isuzu\",\"Datsun\",\"Chevrolet\",\"Opel\"]\n",
    "# -------------------------------------\n",
    "\n",
    "# helpers\n",
    "def guess_brand_and_model(title):\n",
    "    if not title: return \"\", \"\"\n",
    "    for b in BRANDS:\n",
    "        if b.lower() in title.lower():\n",
    "            brand = b\n",
    "            model = re.sub(re.escape(b), \"\", title, flags=re.IGNORECASE).strip()\n",
    "            model = re.sub(r'^[\\-\\:\\–\\—\\s]+','', model)\n",
    "            if not model:\n",
    "                model = title\n",
    "            return brand, model\n",
    "    parts = title.split()\n",
    "    return (parts[0], \" \".join(parts[1:])) if parts else (\"\",\"\")\n",
    "\n",
    "def clean_kms(k):\n",
    "    if not k: return \"\"\n",
    "    return re.sub(r'[^\\d\\.]', '', str(k))\n",
    "\n",
    "def find_rupee(text):\n",
    "    m = re.search(r'₹\\s*[\\d\\.,\\sA-Za-z]+', text)\n",
    "    return m.group(0).strip() if m else \"\"\n",
    "\n",
    "def find_kms(text):\n",
    "    m = re.search(r'([\\d,\\.]+)\\s*(?:kms|km)\\b', text, flags=re.I)\n",
    "    return m.group(1).replace(\",\",\"\") if m else \"\"\n",
    "\n",
    "def find_fuel(text):\n",
    "    for f in [\"Petrol\",\"Diesel\",\"CNG\",\"LPG\",\"Electric\",\"Hybrid\"]:\n",
    "        if re.search(r'\\b' + re.escape(f) + r'\\b', text, flags=re.I):\n",
    "            return f\n",
    "    return \"\"\n",
    "\n",
    "def find_year(text):\n",
    "    m = re.search(r'\\b(19|20)\\d{2}\\b', text)\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    "# NEW: mileage extraction helper (looks for kmpl / km/kg / km/kWh / etc.)\n",
    "def extract_mileage(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    txt = text.replace(\"\\xa0\",\" \").strip()\n",
    "    # common patterns like \"18.5 kmpl\", \"22 km/kg\", \"120 km/kWh\"\n",
    "    m = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|km/kg|km/kwh|km/l|kpl|km)', txt, flags=re.I)\n",
    "    if m:\n",
    "        val = m.group(1)\n",
    "        unit = m.group(2)\n",
    "        return f\"{val} {unit}\".strip()\n",
    "    # sometimes \"Mileage: 18.5 kmpl\" or \"18.5kmpl\" or \"ARAI mileage 18 kmpl\"\n",
    "    m2 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|kpl|km/kg|km/kwh|km/l)\\b', txt, flags=re.I)\n",
    "    if m2:\n",
    "        return f\"{m2.group(1)} {m2.group(2)}\"\n",
    "    # also check \"Mileage - 18.5\" followed by unit nearby\n",
    "    m3 = re.search(r'Mileage[:\\-\\s]*([\\d]{1,3}(?:\\.\\d+)?)', txt, flags=re.I)\n",
    "    if m3:\n",
    "        # try to find unit near the number\n",
    "        after = txt[m3.end(): m3.end()+12]\n",
    "        u = re.search(r'(kmpl|kpl|km/kg|km/kwh|km/l)', after, flags=re.I)\n",
    "        if u:\n",
    "            return f\"{m3.group(1)} {u.group(1)}\"\n",
    "        return m3.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Setup Selenium\n",
    "opts = Options()\n",
    "if HEADLESS:\n",
    "    opts.add_argument(\"--headless=new\")\n",
    "opts.add_argument(\"--no-sandbox\")\n",
    "opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "opts.add_argument(\"--window-size=1920,1080\")\n",
    "opts.add_argument(\"--disable-gpu\")\n",
    "# avoid automation flags where possible (helps some sites)\n",
    "opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=opts)\n",
    "\n",
    "try:\n",
    "    driver.get(START_URL)\n",
    "    time.sleep(2.0)\n",
    "\n",
    "    # detect total listings/pages (best-effort)\n",
    "    soup0 = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    text0 = soup0.get_text(\" \", strip=True)\n",
    "    total_listings = None\n",
    "    m = re.search(r'([\\d,]{2,})\\s+Second Hand Cars in Nagpur', text0, flags=re.I)\n",
    "    if not m:\n",
    "        m = re.search(r'of\\s+([\\d,]+)\\s+results', text0, flags=re.I)\n",
    "    if m:\n",
    "        total_listings = int(m.group(1).replace(\",\", \"\"))\n",
    "    per_page_guess = max(1, len(soup0.find_all(\"h3\")))\n",
    "    estimated_pages = math.ceil(total_listings / per_page_guess) if total_listings else None\n",
    "    total_pages = int(estimated_pages) if estimated_pages else 200\n",
    "    if MAX_PAGES_OVERRIDE:\n",
    "        total_pages = MAX_PAGES_OVERRIDE\n",
    "    print(f\"Detected total_listings={total_listings}, per_page_guess={per_page_guess}, total_pages_to_try={total_pages}\")\n",
    "\n",
    "    # --- collect all listing card containers (and their detail links where present) ---\n",
    "    detail_links = []\n",
    "    cards_collected = []\n",
    "    seen_links = set()\n",
    "    seen_keys = set()  # dedupe by title+price\n",
    "\n",
    "    for p in range(1, total_pages + 1):\n",
    "        page_url = START_URL.rstrip(\"/\") + \"?page=\" + str(p)\n",
    "        try:\n",
    "            driver.get(page_url)\n",
    "        except Exception:\n",
    "            time.sleep(1.0)\n",
    "            driver.get(page_url)\n",
    "        # aggressively scroll to trigger lazy-load\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        scroll_round = 0\n",
    "        while scroll_round < MAX_SCROLL_ROUNDS:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(SCROLL_PAUSE + random.random()*0.3)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                # small wiggle to force load\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight-400);\")\n",
    "                time.sleep(0.4)\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(0.4)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "            last_height = new_height\n",
    "            scroll_round += 1\n",
    "\n",
    "        # parse page to find listing *cards*\n",
    "        page_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # Heuristic: cards often contain a title (h3), price (₹) and kms text.\n",
    "        # We'll find all h3/title nodes and then locate the nearest card container around them.\n",
    "        titles = page_soup.find_all(\"h3\")\n",
    "        for h in titles:\n",
    "            title = h.get_text(\" \", strip=True)\n",
    "            if not title:\n",
    "                continue\n",
    "\n",
    "            # climb up parents to find a card-like container (max 6 levels)\n",
    "            parent = h\n",
    "            container_text = \"\"\n",
    "            detail_href = \"\"\n",
    "            for _ in range(6):\n",
    "                if parent is None:\n",
    "                    break\n",
    "                # gather text\n",
    "                txt = parent.get_text(\" \", strip=True)\n",
    "                if \"₹\" in txt or re.search(r'\\b\\d+\\s*(?:kms|km)\\b', txt, flags=re.I):\n",
    "                    container_text = txt\n",
    "                    # also try to find detail link inside this parent container\n",
    "                    a = parent.find(\"a\", href=True)\n",
    "                    if a:\n",
    "                        href = a[\"href\"]\n",
    "                        abs_href = href if \"cardekho.com\" in href else urljoin(page_url, href)\n",
    "                        detail_href = abs_href.split(\"#\")[0].split(\"?utm\")[0]\n",
    "                    break\n",
    "                parent = parent.parent\n",
    "\n",
    "            # fallback: if no container_text found, use h.get_text plus parent.get_text\n",
    "            if not container_text:\n",
    "                parent = h.parent\n",
    "                container_text = parent.get_text(\" \", strip=True) if parent else h.get_text(\" \", strip=True)\n",
    "\n",
    "            # ensure it's likely a listing: should have price or kms or both\n",
    "            if (\"₹\" not in container_text) and (re.search(r'\\b\\d+\\s*(?:kms|km)\\b', container_text, flags=re.I) is None):\n",
    "                continue\n",
    "\n",
    "            price = find_rupee(container_text)\n",
    "            kms = find_kms(container_text)\n",
    "            fuel = find_fuel(container_text)\n",
    "            year = find_year(title) or find_year(container_text)\n",
    "            mileage = extract_mileage(container_text)  # <-- extract mileage from card text\n",
    "\n",
    "            brand, model = guess_brand_and_model(title)\n",
    "\n",
    "            # dedupe key\n",
    "            unique_key = (title + \"||\" + (price or \"\")).strip()\n",
    "            if unique_key in seen_keys:\n",
    "                continue\n",
    "            seen_keys.add(unique_key)\n",
    "\n",
    "            if detail_href and detail_href not in seen_links:\n",
    "                seen_links.add(detail_href)\n",
    "            # append raw row (text-based) including mileage\n",
    "            cards_collected.append({\n",
    "                \"Car_name\": title,\n",
    "                \"brand\": brand,\n",
    "                \"model\": model,\n",
    "                \"kms_driven\": kms.replace(\",\",\"\"),\n",
    "                \"fuel_type\": fuel,\n",
    "                \"year_of_manufacture\": year,\n",
    "                \"price\": price,\n",
    "                \"mileage\": mileage,\n",
    "                \"detail_page\": detail_href,\n",
    "                \"page\": p\n",
    "            })\n",
    "\n",
    "        # small pause\n",
    "        time.sleep(random.uniform(*PAGE_PAUSE))\n",
    "\n",
    "        # early stop if we've collected at least detected total_listings\n",
    "        if total_listings and len(seen_keys) >= total_listings:\n",
    "            print(\"Collected detected total_listings, stopping page scan.\")\n",
    "            break\n",
    "\n",
    "        # small progress print every 10 pages\n",
    "        if p % 10 == 0:\n",
    "            print(f\"Scanned page {p}; collected cards so far: {len(cards_collected)}\")\n",
    "\n",
    "    print(f\"Initial collection done: {len(cards_collected)} card rows, detail links discovered: {len(seen_links)}\")\n",
    "\n",
    "    # If detail links exist, visit each detail page to extract more reliable fields (optional but recommended)\n",
    "    # We'll visit only pages that either lack kms/fuel/year/price/mileage to improve data quality.\n",
    "    # This block is slower; set visit_details=False to skip.\n",
    "    visit_details = True\n",
    "    improved_rows = []\n",
    "    visited = 0\n",
    "\n",
    "    if visit_details and len(seen_links) > 0:\n",
    "        for idx, row in enumerate(cards_collected):\n",
    "            # decide whether to open detail page: if any of main fields missing or no detail link present\n",
    "            need_detail = False\n",
    "            if not row[\"kms_driven\"] or not row[\"fuel_type\"] or not row[\"price\"] or not row[\"year_of_manufacture\"] or not row.get(\"mileage\"):\n",
    "                need_detail = True\n",
    "            if row[\"detail_page\"]:\n",
    "                detail_url = row[\"detail_page\"]\n",
    "            else:\n",
    "                detail_url = None\n",
    "            if not need_detail and detail_url:\n",
    "                # keep as is\n",
    "                improved_rows.append(row)\n",
    "                continue\n",
    "\n",
    "            if detail_url:\n",
    "                try:\n",
    "                    # open detail page\n",
    "                    driver.get(detail_url)\n",
    "                    # wait short while\n",
    "                    time.sleep(1.0 + random.random()*0.8)\n",
    "                    dsoup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                    page_text = dsoup.get_text(\" \", strip=True)\n",
    "\n",
    "                    # Title from h1/h2 if present\n",
    "                    ttag = dsoup.find([\"h1\",\"h2\"])\n",
    "                    if ttag:\n",
    "                        title_det = ttag.get_text(\" \", strip=True)\n",
    "                        if title_det:\n",
    "                            row[\"Car_name\"] = title_det\n",
    "                            brand, model = guess_brand_and_model(title_det)\n",
    "                            row[\"brand\"] = brand\n",
    "                            row[\"model\"] = model\n",
    "\n",
    "                    # Try to find labeled values first (reliable)\n",
    "                    # Kms (look for label 'Kms Driven' or 'Kms')\n",
    "                    label_kms = dsoup.find(text=re.compile(r'Kms\\s*Driven|Kms|Odometer', flags=re.I))\n",
    "                    if label_kms:\n",
    "                        try:\n",
    "                            val = label_kms.parent.find_next_sibling()\n",
    "                            if val:\n",
    "                                k = re.sub(r'[^\\d]', '', val.get_text(\" \", strip=True))\n",
    "                                if k:\n",
    "                                    row[\"kms_driven\"] = k\n",
    "                        except:\n",
    "                            pass\n",
    "                    # fallback to page text\n",
    "                    if not row[\"kms_driven\"]:\n",
    "                        kf = find_kms(page_text)\n",
    "                        if kf:\n",
    "                            row[\"kms_driven\"] = kf\n",
    "\n",
    "                    # fuel type label\n",
    "                    label_fuel = dsoup.find(text=re.compile(r'Fuel\\s*Type|Fuel', flags=re.I))\n",
    "                    if label_fuel:\n",
    "                        try:\n",
    "                            val = label_fuel.parent.find_next_sibling()\n",
    "                            if val:\n",
    "                                row[\"fuel_type\"] = val.get_text(\" \", strip=True)\n",
    "                        except:\n",
    "                            pass\n",
    "                    if not row[\"fuel_type\"]:\n",
    "                        ff = find_fuel(page_text)\n",
    "                        if ff:\n",
    "                            row[\"fuel_type\"] = ff\n",
    "\n",
    "                    # year\n",
    "                    label_year = dsoup.find(text=re.compile(r'Year\\s*of\\s*Manufacture|Registration\\s*Year|Year', flags=re.I))\n",
    "                    if label_year:\n",
    "                        try:\n",
    "                            val = label_year.parent.find_next_sibling()\n",
    "                            if val:\n",
    "                                yy = find_year(val.get_text(\" \", strip=True))\n",
    "                                if yy:\n",
    "                                    row[\"year_of_manufacture\"] = yy\n",
    "                        except:\n",
    "                            pass\n",
    "                    if not row[\"year_of_manufacture\"]:\n",
    "                        yy = find_year(row[\"Car_name\"]) or find_year(page_text)\n",
    "                        if yy:\n",
    "                            row[\"year_of_manufacture\"] = yy\n",
    "\n",
    "                    # price\n",
    "                    pr = find_rupee(page_text)\n",
    "                    if pr:\n",
    "                        row[\"price\"] = pr\n",
    "\n",
    "                    # MILEAGE extraction on detail page: labeled field or meta-line or page-wide fallback\n",
    "                    mileage_val = \"\"\n",
    "                    # 1) labeled field 'Mileage' or 'Avg. Mileage'\n",
    "                    mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
    "                    if mnode:\n",
    "                        try:\n",
    "                            parent = mnode.parent\n",
    "                            sib = parent.find_next_sibling()\n",
    "                            if sib:\n",
    "                                mileage_val = sib.get_text(\" \", strip=True)\n",
    "                        except:\n",
    "                            mileage_val = \"\"\n",
    "                    # 2) try meta-line near title\n",
    "                    if not mileage_val and ttag:\n",
    "                        nxt = ttag.find_next()\n",
    "                        checks = 0\n",
    "                        while nxt and checks < 8:\n",
    "                            txt = nxt.get_text(\" \", strip=True)\n",
    "                            if txt and ((\"kms\" in txt.lower()) or re.search(r'\\b\\d+\\s*(?:kmpl|km/kg|km/kwh|km/l|kpl)\\b', txt, flags=re.I)):\n",
    "                                mileage_val = txt\n",
    "                                break\n",
    "                            nxt = nxt.find_next()\n",
    "                            checks += 1\n",
    "                    # 3) fallback to page_text extraction\n",
    "                    if not mileage_val:\n",
    "                        mileage_val = extract_mileage(page_text)\n",
    "\n",
    "                    # normalize mileage\n",
    "                    if mileage_val:\n",
    "                        row[\"mileage\"] = mileage_val\n",
    "\n",
    "                except Exception as e:\n",
    "                    # if detail fetch fails, keep earlier extracted values\n",
    "                    pass\n",
    "\n",
    "                # tiny sleep between detail visits\n",
    "                time.sleep(random.uniform(0.35, 0.9))\n",
    "            improved_rows.append(row)\n",
    "            visited += 1\n",
    "\n",
    "            # checkpoint: save every 200 detail pages processed\n",
    "            if visited % 200 == 0:\n",
    "                df_ck = pd.DataFrame(improved_rows)\n",
    "                df_ck = df_ck.drop_duplicates(subset=[\"detail_page\",\"Car_name\",\"price\"])\n",
    "                df_ck.to_csv(OUTPUT_CSV, index=False)\n",
    "                df_ck.to_excel(OUTPUT_XLSX, index=False)\n",
    "                print(f\"Checkpoint saved after {visited} detail visits: {len(df_ck)} rows.\")\n",
    "\n",
    "    else:\n",
    "        improved_rows = cards_collected\n",
    "\n",
    "    # Final cleaning + dedupe\n",
    "    df = pd.DataFrame(improved_rows)\n",
    "    # normalize strings and numeric kms\n",
    "    for c in [\"Car_name\",\"brand\",\"model\",\"fuel_type\",\"price\",\"detail_page\",\"mileage\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna(\"\").astype(str).str.strip()\n",
    "    df[\"kms_driven\"] = df[\"kms_driven\"].apply(lambda x: clean_kms(x) if x else \"\")\n",
    "    df[\"year_of_manufacture\"] = df[\"year_of_manufacture\"].apply(lambda x: find_year(str(x)) if x else \"\")\n",
    "\n",
    "    # dedupe by detail_page if present else by Car_name+price\n",
    "    if \"detail_page\" in df.columns and df[\"detail_page\"].str.len().sum() > 0:\n",
    "        df = df.drop_duplicates(subset=[\"detail_page\"]).reset_index(drop=True)\n",
    "    else:\n",
    "        df = df.drop_duplicates(subset=[\"Car_name\",\"price\"]).reset_index(drop=True)\n",
    "\n",
    "    # Save\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    df.to_excel(OUTPUT_XLSX, index=False)\n",
    "    print(f\"Saved cleaned output: {OUTPUT_CSV} and {OUTPUT_XLSX}\")\n",
    "    print(\"Total rows collected:\", len(df))\n",
    "    display(df.head(40))\n",
    "\n",
    "finally:\n",
    "    try:\n",
    "        driver.quit()\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf4405-fbd2-4b9c-8c47-fd6c61af5281",
   "metadata": {},
   "source": [
    "4th Stage of Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f79a439-f3ef-45a2-9c2d-1c1b55df1b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 517 rows from cardekho_used_cars_nagpur_price_fixed.xlsx\n",
      "Rows flagged for repair: 41 (will visit detail pages)\n",
      "[1/41] Updated idx=0: mileage='000 km' transmission='Manual'\n",
      "[2/41] Updated idx=1: mileage='725 km' transmission='Manual'\n",
      "[3/41] Updated idx=2: mileage='765 km' transmission='Manual'\n",
      "[4/41] Updated idx=3: mileage='57' transmission='AT'\n",
      "[5/41] Updated idx=4: mileage='80' transmission='AT'\n",
      "[6/41] Updated idx=5: mileage='228' transmission='AT'\n",
      "[7/41] Updated idx=6: mileage='135' transmission='AT'\n",
      "[8/41] Updated idx=7: mileage='34' transmission='AT'\n",
      "[9/41] Updated idx=8: mileage='68' transmission='AT'\n",
      "[10/41] Updated idx=9: mileage='552 km' transmission='Manual'\n",
      "[11/41] Updated idx=10: mileage='000 km' transmission='Manual'\n",
      "[12/41] Updated idx=11: mileage='000 km' transmission='Automatic'\n",
      "[13/41] Updated idx=12: mileage='000 km' transmission='Manual'\n",
      "[14/41] Updated idx=13: mileage='800 km' transmission='Manual'\n",
      "[15/41] Updated idx=14: mileage='000 km' transmission='Manual'\n",
      "[16/41] Updated idx=15: mileage='000 km' transmission='Manual'\n",
      "[17/41] Updated idx=16: mileage='000 km' transmission='Automatic'\n",
      "[18/41] Updated idx=17: mileage='000 km' transmission='Automatic'\n",
      "[19/41] Updated idx=18: mileage='000 km' transmission='Manual'\n",
      "[20/41] Updated idx=19: mileage='000 km' transmission='Manual'\n",
      "[21/41] Updated idx=20: mileage='000 km' transmission='Manual'\n",
      "[22/41] Updated idx=21: mileage='000 km' transmission='Manual'\n",
      "[23/41] Updated idx=22: mileage='000 km' transmission='Manual'\n",
      "[24/41] Updated idx=23: mileage='228' transmission='AT'\n",
      "[25/41] Updated idx=24: mileage='11.50' transmission='There are 33 second-hand cars in Nagpur currently available for sale of brands like Maruti , Hyundai , Tata , Mahindra , Toyota , Renault . Used/Old cars price start from ₹1.70 Lakh in Nagpur. The most popular used cars are in Nagpur Maruti Swift (₹1.20 Lakh - ₹7.50 Lakh), Audi A4 (₹5.85 Lakh - ₹23 Lakh), Skoda Kodiaq (₹21 Lakh), Toyota Fortuner (₹8.75 Lakh - ₹42 Lakh), Mahindra XUV500 (₹4.55 Lakh - ₹11.50 Lakh).To know more about used cars prices, photos, mileage, reviews, and other details, please select your desired model from the list below, Also check used car valuation on CarDekho. Top 5 Used Cars in Nagpur Used Cars Price List Second Hand Cars Price in Nagpur Maruti Swift ₹ 1.20 Lakh - ₹ 7.50 Lakh* Audi A4 ₹ 5.85 Lakh - ₹ 23 Lakh* Skoda Kodiaq ₹ 21 Lakh* Toyota Fortuner ₹ 8.75 Lakh - ₹ 42 Lakh* Mahindra XUV500 ₹ 4.55 Lakh - ₹ 11.50 Lakh* Read More'\n",
      "[26/41] Updated idx=25: mileage='000 km' transmission='Manual'\n",
      "[27/41] Updated idx=26: mileage='000 km' transmission='Manual'\n",
      "[28/41] Updated idx=27: mileage='000 km' transmission='Manual'\n",
      "[29/41] Updated idx=28: mileage='000 km' transmission='Manual'\n",
      "[30/41] Updated idx=29: mileage='469 km' transmission='Manual'\n",
      "[31/41] Updated idx=30: mileage='000 km' transmission='Automatic'\n",
      "[32/41] Updated idx=31: mileage='000 km' transmission='Automatic'\n",
      "[33/41] Updated idx=32: mileage='000 km' transmission='Manual'\n",
      "[34/41] Updated idx=33: mileage='129 km' transmission='Manual'\n",
      "[35/41] Updated idx=34: mileage='000 km' transmission='Manual'\n",
      "[36/41] Updated idx=35: mileage='000 km' transmission='Manual'\n",
      "[37/41] Updated idx=36: mileage='000 km' transmission='Automatic'\n",
      "[38/41] Updated idx=37: mileage='3.79' transmission='There are 11 second-hand cars in Nagpur currently available for sale of brands like Maruti , Hyundai , Tata , Mahindra , Honda , Toyota . Used/Old cars price start from ₹1.49 Lakh in Nagpur. The most popular used cars are in Nagpur Ford Figo (₹1.49 Lakh - ₹3.79 Lakh).To know more about used cars prices, photos, mileage, reviews, and other details, please select your desired model from the list below, Also check used car valuation on CarDekho. Top 1 Used Cars in Nagpur Used Cars Price List Second Hand Cars Price in Nagpur Ford Figo ₹ 1.49 Lakh - ₹ 3.79 Lakh* Read More'\n",
      "[39/41] Updated idx=38: mileage='000 km' transmission='Automatic'\n",
      "[40/41] Updated idx=39: mileage='000 km' transmission='Manual'\n",
      "[41/41] Failed to load: nan\n",
      "Done. Updated 40 rows. Saved cleaned file to:\n",
      " - cardekho_used_cars_nagpur_price_fixed_cleaned.xlsx\n",
      " - cardekho_used_cars_nagpur_price_fixed_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Jupyter cell: Repair mileage & transmission for existing Cardekho file\n",
    "# - Loads /mnt/data/cardekho_used_cars_hyderabad_price_fixed.xlsx\n",
    "# - Visits detail_page for rows missing/invalid mileage or transmission\n",
    "# - Writes back cleaned file (CSV + XLSX)\n",
    "# Requirements: selenium, webdriver-manager, beautifulsoup4, pandas, openpyxl\n",
    "\n",
    "import re, time, random, os\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "INPUT_XLSX = \"cardekho_used_cars_nagpur_price_fixed.xlsx\"\n",
    "OUTPUT_XLSX = \"cardekho_used_cars_nagpur_price_fixed_cleaned.xlsx\"\n",
    "OUTPUT_CSV = \"cardekho_used_cars_nagpur_price_fixed_cleaned.csv\"\n",
    "\n",
    "HEADLESS = True                # set False to watch browser\n",
    "DELAY_BETWEEN = (0.6, 1.2)     # polite per-page pause\n",
    "CHECKPOINT_EVERY = 50          # save every N updated rows\n",
    "MAX_RETRIES = 1\n",
    "# --------------------------------\n",
    "\n",
    "if not os.path.exists(INPUT_XLSX):\n",
    "    raise FileNotFoundError(f\"Input file not found: {INPUT_XLSX}. Put your file at this path and re-run.\")\n",
    "\n",
    "# --- utility functions ---\n",
    "def text_of(elem):\n",
    "    return elem.get_text(\" \", strip=True) if elem else \"\"\n",
    "\n",
    "def normalize_mileage(raw):\n",
    "    if not raw:\n",
    "        return \"\"\n",
    "    s = str(raw).strip()\n",
    "    s = s.replace(\"\\xa0\",\" \").replace(\"\\n\",\" \").strip()\n",
    "    # try to capture number + unit (common)\n",
    "    m = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|kpl|km/kg|km/kwh|km/l|km|mpg)', s, flags=re.I)\n",
    "    if m:\n",
    "        val = m.group(1)\n",
    "        unit = m.group(2).lower()\n",
    "        # normalize unit names\n",
    "        unit = unit.replace(\"kpl\",\"kmpl\").replace(\"km/l\",\"kmpl\")\n",
    "        return f\"{val} {unit}\"\n",
    "    # tries like \"18.5\" then search for unit nearby\n",
    "    m2 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)', s)\n",
    "    if m2:\n",
    "        # if no unit, just return number\n",
    "        return m2.group(1)\n",
    "    return s\n",
    "\n",
    "def normalize_transmission(raw):\n",
    "    if not raw:\n",
    "        return \"\"\n",
    "    s = str(raw)\n",
    "    for t in [\"AMT\",\"CVT\",\"DCT\",\"AT\",\"MT\",\"Manual\",\"Automatic\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', s, flags=re.I):\n",
    "            # canonicalize\n",
    "            if t.upper() in (\"AMT\",\"CVT\",\"DCT\",\"AT\",\"MT\"):\n",
    "                return t.upper()\n",
    "            return t.title()\n",
    "    # last resort: find words\n",
    "    if re.search(r'\\bmanual\\b', s, flags=re.I):\n",
    "        return \"Manual\"\n",
    "    if re.search(r'\\bautomatic\\b', s, flags=re.I):\n",
    "        return \"Automatic\"\n",
    "    return s.strip()\n",
    "\n",
    "def extract_mileage_from_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # 1) direct patterns e.g. \"18.5 kmpl\"\n",
    "    m = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|kpl|km/kg|km/kwh|km/l|km|mpg)\\b', text, flags=re.I)\n",
    "    if m:\n",
    "        unit = m.group(2).lower().replace(\"kpl\",\"kmpl\").replace(\"km/l\",\"kmpl\")\n",
    "        return f\"{m.group(1)} {unit}\"\n",
    "    # 2) near 'mileage' keyword: capture window +/- 60 chars\n",
    "    for keyword in [\"mileage\",\"avg. mileage\",\"avg mileage\",\"city mileage\",\"claimed mileage\",\"average mileage\"]:\n",
    "        idx = text.lower().find(keyword)\n",
    "        if idx != -1:\n",
    "            start = max(0, idx-60)\n",
    "            end = min(len(text), idx+80)\n",
    "            ctx = text[start:end]\n",
    "            m2 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|kpl|km/kg|km/kwh|km/l|km|mpg)\\b', ctx, flags=re.I)\n",
    "            if m2:\n",
    "                unit = m2.group(2).lower().replace(\"kpl\",\"kmpl\").replace(\"km/l\",\"kmpl\")\n",
    "                return f\"{m2.group(1)} {unit}\"\n",
    "            # number only\n",
    "            m3 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)', ctx)\n",
    "            if m3:\n",
    "                return m3.group(1)\n",
    "    # 3) any number+unit elsewhere\n",
    "    m4 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|kpl|km/kg|km/kwh|km/l|km|mpg)\\b', text, flags=re.I)\n",
    "    if m4:\n",
    "        unit = m4.group(2).lower().replace(\"kpl\",\"kmpl\").replace(\"km/l\",\"kmpl\")\n",
    "        return f\"{m4.group(1)} {unit}\"\n",
    "    return \"\"\n",
    "\n",
    "def extract_trans_from_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # look for label/context words\n",
    "    for t in [\"Manual\",\"Automatic\",\"AMT\",\"CVT\",\"DCT\",\"AT\",\"MT\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', text, flags=re.I):\n",
    "            return normalize_transmission(t)\n",
    "    # also search near keywords 'transmission' or 'gearbox'\n",
    "    idx = text.lower().find(\"transmission\")\n",
    "    if idx == -1:\n",
    "        idx = text.lower().find(\"gearbox\")\n",
    "    if idx != -1:\n",
    "        start = max(0, idx-40)\n",
    "        end = min(len(text), idx+80)\n",
    "        ctx = text[start:end]\n",
    "        for t in [\"Manual\",\"Automatic\",\"AMT\",\"CVT\",\"DCT\",\"AT\",\"MT\"]:\n",
    "            if re.search(r'\\b' + re.escape(t) + r'\\b', ctx, flags=re.I):\n",
    "                return normalize_transmission(t)\n",
    "        # fallback to any word in ctx\n",
    "        m = re.search(r'\\b(Manual|Automatic|AMT|CVT|DCT|AT|MT)\\b', ctx, flags=re.I)\n",
    "        if m:\n",
    "            return normalize_transmission(m.group(1))\n",
    "    return \"\"\n",
    "\n",
    "# ----------------- load dataset -----------------\n",
    "df = pd.read_excel(INPUT_XLSX)\n",
    "print(f\"Loaded {len(df)} rows from {INPUT_XLSX}\")\n",
    "\n",
    "# identify rows that need fixing:\n",
    "# Criteria: mileage empty OR transmission empty OR mileage looks like URL/junk (contains 'http' or '/')\n",
    "def mileage_is_bad(val):\n",
    "    if not val or str(val).strip() == \"\":\n",
    "        return True\n",
    "    s = str(val).lower()\n",
    "    if \"http\" in s or \"/\" in s and len(s) > 10:   # simplistic junk heuristics\n",
    "        return True\n",
    "    # if it's non-numeric and non-unit, mark for check\n",
    "    if not re.search(r'\\d', s):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def transmission_is_bad(val):\n",
    "    if not val or str(val).strip() == \"\":\n",
    "        return True\n",
    "    s = str(val)\n",
    "    if re.search(r'http|\\/', s):\n",
    "        return True\n",
    "    # ok if contains known token\n",
    "    if re.search(r'\\b(Manual|Automatic|AMT|CVT|DCT|AT|MT)\\b', s, flags=re.I):\n",
    "        return False\n",
    "    return False  # conservative: if present assume ok\n",
    "\n",
    "# build list of indices to fix\n",
    "to_fix_idx = []\n",
    "for i, row in df.iterrows():\n",
    "    mismatch = False\n",
    "    if mileage_is_bad(row.get(\"mileage\", \"\")):\n",
    "        mismatch = True\n",
    "    if transmission_is_bad(row.get(\"transmission\", \"\")):\n",
    "        mismatch = True\n",
    "    # we will only attempt to fix those that have a valid detail_page URL\n",
    "    if mismatch and row.get(\"detail_page\"):\n",
    "        to_fix_idx.append(i)\n",
    "\n",
    "print(f\"Rows flagged for repair: {len(to_fix_idx)} (will visit detail pages)\")\n",
    "\n",
    "if len(to_fix_idx) == 0:\n",
    "    print(\"No rows need fixing. Exiting.\")\n",
    "else:\n",
    "    # Setup Selenium (headful or headless)\n",
    "    opts = Options()\n",
    "    if HEADLESS:\n",
    "        opts.add_argument(\"--headless=new\")\n",
    "    opts.add_argument(\"--no-sandbox\")\n",
    "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    opts.add_argument(\"--window-size=1200,900\")\n",
    "    opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)\n",
    "\n",
    "    updated = 0\n",
    "    try:\n",
    "        for batch_i, idx in enumerate(to_fix_idx, start=1):\n",
    "            row = df.loc[idx]\n",
    "            url = str(row.get(\"detail_page\")).strip()\n",
    "            if not url:\n",
    "                continue\n",
    "            # polite jitter\n",
    "            time.sleep(random.uniform(*DELAY_BETWEEN))\n",
    "            # fetch page\n",
    "            success = False\n",
    "            for attempt in range(MAX_RETRIES+1):\n",
    "                try:\n",
    "                    driver.get(url)\n",
    "                    # let JS run and content load\n",
    "                    time.sleep(1.0 + random.random()*0.8)\n",
    "                    page_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                    page_text = page_soup.get_text(\" \", strip=True)\n",
    "                    success = True\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    if attempt < MAX_RETRIES:\n",
    "                        time.sleep(0.6)\n",
    "                        continue\n",
    "                    else:\n",
    "                        success = False\n",
    "            if not success:\n",
    "                print(f\"[{batch_i}/{len(to_fix_idx)}] Failed to load: {url}\")\n",
    "                continue\n",
    "\n",
    "            # MULTIPLE extraction strategies, most-specific -> fallback\n",
    "            new_mileage = \"\"\n",
    "            new_trans = \"\"\n",
    "\n",
    "            # Strategy A: labeled dt/dd or table tr (common structure)\n",
    "            # dt/dd\n",
    "            try:\n",
    "                dts = page_soup.find_all(\"dt\")\n",
    "                if dts:\n",
    "                    for dt in dts:\n",
    "                        label = text_of(dt).lower()\n",
    "                        if \"mile\" in label:\n",
    "                            dd = dt.find_next_sibling(\"dd\")\n",
    "                            if dd:\n",
    "                                cand = text_of(dd)\n",
    "                                if cand:\n",
    "                                    new_mileage = extract_mileage_from_text(cand) or normalize_mileage(cand)\n",
    "                        if \"trans\" in label or \"gear\" in label:\n",
    "                            dd = dt.find_next_sibling(\"dd\")\n",
    "                            if dd:\n",
    "                                new_trans = extract_trans_from_text(text_of(dd)) or normalize_transmission(text_of(dd))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Strategy B: table rows <tr><th>Label</th><td>Value</td>\n",
    "            if not new_mileage or not new_trans:\n",
    "                try:\n",
    "                    for tr in page_soup.find_all(\"tr\"):\n",
    "                        th = tr.find([\"th\",\"td\"])\n",
    "                        tlabel = text_of(th).lower() if th else \"\"\n",
    "                        tvals = [text_of(x) for x in tr.find_all(\"td\")]\n",
    "                        tval = tvals[0] if tvals else \"\"\n",
    "                        if not new_mileage and (\"mileage\" in tlabel or \"avg\" in tlabel and \"mileage\" in tlabel):\n",
    "                            new_mileage = extract_mileage_from_text(tval) or normalize_mileage(tval)\n",
    "                        if not new_trans and (\"transmission\" in tlabel or \"gearbox\" in tlabel or \"gear\" in tlabel):\n",
    "                            new_trans = extract_trans_from_text(tval) or normalize_transmission(tval)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Strategy C: look for elements with class/id containing keywords\n",
    "            if not new_mileage:\n",
    "                try:\n",
    "                    mileage_nodes = page_soup.find_all(attrs={\"class\": re.compile(r\"mile|mileage|avg-mile|avgMileage\", flags=re.I)})\n",
    "                    for n in mileage_nodes:\n",
    "                        cand = text_of(n)\n",
    "                        cand_val = extract_mileage_from_text(cand) or normalize_mileage(cand)\n",
    "                        if cand_val:\n",
    "                            new_mileage = cand_val\n",
    "                            break\n",
    "                except Exception:\n",
    "                    pass\n",
    "            if not new_trans:\n",
    "                try:\n",
    "                    trans_nodes = page_soup.find_all(attrs={\"class\": re.compile(r\"trans|gear|gearbox\", flags=re.I)})\n",
    "                    for n in trans_nodes:\n",
    "                        cand = text_of(n)\n",
    "                        cand_val = extract_trans_from_text(cand) or normalize_transmission(cand)\n",
    "                        if cand_val:\n",
    "                            new_trans = cand_val\n",
    "                            break\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Strategy D: meta / data- attributes (rare)\n",
    "            if not new_mileage:\n",
    "                try:\n",
    "                    mtag = page_soup.find(\"meta\", attrs={\"name\": re.compile(r\"mileage\", flags=re.I)})\n",
    "                    if mtag and mtag.get(\"content\"):\n",
    "                        cand = mtag.get(\"content\")\n",
    "                        new_mileage = extract_mileage_from_text(cand) or normalize_mileage(cand)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Strategy E: near-title meta-line (many Cardekho detail pages show compact specs after title)\n",
    "            if not new_mileage or not new_trans:\n",
    "                try:\n",
    "                    htag = page_soup.find([\"h1\",\"h2\"])\n",
    "                    if htag:\n",
    "                        nxt = htag.find_next()\n",
    "                        checks = 0\n",
    "                        while nxt and checks < 10:\n",
    "                            txt = text_of(nxt)\n",
    "                            if txt and ((\"kms\" in txt.lower()) or (\"kmpl\" in txt.lower()) or (\"mileage\" in txt.lower()) or (\"transmission\" in txt.lower()) or (\"gear\" in txt.lower())):\n",
    "                                if not new_mileage:\n",
    "                                    new_mileage = extract_mileage_from_text(txt) or normalize_mileage(txt)\n",
    "                                if not new_trans:\n",
    "                                    new_trans = extract_trans_from_text(txt) or normalize_transmission(txt)\n",
    "                                break\n",
    "                            nxt = nxt.find_next()\n",
    "                            checks += 1\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Strategy F: page-wide regex fallback (last resort)\n",
    "            if not new_mileage:\n",
    "                new_mileage = extract_mileage_from_text(page_text)\n",
    "            if not new_trans:\n",
    "                new_trans = extract_trans_from_text(page_text)\n",
    "\n",
    "            # Final normalization\n",
    "            new_mileage = normalize_mileage(new_mileage)\n",
    "            new_trans = normalize_transmission(new_trans)\n",
    "\n",
    "            # If still empty, try card-level existing values as fallback (do not overwrite good existing)\n",
    "            existing_mileage = df.at[idx, \"mileage\"] if \"mileage\" in df.columns else \"\"\n",
    "            existing_trans = df.at[idx, \"transmission\"] if \"transmission\" in df.columns else \"\"\n",
    "            if not new_mileage and existing_mileage and not mileage_is_bad(existing_mileage):\n",
    "                new_mileage = existing_mileage\n",
    "            if not new_trans and existing_trans and existing_trans.strip():\n",
    "                new_trans = existing_trans\n",
    "\n",
    "            # write back if changed\n",
    "            changed = False\n",
    "            if new_mileage and (str(df.at[idx, \"mileage\"]) != new_mileage):\n",
    "                df.at[idx, \"mileage\"] = new_mileage\n",
    "                changed = True\n",
    "            if new_trans and (str(df.at[idx, \"transmission\"]) != new_trans):\n",
    "                df.at[idx, \"transmission\"] = new_trans\n",
    "                changed = True\n",
    "\n",
    "            if changed:\n",
    "                updated += 1\n",
    "                print(f\"[{batch_i}/{len(to_fix_idx)}] Updated idx={idx}: mileage='{new_mileage}' transmission='{new_trans}'\")\n",
    "            else:\n",
    "                print(f\"[{batch_i}/{len(to_fix_idx)}] No new data for idx={idx}\")\n",
    "\n",
    "            # checkpointing\n",
    "            if updated and updated % CHECKPOINT_EVERY == 0:\n",
    "                df.to_csv(OUTPUT_CSV, index=False)\n",
    "                df.to_excel(OUTPUT_XLSX, index=False)\n",
    "                print(f\"Checkpoint saved after {updated} updates.\")\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # final save\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    df.to_excel(OUTPUT_XLSX, index=False)\n",
    "    print(f\"Done. Updated {updated} rows. Saved cleaned file to:\\n - {OUTPUT_XLSX}\\n - {OUTPUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af252ab-d5cc-4b70-b61f-3d80122c953d",
   "metadata": {},
   "source": [
    "5th Stage of Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f24b9a12-6ee7-45a0-a036-abef60b589cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected total_listings=602, per_page_guess=64, total_pages=10\n",
      "Scanned page 10; rows so far: 535\n",
      "Collected 535 card-level rows, detail links: 518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_46520\\1512990343.py:461: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_46520\\1512990343.py:476: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 detail pages...\n",
      "Processed 200 detail pages...\n",
      "Processed 300 detail pages...\n",
      "Processed 400 detail pages...\n",
      "Processed 500 detail pages...\n",
      "Saved 519 rows to cardekho_used_cars_nagpur_price_fixed.csv and cardekho_used_cars_nagpur_price_fixed.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "cardekho_with_price_fix.py\n",
    "\n",
    "Improved scraper for CarDekho used cars (Hyderabad) with robust price extraction.\n",
    "Only mileage logic improved — rest unchanged.\n",
    "Requires: selenium, webdriver-manager, beautifulsoup4, pandas, openpyxl\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ---------------------------\n",
    "# Path to uploaded file (local). Use this path if you want to read the previously saved file.\n",
    "# Downstream systems can convert this local path into a downloadable URL if needed.\n",
    "UPLOADED_FILE_PATH = \"cardekho_used_cars_nagpur_price_fixed_cleaned.xlsx\"\n",
    "# ---------------------------\n",
    "\n",
    "# -------- CONFIG ----------\n",
    "START_URL = \"https://www.cardekho.com/used-cars+in+nagpur\"\n",
    "OUTPUT_CSV = \"cardekho_used_cars_nagpur_price_fixed.csv\"\n",
    "OUTPUT_XLSX = \"cardekho_used_cars_nagpur_price_fixed.xlsx\"\n",
    "\n",
    "HEADLESS = True\n",
    "MAX_PAGES_OVERRIDE = None\n",
    "MAX_SCROLLS = 40\n",
    "SCROLL_PAUSE = 0.7\n",
    "PAGE_PAUSE = (0.6, 1.4)\n",
    "VISIT_DETAIL_PAGES = True\n",
    "DETAIL_PAUSE = (0.6, 1.2)\n",
    "MAX_DETAIL_RETRIES = 1\n",
    "\n",
    "BRANDS = [\n",
    "    \"Maruti\", \"Hyundai\", \"Tata\", \"Honda\", \"Toyota\", \"Mahindra\", \"Kia\",\n",
    "    \"BMW\", \"Audi\", \"Mercedes-Benz\", \"Mercedes\", \"Renault\", \"MG\", \"Skoda\",\n",
    "    \"Volkswagen\", \"Ford\", \"Nissan\", \"Jeep\", \"Volvo\", \"Land Rover\", \"Jaguar\",\n",
    "    \"Isuzu\", \"Datsun\", \"Chevrolet\", \"Opel\"\n",
    "]\n",
    "# --------------------------\n",
    "\n",
    "def text_of(elem):\n",
    "    return elem.get_text(\" \", strip=True) if elem else \"\"\n",
    "\n",
    "def guess_brand_and_model(name):\n",
    "    if not name:\n",
    "        return \"\", \"\"\n",
    "    for b in BRANDS:\n",
    "        if b.lower() in name.lower():\n",
    "            model = re.sub(re.escape(b), \"\", name, flags=re.IGNORECASE).strip()\n",
    "            model = re.sub(r'^[\\-\\:\\–\\—\\s]+', '', model)\n",
    "            return b, model or name\n",
    "    parts = name.split()\n",
    "    return (parts[0], \" \".join(parts[1:]) if len(parts) > 1 else \"\") if parts else (\"\",\"\")\n",
    "\n",
    "def extract_kms(text):\n",
    "    m = re.search(r'([\\d,\\.]+)\\s*(?:kms|km)\\b', text, flags=re.I)\n",
    "    if m:\n",
    "        return m.group(1).replace(\",\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "def extract_fuel(text):\n",
    "    for f in [\"Petrol\", \"Diesel\", \"CNG\", \"LPG\", \"Electric\", \"Hybrid\"]:\n",
    "        if re.search(r'\\b' + re.escape(f) + r'\\b', text, flags=re.I):\n",
    "            return f\n",
    "    return \"\"\n",
    "\n",
    "# ----------------------\n",
    "# IMPROVED MILEAGE LOGIC\n",
    "# ----------------------\n",
    "\n",
    "# convert mpg to kmpl factor\n",
    "_MPG_TO_KMPL = 0.425144\n",
    "\n",
    "def _try_parse_number(s):\n",
    "    \"\"\"Return float or None for first numeric group found.\"\"\"\n",
    "    if not s:\n",
    "        return None\n",
    "    s2 = str(s).replace(\",\", \"\").replace(\"\\xa0\",\" \").strip()\n",
    "    m = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)', s2)\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return float(m.group(1))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_mileage(text):\n",
    "    \"\"\"\n",
    "    Robust mileage extraction that:\n",
    "     - prefers explicit units (kmpl, km/l, kpl)\n",
    "     - converts mpg -> kmpl\n",
    "     - ignores pure distance values like '120 km' (treat as invalid)\n",
    "     - returns standardized string like '18.5 kmpl' or '' if not found\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    s = str(text).replace(\"\\xa0\",\" \").strip()\n",
    "    low = s.lower()\n",
    "\n",
    "    # 1) explicit kmpl / km/l / kpl patterns\n",
    "    m = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)\\s*(km\\s*/\\s*l|kmpl|kpl|kmperlitre|km per litre)\\b', low, flags=re.I)\n",
    "    if m:\n",
    "        num = float(m.group(1))\n",
    "        # format number: remove .0 if integer else keep up to 2 decimals\n",
    "        num_fmt = int(num) if num.is_integer() else round(num, 2)\n",
    "        return f\"{num_fmt} kmpl\"\n",
    "\n",
    "    # 2) mpg -> convert to kmpl\n",
    "    m_mpg = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)\\s*mpg\\b', low, flags=re.I)\n",
    "    if m_mpg:\n",
    "        mpg = float(m_mpg.group(1))\n",
    "        kmpl = round(mpg * _MPG_TO_KMPL, 2)\n",
    "        kmpl_fmt = int(kmpl) if float(kmpl).is_integer() else kmpl\n",
    "        return f\"{kmpl_fmt} kmpl\"\n",
    "\n",
    "    # 3) patterns like \"18.5 kmpl\" without spaces or with units in mixed-case\n",
    "    m2 = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)\\s*(kmpl|kpl|km/l)\\b', low, flags=re.I)\n",
    "    if m2:\n",
    "        num = float(m2.group(1))\n",
    "        num_fmt = int(num) if num.is_integer() else round(num, 2)\n",
    "        return f\"{num_fmt} kmpl\"\n",
    "\n",
    "    # 4) look for 'mileage' keyword and numbers near it\n",
    "    for keyword in (\"mileage\", \"avg. mileage\", \"avg mileage\", \"claimed mileage\", \"claimed fuel economy\"):\n",
    "        idx = low.find(keyword)\n",
    "        if idx != -1:\n",
    "            window = low[max(0, idx-50): idx+80]\n",
    "            m3 = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)\\s*(kmpl|kpl|km/l|mpg)?', window, flags=re.I)\n",
    "            if m3:\n",
    "                num = float(m3.group(1))\n",
    "                unit = m3.group(2)\n",
    "                if unit and \"mpg\" in unit:\n",
    "                    kmpl = round(num * _MPG_TO_KMPL, 2)\n",
    "                    kmpl_fmt = int(kmpl) if float(kmpl).is_integer() else kmpl\n",
    "                    return f\"{kmpl_fmt} kmpl\"\n",
    "                # if unit absent, only accept if number plausible for kmpl\n",
    "                if not unit:\n",
    "                    if num <= 50:  # treat as kmpl\n",
    "                        num_fmt = int(num) if float(num).is_integer() else round(num, 2)\n",
    "                        return f\"{num_fmt} kmpl\"\n",
    "                else:\n",
    "                    # if unit is kmpl-like handled above; fallback\n",
    "                    num_fmt = int(num) if float(num).is_integer() else round(num, 2)\n",
    "                    return f\"{num_fmt} kmpl\"\n",
    "\n",
    "    # 5) generic number+unit elsewhere on page\n",
    "    m4 = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)\\s*(kmpl|kpl|km/l|mpg)\\b', low, flags=re.I)\n",
    "    if m4:\n",
    "        val = float(m4.group(1))\n",
    "        unit = m4.group(2)\n",
    "        if 'mpg' in unit:\n",
    "            kmpl = round(val * _MPG_TO_KMPL, 2)\n",
    "            kmpl_fmt = int(kmpl) if float(kmpl).is_integer() else kmpl\n",
    "            return f\"{kmpl_fmt} kmpl\"\n",
    "        num_fmt = int(val) if val.is_integer() else round(val, 2)\n",
    "        return f\"{num_fmt} kmpl\"\n",
    "\n",
    "    # 6) numeric-only fallback: if page has a single small number (<50) assume kmpl\n",
    "    num = _try_parse_number(s)\n",
    "    if num is not None and num <= 50:\n",
    "        num_fmt = int(num) if float(num).is_integer() else round(num, 2)\n",
    "        return f\"{num_fmt} kmpl\"\n",
    "\n",
    "    # 7) otherwise likely a distance or invalid — return empty\n",
    "    return \"\"\n",
    "\n",
    "# helper used by the fallback detail extraction (kept unchanged)\n",
    "def extract_mileage_from_text(text):\n",
    "    # reuse improved extract_mileage\n",
    "    return extract_mileage(text)\n",
    "\n",
    "def extract_transmission(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    for t in [\"Manual\",\"Automatic\",\"CVT\",\"AMT\",\"DCT\",\"AT\",\"MT\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', text, flags=re.I):\n",
    "            if t.upper() in (\"AT\",\"AMT\",\"CVT\",\"DCT\",\"MT\"):\n",
    "                return t.upper()\n",
    "            return t.title()\n",
    "    return \"\"\n",
    "\n",
    "# ----------------------\n",
    "# existing other helpers unchanged\n",
    "# ----------------------\n",
    "\n",
    "def extract_price_from_soup(soup):\n",
    "    # 1. meta tags\n",
    "    meta_selectors = [\n",
    "        ('meta', {'property': 'og:price:amount'}),\n",
    "        ('meta', {'itemprop': 'price'}),\n",
    "        ('meta', {'name': 'price'}),\n",
    "    ]\n",
    "    for tag, attrs in meta_selectors:\n",
    "        mtag = soup.find(tag, attrs=attrs)\n",
    "        if mtag:\n",
    "            val = mtag.get('content') or mtag.get('value') or \"\"\n",
    "            if val:\n",
    "                if re.search(r'[\\d]', val) and '₹' not in val:\n",
    "                    return \"₹ \" + val.strip()\n",
    "                return val.strip()\n",
    "\n",
    "    # 2. attributes that often store price\n",
    "    for attr in ('data-price', 'data-offer-price', 'data-srp', 'data-amount', 'data-price-value'):\n",
    "        el = soup.find(attrs={attr: True})\n",
    "        if el:\n",
    "            val = el.get(attr)\n",
    "            if val:\n",
    "                if re.search(r'[\\d]', val) and '₹' not in val:\n",
    "                    return \"₹ \" + val.strip()\n",
    "                return val.strip()\n",
    "\n",
    "    # 3. elements with class or id containing 'price' or 'amount'\n",
    "    px = soup.find(lambda tag: tag.name in (\"div\",\"span\",\"p\",\"strong\") and (\n",
    "        tag.get(\"class\") or tag.get(\"id\")\n",
    "    ) and re.search(r'price|amount|selling|srp|finalPrice|carPrice|actual-price', \" \".join((tag.get(\"class\") or []) + [tag.get(\"id\") or \"\"]), flags=re.I))\n",
    "    if px:\n",
    "        txt = text_of(px)\n",
    "        pr = find_rupee_in_text(txt)\n",
    "        if pr:\n",
    "            return pr\n",
    "        if txt:\n",
    "            return txt.strip()\n",
    "\n",
    "    # 4. any visible text near top with rupee sign\n",
    "    top_region = \"\"\n",
    "    head_candidates = soup.find_all([\"header\", \"section\", \"div\"], limit=6)\n",
    "    for c in head_candidates:\n",
    "        t = text_of(c)\n",
    "        if '₹' in t:\n",
    "            top_region = t\n",
    "            break\n",
    "    if not top_region:\n",
    "        top_region = soup.get_text(\" \", strip=True)\n",
    "\n",
    "    pr = find_rupee_in_text(top_region)\n",
    "    if pr:\n",
    "        return pr\n",
    "\n",
    "    # 5. fallback regex on whole page (Lakh/Crore)\n",
    "    p2 = re.search(r'[\\d\\.,]+\\s*(?:Lakh|lakh|Lakhs|lakhs|Crore|crore|Cr)\\b', soup.get_text(\" \", strip=True))\n",
    "    if p2:\n",
    "        return p2.group(0).strip()\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def find_rupee_in_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    m = re.search(r'₹\\s*[\\d\\.,\\sA-Za-z]+', text)\n",
    "    if m:\n",
    "        return m.group(0).strip()\n",
    "    m2 = re.search(r'[\\d\\.,]+\\s*(Lakh|lakh|Lakhs|lakhs|Crore|crore|Cr)\\b', text)\n",
    "    if m2:\n",
    "        return m2.group(0).strip()\n",
    "    return \"\"\n",
    "\n",
    "def extract_price_from_text(text):\n",
    "    p = find_rupee_in_text(text)\n",
    "    return p\n",
    "\n",
    "def extract_year(text):\n",
    "    m = re.search(r'\\b(19|20)\\d{2}\\b', text)\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    "# ----------------------\n",
    "# main scraping flow (unchanged)\n",
    "# ----------------------\n",
    "\n",
    "def main():\n",
    "    chrome_opts = Options()\n",
    "    if HEADLESS:\n",
    "        chrome_opts.add_argument(\"--headless=new\")\n",
    "    chrome_opts.add_argument(\"--no-sandbox\")\n",
    "    chrome_opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_opts.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_opts)\n",
    "\n",
    "    try:\n",
    "        driver.get(START_URL)\n",
    "        time.sleep(2.0)\n",
    "        soup0 = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        text0 = soup0.get_text(\" \", strip=True)\n",
    "\n",
    "        total_listings = None\n",
    "        m = re.search(r'([\\d,]{2,})\\s+Second Hand Cars in Nagpur', text0, flags=re.I)\n",
    "        if not m:\n",
    "            m = re.search(r'of\\s+([\\d,]+)\\s+results', text0, flags=re.I)\n",
    "        if m:\n",
    "            total_listings = int(m.group(1).replace(\",\", \"\"))\n",
    "\n",
    "        per_page_guess = max(1, len(soup0.find_all(\"h3\")))\n",
    "        estimated_pages = math.ceil(total_listings / per_page_guess) if total_listings else None\n",
    "        total_pages = int(estimated_pages) if estimated_pages else 200\n",
    "        if MAX_PAGES_OVERRIDE:\n",
    "            total_pages = MAX_PAGES_OVERRIDE\n",
    "\n",
    "        print(f\"Detected total_listings={total_listings}, per_page_guess={per_page_guess}, total_pages={total_pages}\")\n",
    "\n",
    "        rows = []\n",
    "        seen_keys = set()\n",
    "        detail_links = []\n",
    "\n",
    "        for p in range(1, total_pages + 1):\n",
    "            page_url = START_URL.rstrip(\"/\") + \"?page=\" + str(p)\n",
    "            try:\n",
    "                driver.get(page_url)\n",
    "            except Exception:\n",
    "                time.sleep(1.0)\n",
    "                driver.get(page_url)\n",
    "\n",
    "            # scroll aggressively\n",
    "            last_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            sc = 0\n",
    "            while sc < MAX_SCROLLS:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(SCROLL_PAUSE)\n",
    "                new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_h == last_h:\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight-400);\")\n",
    "                    time.sleep(0.4)\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    time.sleep(0.4)\n",
    "                    new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                    if new_h == last_h:\n",
    "                        break\n",
    "                last_h = new_h\n",
    "                sc += 1\n",
    "\n",
    "            page_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            titles = page_soup.find_all(\"h3\")\n",
    "            for h in titles:\n",
    "                title = text_of(h)\n",
    "                if not title:\n",
    "                    continue\n",
    "\n",
    "                container = h\n",
    "                card_text = \"\"\n",
    "                link = \"\"\n",
    "                for _ in range(6):\n",
    "                    if container is None:\n",
    "                        break\n",
    "                    card_text = text_of(container)\n",
    "                    if \"₹\" in card_text or re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I):\n",
    "                        a = container.find(\"a\", href=True)\n",
    "                        if a:\n",
    "                            href = a[\"href\"]\n",
    "                            link = href if \"cardekho.com\" in href else urljoin(page_url, href)\n",
    "                            link = link.split(\"#\")[0].split(\"?utm\")[0]\n",
    "                        break\n",
    "                    container = container.parent\n",
    "\n",
    "                if not card_text:\n",
    "                    parent = h.parent\n",
    "                    card_text = text_of(parent) if parent else title\n",
    "\n",
    "                if (\"₹\" not in card_text) and (re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I) is None):\n",
    "                    continue\n",
    "\n",
    "                price_card = extract_price_from_text(card_text)\n",
    "                key = (title + \"||\" + (price_card or \"\")).strip()\n",
    "                if key in seen_keys:\n",
    "                    continue\n",
    "                seen_keys.add(key)\n",
    "\n",
    "                kms = extract_kms(card_text)\n",
    "                fuel = extract_fuel(card_text)\n",
    "                year = extract_year(title) or extract_year(card_text)\n",
    "                brand = \"\"\n",
    "                model = \"\"\n",
    "                try:\n",
    "                    brand, model = guess_brand_and_model(title)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                rows.append({\n",
    "                    \"Car_name\": title,\n",
    "                    \"brand\": brand,\n",
    "                    \"model\": model,\n",
    "                    \"kms_driven\": kms,\n",
    "                    \"mileage\": \"\",             # will be filled from detail page if available\n",
    "                    \"transmission\": \"\",\n",
    "                    \"fuel_type\": fuel,\n",
    "                    \"year_of_manufacture\": year,\n",
    "                    \"price\": price_card,\n",
    "                    \"detail_page\": link\n",
    "                })\n",
    "\n",
    "                if link:\n",
    "                    detail_links.append(link)\n",
    "\n",
    "            time.sleep(random.uniform(*PAGE_PAUSE))\n",
    "\n",
    "            if total_listings and len(seen_keys) >= total_listings:\n",
    "                print(\"Reached detected total listings; stopping page scan.\")\n",
    "                break\n",
    "\n",
    "            if p % 10 == 0:\n",
    "                print(f\"Scanned page {p}; rows so far: {len(rows)}\")\n",
    "\n",
    "        print(f\"Collected {len(rows)} card-level rows, detail links: {len(set(detail_links))}\")\n",
    "\n",
    "        # Now ensure price/mileage/transmission are filled: visit detail pages for any row missing price/mileage/trans\n",
    "        if VISIT_DETAIL_PAGES and detail_links:\n",
    "            unique_detail_links = []\n",
    "            seen_dl = set()\n",
    "            for u in detail_links:\n",
    "                if u and u not in seen_dl:\n",
    "                    seen_dl.add(u)\n",
    "                    unique_detail_links.append(u)\n",
    "\n",
    "            # map link -> price/mileage/transmission\n",
    "            detail_map = {}\n",
    "\n",
    "            for i, dl in enumerate(unique_detail_links):\n",
    "                # polite pause\n",
    "                if i > 0:\n",
    "                    time.sleep(random.uniform(*DETAIL_PAUSE))\n",
    "                attempt = 0\n",
    "                success = False\n",
    "                while attempt <= MAX_DETAIL_RETRIES and not success:\n",
    "                    try:\n",
    "                        driver.get(dl)\n",
    "                        time.sleep(1.0 + random.random()*0.8)\n",
    "                        dsoup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "                        # price from many possible places\n",
    "                        price_val = extract_price_from_soup(dsoup)\n",
    "                        if not price_val:\n",
    "                            price_val = extract_price_from_text(dsoup.get_text(\" \", strip=True))\n",
    "\n",
    "                        # mileage and transmission extraction now uses improved functions\n",
    "                        page_text = dsoup.get_text(\" \", strip=True)\n",
    "                        # try meta-line near title for quick values\n",
    "                        h_tag = dsoup.find([\"h1\",\"h2\"])\n",
    "                        meta_line = \"\"\n",
    "                        if h_tag:\n",
    "                            nxt = h_tag.find_next()\n",
    "                            checks = 0\n",
    "                            while nxt and checks < 8:\n",
    "                                t = text_of(nxt)\n",
    "                                if t and ((\"kms\" in t.lower()) or (\"₹\" in t) or re.search(r'\\b\\d+\\s*(?:kmpl|km/kg|km/kwh|km/l|kpl)\\b', t, flags=re.I)):\n",
    "                                    meta_line = t\n",
    "                                    break\n",
    "                                nxt = nxt.find_next()\n",
    "                                checks += 1\n",
    "\n",
    "                        # mileage: improved extraction\n",
    "                        mileage_val = \"\"\n",
    "                        mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
    "                        if mnode:\n",
    "                            try:\n",
    "                                parent = mnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    mileage_val = text_of(sib)\n",
    "                            except:\n",
    "                                mileage_val = \"\"\n",
    "                        if not mileage_val:\n",
    "                            # check meta_line then page_text using improved extract_mileage\n",
    "                            mileage_val = extract_mileage(meta_line or page_text) or extract_mileage(page_text)\n",
    "\n",
    "                        # transmission\n",
    "                        trans_val = \"\"\n",
    "                        tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n",
    "                        if tnode:\n",
    "                            try:\n",
    "                                parent = tnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    trans_val = text_of(sib)\n",
    "                            except:\n",
    "                                trans_val = \"\"\n",
    "                        if not trans_val:\n",
    "                            trans_val = extract_transmission(meta_line or page_text)\n",
    "\n",
    "                        # normalize mileage into consistent 'X kmpl' format (handled by extract_mileage)\n",
    "                        mileage_clean = extract_mileage(mileage_val or \"\")\n",
    "                        detail_map[dl] = {\n",
    "                            \"price\": price_val or \"\",\n",
    "                            \"mileage\": mileage_clean or \"\",\n",
    "                            \"transmission\": trans_val or \"\"\n",
    "                        }\n",
    "                        success = True\n",
    "                    except Exception as e:\n",
    "                        attempt += 1\n",
    "                        if attempt > MAX_DETAIL_RETRIES:\n",
    "                            detail_map[dl] = {\"price\": \"\", \"mileage\": \"\", \"transmission\": \"\"}\n",
    "                            success = True\n",
    "                        else:\n",
    "                            time.sleep(0.8)\n",
    "\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print(f\"Processed {i+1} detail pages...\")\n",
    "\n",
    "            # merge into rows\n",
    "            for r in rows:\n",
    "                link = r.get(\"detail_page\", \"\")\n",
    "                if link and link in detail_map:\n",
    "                    if not r.get(\"price\"):\n",
    "                        r[\"price\"] = detail_map[link][\"price\"]\n",
    "                    # set mileage/transmission from detail\n",
    "                    if detail_map[link].get(\"mileage\"):\n",
    "                        r[\"mileage\"] = detail_map[link][\"mileage\"]\n",
    "                    if detail_map[link].get(\"transmission\"):\n",
    "                        r[\"transmission\"] = detail_map[link][\"transmission\"]\n",
    "\n",
    "        # final normalization\n",
    "        df = pd.DataFrame(rows, columns=[\n",
    "            \"Car_name\",\"brand\",\"model\",\"kms_driven\",\"mileage\",\"transmission\",\"fuel_type\",\"year_of_manufacture\",\"price\",\"detail_page\"\n",
    "        ])\n",
    "        df[\"kms_driven\"] = df[\"kms_driven\"].fillna(\"\").astype(str).apply(lambda x: re.sub(r'[^\\d\\.]', '', x))\n",
    "        df[\"mileage\"] = df[\"mileage\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"transmission\"] = df[\"transmission\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "        df[\"year_of_manufacture\"] = df[\"year_of_manufacture\"].fillna(\"\").astype(str).apply(lambda x: (re.search(r'\\b(19|20)\\d{2}\\b', x).group(0) if re.search(r'\\b(19|20)\\d{2}\\b', x) else \"\"))\n",
    "        df[\"price\"] = df[\"price\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"fuel_type\"] = df[\"fuel_type\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "\n",
    "        # dedupe\n",
    "        if \"detail_page\" in df.columns and df[\"detail_page\"].str.len().sum() > 0:\n",
    "            df = df.drop_duplicates(subset=[\"detail_page\"]).reset_index(drop=True)\n",
    "        else:\n",
    "            df = df.drop_duplicates(subset=[\"Car_name\",\"price\"]).reset_index(drop=True)\n",
    "\n",
    "        # save\n",
    "        df.to_csv(OUTPUT_CSV, index=False)\n",
    "        df.to_excel(OUTPUT_XLSX, index=False)\n",
    "        print(f\"Saved {len(df)} rows to {OUTPUT_CSV} and {OUTPUT_XLSX}\")\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# helpers used in detail extraction (note: improved extract_mileage used above)\n",
    "def extract_mileage_fallback(text):\n",
    "    # kept for compatibility; call improved extractor\n",
    "    return extract_mileage(text)\n",
    "\n",
    "def extract_transmission(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    for t in [\"Manual\",\"Automatic\",\"CVT\",\"AMT\",\"DCT\",\"AT\",\"MT\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', text, flags=re.I):\n",
    "            if t.upper() in (\"AT\",\"AMT\",\"CVT\",\"DCT\",\"MT\"):\n",
    "                return t.upper()\n",
    "            return t.title()\n",
    "    return \"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9bcacf-f01c-40b1-b31b-156a3576f738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e850cd8e-8e65-41e0-81d1-82b709e57223",
   "metadata": {},
   "source": [
    "1st stage of scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa13b5c2-d6f1-4e1f-abdf-d98797ef7ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected total_listings=2588, per_page_guess=66, total_pages=40\n",
      "Scanned page 10; collected rows so far: 804\n",
      "Scanned page 20; collected rows so far: 816\n",
      "Scanned page 30; collected rows so far: 825\n",
      "Scanned page 40; collected rows so far: 849\n",
      "Collected 849 card-level rows, discovered 797 detail links.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_49764\\3009540914.py:316: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_49764\\3009540914.py:332: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 detail pages...\n",
      "Processed 200 detail pages...\n",
      "Processed 300 detail pages...\n",
      "Processed 400 detail pages...\n",
      "Processed 500 detail pages...\n",
      "Processed 600 detail pages...\n",
      "Processed 700 detail pages...\n",
      "Done. Collected 798 rows. Saved to cardekho_used_cars_pune_with_mileage.csv and cardekho_used_cars_pune_with_mileage.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "cardekho_used_pune_scraper_with_mileage.py\n",
    "\n",
    "Scrapes https://www.cardekho.com/used-cars+in+indore and writes CSV + Excel.\n",
    "Extracted columns:\n",
    "Car_name, brand, model, kms_driven, mileage, transmission, fuel_type, year_of_manufacture, price, detail_page\n",
    "\n",
    "Requires: selenium, beautifulsoup4, pandas, openpyxl, webdriver-manager\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# -------- CONFIG ----------\n",
    "# START_URL = \"https://www.cardekho.com/used-cars+in+hyderabad\"\n",
    "START_URL = \"https://www.cardekho.com/used-cars+in+pune\"   # URL for pune\n",
    "OUTPUT_CSV = \"cardekho_used_cars_pune_with_mileage.csv\"\n",
    "OUTPUT_XLSX = \"cardekho_used_cars_pune_with_mileage.xlsx\"\n",
    "\n",
    "HEADLESS = True                 # Set False to watch browser\n",
    "MAX_PAGES_OVERRIDE = None       # Set to int to force how many result pages to scan; None -> auto-detect\n",
    "MAX_SCROLLS = 40                # scroll rounds per search-result page\n",
    "SCROLL_PAUSE = 0.7\n",
    "PAGE_PAUSE = (0.6, 1.4)\n",
    "VISIT_DETAIL_PAGES = True       # True -> open each listing detail page for mileage/transmission accuracy\n",
    "DETAIL_PAUSE = (0.6, 1.2)\n",
    "MAX_DETAIL_RETRIES = 1         # retry detail page once on failure\n",
    "# Brands to help split brand/model\n",
    "BRANDS = [\n",
    "    \"Maruti\", \"Hyundai\", \"Tata\", \"Honda\", \"Toyota\", \"Mahindra\", \"Kia\",\n",
    "    \"BMW\", \"Audi\", \"Mercedes-Benz\", \"Mercedes\", \"Renault\", \"MG\", \"Skoda\",\n",
    "    \"Volkswagen\", \"Ford\", \"Nissan\", \"Jeep\", \"Volvo\", \"Land Rover\", \"Jaguar\",\n",
    "    \"Isuzu\", \"Datsun\", \"Chevrolet\", \"Opel\"\n",
    "]\n",
    "# --------------------------\n",
    "\n",
    "# Helper parsers\n",
    "def guess_brand_and_model(name):\n",
    "    if not name:\n",
    "        return \"\", \"\"\n",
    "    for b in BRANDS:\n",
    "        if b.lower() in name.lower():\n",
    "            model = re.sub(re.escape(b), \"\", name, flags=re.IGNORECASE).strip()\n",
    "            model = re.sub(r'^[\\-\\:\\–\\—\\s]+', '', model)\n",
    "            return b, model or name\n",
    "    parts = name.split()\n",
    "    return (parts[0], \" \".join(parts[1:]) if len(parts) > 1 else \"\") if parts else (\"\",\"\")\n",
    "\n",
    "def extract_kms(text):\n",
    "    m = re.search(r'([\\d,\\.]+)\\s*(?:kms|km)\\b', text, flags=re.I)\n",
    "    if m:\n",
    "        return m.group(1).replace(\",\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "def extract_fuel(text):\n",
    "    for f in [\"Petrol\", \"Diesel\", \"CNG\", \"LPG\", \"Electric\", \"Hybrid\"]:\n",
    "        if re.search(r'\\b' + re.escape(f) + r'\\b', text, flags=re.I):\n",
    "            return f\n",
    "    return \"\"\n",
    "\n",
    "def extract_price(text):\n",
    "    m = re.search(r'₹\\s*[\\d\\.,\\sA-Za-z]+', text)\n",
    "    if m:\n",
    "        return m.group(0).strip()\n",
    "    m2 = re.search(r'[\\d\\.,]+\\s*(Lakh|lakh|Lakhs|lakhs|Crore|crore|Cr)\\b', text)\n",
    "    if m2:\n",
    "        return m2.group(0)\n",
    "    return \"\"\n",
    "\n",
    "def extract_year(text):\n",
    "    m = re.search(r'\\b(19|20)\\d{2}\\b', text)\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    "# mileage pattern examples:\n",
    "# 18.5 kmpl, 22 km/kg, 120 km/kWh, 18 kmpl (ARAI), 25.6 kmpl\n",
    "MILEAGE_REGEXES = [\n",
    "    re.compile(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|km/kg|km/kwh|km/l|kmperlitre|km/gal|km/100km|kml|kpl)\\b', flags=re.I),\n",
    "    re.compile(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(km(?:/kwh|/kg|pl)?)\\b', flags=re.I),\n",
    "    re.compile(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(mpg|mpg\\;)', flags=re.I)\n",
    "]\n",
    "\n",
    "def extract_mileage(text):\n",
    "    txt = text.replace(\"\\xa0\",\" \").strip()\n",
    "    for rx in MILEAGE_REGEXES:\n",
    "        m = rx.search(txt)\n",
    "        if m:\n",
    "            val = m.group(1)\n",
    "            unit = m.group(2)\n",
    "            return f\"{val} {unit}\".strip()\n",
    "    # sometimes written like \"Mileage: 18.5 kmpl\" or \"18.5kmpl\"\n",
    "    m2 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|km/kg|km/kwh|km|kpl|km/l)\\b', txt, flags=re.I)\n",
    "    if m2:\n",
    "        return f\"{m2.group(1)} {m2.group(2)}\"\n",
    "    return \"\"\n",
    "\n",
    "# transmission extraction\n",
    "def extract_transmission(text):\n",
    "    for t in [\"Manual\", \"Automatic\", \"CVT\", \"AMT\", \"DCT\", \"AT\", \"MT\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', text, flags=re.I):\n",
    "            # normalize common variants\n",
    "            if t.upper() in (\"AT\",\"AMT\",\"CVT\",\"DCT\",\"MT\"):\n",
    "                return t.upper()\n",
    "            return t.title()\n",
    "    return \"\"\n",
    "\n",
    "# safe text extractor for BeautifulSoup element\n",
    "def text_of(elem):\n",
    "    return elem.get_text(\" \", strip=True) if elem else \"\"\n",
    "\n",
    "# ---------- main ----------\n",
    "def main():\n",
    "    # Setup Selenium Chrome\n",
    "    chrome_opts = Options()\n",
    "    if HEADLESS:\n",
    "        chrome_opts.add_argument(\"--headless=new\")\n",
    "    chrome_opts.add_argument(\"--no-sandbox\")\n",
    "    chrome_opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_opts.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_opts.add_argument(\"--disable-gpu\")\n",
    "    chrome_opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_opts)\n",
    "\n",
    "    try:\n",
    "        # load first page and detect pages count\n",
    "        driver.get(START_URL)\n",
    "        time.sleep(2.0)\n",
    "        soup0 = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        page_text = soup0.get_text(\" \", strip=True)\n",
    "\n",
    "        total_listings = None\n",
    "        m = re.search(r'([\\d,]{2,})\\s+Second Hand Cars in Pune', page_text, flags=re.I)\n",
    "        if not m:\n",
    "            m = re.search(r'of\\s+([\\d,]+)\\s+results', page_text, flags=re.I)\n",
    "        if m:\n",
    "            total_listings = int(m.group(1).replace(\",\", \"\"))\n",
    "\n",
    "        per_page_guess = max(1, len(soup0.find_all(\"h3\")))\n",
    "        estimated_pages = math.ceil(total_listings / per_page_guess) if total_listings else None\n",
    "        total_pages = int(estimated_pages) if estimated_pages else 200\n",
    "        if MAX_PAGES_OVERRIDE:\n",
    "            total_pages = MAX_PAGES_OVERRIDE\n",
    "\n",
    "        print(f\"Detected total_listings={total_listings}, per_page_guess={per_page_guess}, total_pages={total_pages}\")\n",
    "\n",
    "        rows = []\n",
    "        seen_keys = set()\n",
    "        detail_links = []\n",
    "\n",
    "        # iterate search result pages\n",
    "        for p in range(1, total_pages + 1):\n",
    "            page_url = START_URL.rstrip(\"/\") + \"?page=\" + str(p)\n",
    "            try:\n",
    "                driver.get(page_url)\n",
    "            except Exception:\n",
    "                time.sleep(1.0)\n",
    "                driver.get(page_url)\n",
    "\n",
    "            # aggressively scroll to let lazy content load\n",
    "            last_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            scroll_count = 0\n",
    "            while scroll_count < MAX_SCROLLS:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(SCROLL_PAUSE)\n",
    "                new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_h == last_h:\n",
    "                    # wiggle\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight-400);\")\n",
    "                    time.sleep(0.4)\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    time.sleep(0.4)\n",
    "                    new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                    if new_h == last_h:\n",
    "                        break\n",
    "                last_h = new_h\n",
    "                scroll_count += 1\n",
    "\n",
    "            page_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "            # find title nodes (h3) and extract card container text\n",
    "            titles = page_soup.find_all(\"h3\")\n",
    "            for h in titles:\n",
    "                title = text_of(h)\n",
    "                if not title:\n",
    "                    continue\n",
    "\n",
    "                # climb up to find a container with price or kms present\n",
    "                container = h\n",
    "                card_text = \"\"\n",
    "                link = \"\"\n",
    "                for _ in range(6):\n",
    "                    if container is None:\n",
    "                        break\n",
    "                    card_text = text_of(container)\n",
    "                    if \"₹\" in card_text or re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I):\n",
    "                        # find anchor inside container for detail link if present\n",
    "                        a = container.find(\"a\", href=True)\n",
    "                        if a:\n",
    "                            href = a[\"href\"]\n",
    "                            link = href if \"cardekho.com\" in href else urljoin(page_url, href)\n",
    "                            link = link.split(\"#\")[0].split(\"?utm\")[0]\n",
    "                        break\n",
    "                    container = container.parent\n",
    "\n",
    "                if not card_text:\n",
    "                    # fallback to grabbing parent text\n",
    "                    parent = h.parent\n",
    "                    card_text = text_of(parent) if parent else title\n",
    "\n",
    "                # check minimal heuristics: price or kms exist\n",
    "                if (\"₹\" not in card_text) and (re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I) is None):\n",
    "                    continue\n",
    "\n",
    "                # dedupe by title+price\n",
    "                price_snip = extract_price(card_text)\n",
    "                key = (title + \"||\" + price_snip).strip()\n",
    "                if key in seen_keys:\n",
    "                    continue\n",
    "                seen_keys.add(key)\n",
    "\n",
    "                kms = extract_kms(card_text)\n",
    "                fuel = extract_fuel(card_text)\n",
    "                year = extract_year(title) or extract_year(card_text)\n",
    "                brand, model = guess_brand_and_model(title)\n",
    "                price = price_snip\n",
    "\n",
    "                # prepare base row (mileage/transmission may be blank now; fill from detail page if VISIT_DETAIL_PAGES)\n",
    "                rows.append({\n",
    "                    \"Car_name\": title,\n",
    "                    \"brand\": brand,\n",
    "                    \"model\": model,\n",
    "                    \"kms_driven\": kms,\n",
    "                    \"mileage\": \"\",             # to fill\n",
    "                    \"transmission\": \"\",       # to fill\n",
    "                    \"fuel_type\": fuel,\n",
    "                    \"year_of_manufacture\": year,\n",
    "                    \"price\": price,\n",
    "                    \"detail_page\": link\n",
    "                })\n",
    "\n",
    "                if link:\n",
    "                    detail_links.append(link)\n",
    "\n",
    "            # jitter between pages\n",
    "            time.sleep(random.uniform(*PAGE_PAUSE))\n",
    "\n",
    "            # early stop if found >= total_listings\n",
    "            if total_listings and len(seen_keys) >= total_listings:\n",
    "                print(\"Reached detected total listings; stopping page scan.\")\n",
    "                break\n",
    "\n",
    "            # small progress print\n",
    "            if p % 10 == 0:\n",
    "                print(f\"Scanned page {p}; collected rows so far: {len(rows)}\")\n",
    "\n",
    "        print(f\"Collected {len(rows)} card-level rows, discovered {len(set(detail_links))} detail links.\")\n",
    "\n",
    "        # Optionally visit detail pages for mileage + transmission (more accurate)\n",
    "        if VISIT_DETAIL_PAGES and detail_links:\n",
    "            unique_detail_links = []\n",
    "            seen_dl = set()\n",
    "            for u in detail_links:\n",
    "                if u and u not in seen_dl:\n",
    "                    seen_dl.add(u)\n",
    "                    unique_detail_links.append(u)\n",
    "\n",
    "            # map detail_link -> parsed fields\n",
    "            detail_map = {}\n",
    "\n",
    "            for i, dl in enumerate(unique_detail_links):\n",
    "                # small polite wait\n",
    "                if i > 0:\n",
    "                    time.sleep(random.uniform(*DETAIL_PAUSE))\n",
    "\n",
    "                # retry loop\n",
    "                attempt = 0\n",
    "                success = False\n",
    "                while attempt <= MAX_DETAIL_RETRIES and not success:\n",
    "                    try:\n",
    "                        driver.get(dl)\n",
    "                        time.sleep(1.0 + random.random()*0.8)  # allow JS\n",
    "                        dsoup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                        page_text = dsoup.get_text(\" \", strip=True)\n",
    "\n",
    "                        # Try structured lookups:\n",
    "                        # 1) meta-line near the H1/H2 (often contains \"kms • Petrol • 2019 • 18.5 kmpl • Automatic\")\n",
    "                        h_tag = dsoup.find([\"h1\",\"h2\"])\n",
    "                        meta_line = \"\"\n",
    "                        if h_tag:\n",
    "                            nxt = h_tag.find_next()\n",
    "                            checks = 0\n",
    "                            while nxt and checks < 8:\n",
    "                                t = text_of(nxt)\n",
    "                                if t and ((\"kms\" in t.lower()) or (\"₹\" in t) or re.search(r'\\b\\d+\\s*(?:kmpl|km/kg|km/kwh|km/l|kpl)\\b', t, flags=re.I)):\n",
    "                                    meta_line = t\n",
    "                                    break\n",
    "                                nxt = nxt.find_next()\n",
    "                                checks += 1\n",
    "\n",
    "                        # 2) labeled field lookup: look for text nodes like 'Mileage' or 'Transmission' and read siblings\n",
    "                        # Mileage\n",
    "                        mileage_val = \"\"\n",
    "                        # find text nodes \"Mileage\" or \"Avg. Mileage\" etc.\n",
    "                        mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
    "                        if mnode:\n",
    "                            try:\n",
    "                                # sibling / next element may contain value\n",
    "                                parent = mnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    mileage_val = text_of(sib)\n",
    "                            except:\n",
    "                                mileage_val = \"\"\n",
    "                        if not mileage_val:\n",
    "                            # try meta_line and page_text\n",
    "                            mileage_val = extract_mileage(meta_line or page_text) or extract_mileage(page_text)\n",
    "\n",
    "                        # Transmission\n",
    "                        trans_val = \"\"\n",
    "                        tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n",
    "                        if tnode:\n",
    "                            try:\n",
    "                                parent = tnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    trans_val = text_of(sib)\n",
    "                            except:\n",
    "                                trans_val = \"\"\n",
    "                        if not trans_val:\n",
    "                            trans_val = extract_transmission(meta_line or page_text)\n",
    "\n",
    "                        # Normalize/massage values\n",
    "                        mileage_clean = extract_mileage(mileage_val or \"\")\n",
    "                        transmission_clean = extract_transmission(trans_val or \"\")\n",
    "\n",
    "                        # fallback: sometimes card-level has mileage like '18 kmpl' in small text — try to extract from page text\n",
    "                        if not mileage_clean:\n",
    "                            mileage_clean = extract_mileage(page_text)\n",
    "\n",
    "                        # store\n",
    "                        detail_map[dl] = {\n",
    "                            \"mileage\": mileage_clean,\n",
    "                            \"transmission\": transmission_clean\n",
    "                        }\n",
    "                        success = True\n",
    "                    except Exception as e:\n",
    "                        attempt += 1\n",
    "                        if attempt > MAX_DETAIL_RETRIES:\n",
    "                            # give empty values on failure\n",
    "                            detail_map[dl] = {\"mileage\": \"\", \"transmission\": \"\"}\n",
    "                            success = True\n",
    "                        else:\n",
    "                            time.sleep(0.8)\n",
    "\n",
    "                # progress print occasionally\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print(f\"Processed {i+1} detail pages...\")\n",
    "\n",
    "            # Now merge detail_map into rows\n",
    "            for r in rows:\n",
    "                link = r.get(\"detail_page\", \"\")\n",
    "                if link and link in detail_map:\n",
    "                    r[\"mileage\"] = detail_map[link][\"mileage\"]\n",
    "                    r[\"transmission\"] = detail_map[link][\"transmission\"]\n",
    "                else:\n",
    "                    # attempt to find mileage/trans in the card text (already tried earlier)\n",
    "                    # leave empty if not found\n",
    "                    if not r[\"mileage\"]:\n",
    "                        # try to infer from model/name\n",
    "                        r[\"mileage\"] = \"\"\n",
    "                    if not r[\"transmission\"]:\n",
    "                        r[\"transmission\"] = \"\"\n",
    "\n",
    "        # build DataFrame and clean\n",
    "        df = pd.DataFrame(rows, columns=[\n",
    "            \"Car_name\", \"brand\", \"model\", \"kms_driven\", \"mileage\", \"transmission\",\n",
    "            \"fuel_type\", \"year_of_manufacture\", \"price\", \"detail_page\"\n",
    "        ])\n",
    "\n",
    "        # normalize\n",
    "        df[\"kms_driven\"] = df[\"kms_driven\"].fillna(\"\").astype(str).apply(lambda x: re.sub(r'[^\\d\\.]', '', x))\n",
    "        df[\"mileage\"] = df[\"mileage\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"transmission\"] = df[\"transmission\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "        df[\"year_of_manufacture\"] = df[\"year_of_manufacture\"].fillna(\"\").astype(str).apply(lambda x: (re.search(r'\\b(19|20)\\d{2}\\b', x).group(0) if re.search(r'\\b(19|20)\\d{2}\\b', x) else \"\"))\n",
    "        df[\"price\"] = df[\"price\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"fuel_type\"] = df[\"fuel_type\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "\n",
    "        # dedupe by detail_link if present else by Car_name+price\n",
    "        if df[\"detail_page\"].notnull().sum() > 0:\n",
    "            df = df.drop_duplicates(subset=[\"detail_page\"]).reset_index(drop=True)\n",
    "        else:\n",
    "            df = df.drop_duplicates(subset=[\"Car_name\", \"price\"]).reset_index(drop=True)\n",
    "\n",
    "        # save\n",
    "        df.to_csv(OUTPUT_CSV, index=False)\n",
    "        df.to_excel(OUTPUT_XLSX, index=False)\n",
    "        print(f\"Done. Collected {len(df)} rows. Saved to {OUTPUT_CSV} and {OUTPUT_XLSX}\")\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cab7c9-a4a7-4f1e-9ba8-2e77a8241ee7",
   "metadata": {},
   "source": [
    "2nd Stage of scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a29e71b-f083-401c-af7f-d75fee1960c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected total_listings=2619, per_page_guess=66, total_pages=40\n",
      "Scanned page 10; rows so far: 720\n",
      "Scanned page 20; rows so far: 756\n",
      "Scanned page 30; rows so far: 760\n",
      "Scanned page 40; rows so far: 803\n",
      "Collected 803 card-level rows, detail links: 761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_56156\\3780998771.py:339: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_56156\\3780998771.py:354: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 detail pages...\n",
      "Processed 200 detail pages...\n",
      "Processed 300 detail pages...\n",
      "Processed 400 detail pages...\n",
      "Processed 500 detail pages...\n",
      "Processed 600 detail pages...\n",
      "Processed 700 detail pages...\n",
      "Saved 762 rows to cardekho_used_cars_pune_price_fixed.csv and cardekho_used_cars_pune_price_fixed.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "cardekho_with_price_fix.py\n",
    "\n",
    "Improved scraper for CarDekho used cars (Pune) with robust price extraction.\n",
    "Requires: selenium, webdriver-manager, beautifulsoup4, pandas, openpyxl\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# -------- CONFIG ----------\n",
    "START_URL = \"https://www.cardekho.com/used-cars+in+pune\"\n",
    "OUTPUT_CSV = \"cardekho_used_cars_pune_price_fixed.csv\"\n",
    "OUTPUT_XLSX = \"cardekho_used_cars_pune_price_fixed.xlsx\"\n",
    "\n",
    "HEADLESS = True\n",
    "MAX_PAGES_OVERRIDE = None\n",
    "MAX_SCROLLS = 40\n",
    "SCROLL_PAUSE = 0.7\n",
    "PAGE_PAUSE = (0.6, 1.4)\n",
    "VISIT_DETAIL_PAGES = True\n",
    "DETAIL_PAUSE = (0.6, 1.2)\n",
    "MAX_DETAIL_RETRIES = 1\n",
    "\n",
    "BRANDS = [\n",
    "    \"Maruti\", \"Hyundai\", \"Tata\", \"Honda\", \"Toyota\", \"Mahindra\", \"Kia\",\n",
    "    \"BMW\", \"Audi\", \"Mercedes-Benz\", \"Mercedes\", \"Renault\", \"MG\", \"Skoda\",\n",
    "    \"Volkswagen\", \"Ford\", \"Nissan\", \"Jeep\", \"Volvo\", \"Land Rover\", \"Jaguar\",\n",
    "    \"Isuzu\", \"Datsun\", \"Chevrolet\", \"Opel\"\n",
    "]\n",
    "# --------------------------\n",
    "\n",
    "def text_of(elem):\n",
    "    return elem.get_text(\" \", strip=True) if elem else \"\"\n",
    "\n",
    "def guess_brand_and_model(name):\n",
    "    if not name:\n",
    "        return \"\", \"\"\n",
    "    for b in BRANDS:\n",
    "        if b.lower() in name.lower():\n",
    "            model = re.sub(re.escape(b), \"\", name, flags=re.IGNORECASE).strip()\n",
    "            model = re.sub(r'^[\\-\\:\\–\\—\\s]+', '', model)\n",
    "            return b, model or name\n",
    "    parts = name.split()\n",
    "    return (parts[0], \" \".join(parts[1:]) if len(parts) > 1 else \"\") if parts else (\"\",\"\")\n",
    "\n",
    "def extract_kms(text):\n",
    "    m = re.search(r'([\\d,\\.]+)\\s*(?:kms|km)\\b', text, flags=re.I)\n",
    "    if m:\n",
    "        return m.group(1).replace(\",\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "def extract_fuel(text):\n",
    "    for f in [\"Petrol\", \"Diesel\", \"CNG\", \"LPG\", \"Electric\", \"Hybrid\"]:\n",
    "        if re.search(r'\\b' + re.escape(f) + r'\\b', text, flags=re.I):\n",
    "            return f\n",
    "    return \"\"\n",
    "\n",
    "# NEW: robust price extraction from soup and raw text\n",
    "def extract_price_from_soup(soup):\n",
    "    # 1. meta tags\n",
    "    meta_selectors = [\n",
    "        ('meta', {'property': 'og:price:amount'}),\n",
    "        ('meta', {'itemprop': 'price'}),\n",
    "        ('meta', {'name': 'price'}),\n",
    "    ]\n",
    "    for tag, attrs in meta_selectors:\n",
    "        mtag = soup.find(tag, attrs=attrs)\n",
    "        if mtag:\n",
    "            val = mtag.get('content') or mtag.get('value') or \"\"\n",
    "            if val:\n",
    "                # normalize: prepend ₹ if numeric and no symbol\n",
    "                if re.search(r'[\\d]', val) and '₹' not in val:\n",
    "                    return \"₹ \" + val.strip()\n",
    "                return val.strip()\n",
    "\n",
    "    # 2. attributes that often store price\n",
    "    for attr in ('data-price', 'data-offer-price', 'data-srp', 'data-amount', 'data-price-value'):\n",
    "        el = soup.find(attrs={attr: True})\n",
    "        if el:\n",
    "            val = el.get(attr)\n",
    "            if val:\n",
    "                if re.search(r'[\\d]', val) and '₹' not in val:\n",
    "                    return \"₹ \" + val.strip()\n",
    "                return val.strip()\n",
    "\n",
    "    # 3. elements with class or id containing 'price' or 'amount'\n",
    "    px = soup.find(lambda tag: tag.name in (\"div\",\"span\",\"p\",\"strong\") and (\n",
    "        tag.get(\"class\") or tag.get(\"id\")\n",
    "    ) and re.search(r'price|amount|selling|srp|finalPrice|carPrice|actual-price', \" \".join((tag.get(\"class\") or []) + [tag.get(\"id\") or \"\"]), flags=re.I))\n",
    "    if px:\n",
    "        txt = text_of(px)\n",
    "        pr = find_rupee_in_text(txt)\n",
    "        if pr:\n",
    "            return pr\n",
    "        if txt:\n",
    "            return txt.strip()\n",
    "\n",
    "    # 4. any visible text near top with rupee sign\n",
    "    top_region = \"\"\n",
    "    # try header / top sections\n",
    "    head_candidates = soup.find_all([\"header\", \"section\", \"div\"], limit=6)\n",
    "    for c in head_candidates:\n",
    "        t = text_of(c)\n",
    "        if '₹' in t:\n",
    "            top_region = t\n",
    "            break\n",
    "    if not top_region:\n",
    "        # fallback full page text (takes last resort)\n",
    "        top_region = soup.get_text(\" \", strip=True)\n",
    "\n",
    "    pr = find_rupee_in_text(top_region)\n",
    "    if pr:\n",
    "        return pr\n",
    "\n",
    "    # 5. fallback regex on whole page (Lakh/Crore)\n",
    "    p2 = re.search(r'[\\d\\.,]+\\s*(?:Lakh|lakh|Lakhs|lakhs|Crore|crore|Cr)\\b', soup.get_text(\" \", strip=True))\n",
    "    if p2:\n",
    "        return p2.group(0).strip()\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def find_rupee_in_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    m = re.search(r'₹\\s*[\\d\\.,\\sA-Za-z]+', text)\n",
    "    if m:\n",
    "        return m.group(0).strip()\n",
    "    # sometimes rupee symbol is missing but values use lakh/crore\n",
    "    m2 = re.search(r'[\\d\\.,]+\\s*(Lakh|lakh|Lakhs|lakhs|Crore|crore|Cr)\\b', text)\n",
    "    if m2:\n",
    "        return m2.group(0).strip()\n",
    "    return \"\"\n",
    "\n",
    "def extract_price_from_text(text):\n",
    "    # ensures same fallback when only raw text available\n",
    "    p = find_rupee_in_text(text)\n",
    "    return p\n",
    "\n",
    "def extract_year(text):\n",
    "    m = re.search(r'\\b(19|20)\\d{2}\\b', text)\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    "# main\n",
    "def main():\n",
    "    chrome_opts = Options()\n",
    "    if HEADLESS:\n",
    "        chrome_opts.add_argument(\"--headless=new\")\n",
    "    chrome_opts.add_argument(\"--no-sandbox\")\n",
    "    chrome_opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_opts.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_opts)\n",
    "\n",
    "    try:\n",
    "        driver.get(START_URL)\n",
    "        time.sleep(2.0)\n",
    "        soup0 = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        text0 = soup0.get_text(\" \", strip=True)\n",
    "\n",
    "        total_listings = None\n",
    "        m = re.search(r'([\\d,]{2,})\\s+Second Hand Cars in Pune', text0, flags=re.I)\n",
    "        if not m:\n",
    "            m = re.search(r'of\\s+([\\d,]+)\\s+results', text0, flags=re.I)\n",
    "        if m:\n",
    "            total_listings = int(m.group(1).replace(\",\", \"\"))\n",
    "\n",
    "        per_page_guess = max(1, len(soup0.find_all(\"h3\")))\n",
    "        estimated_pages = math.ceil(total_listings / per_page_guess) if total_listings else None\n",
    "        total_pages = int(estimated_pages) if estimated_pages else 200\n",
    "        if MAX_PAGES_OVERRIDE:\n",
    "            total_pages = MAX_PAGES_OVERRIDE\n",
    "\n",
    "        print(f\"Detected total_listings={total_listings}, per_page_guess={per_page_guess}, total_pages={total_pages}\")\n",
    "\n",
    "        rows = []\n",
    "        seen_keys = set()\n",
    "        detail_links = []\n",
    "\n",
    "        for p in range(1, total_pages + 1):\n",
    "            page_url = START_URL.rstrip(\"/\") + \"?page=\" + str(p)\n",
    "            try:\n",
    "                driver.get(page_url)\n",
    "            except Exception:\n",
    "                time.sleep(1.0)\n",
    "                driver.get(page_url)\n",
    "\n",
    "            # scroll aggressively\n",
    "            last_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            sc = 0\n",
    "            while sc < MAX_SCROLLS:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(SCROLL_PAUSE)\n",
    "                new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_h == last_h:\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight-400);\")\n",
    "                    time.sleep(0.4)\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    time.sleep(0.4)\n",
    "                    new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                    if new_h == last_h:\n",
    "                        break\n",
    "                last_h = new_h\n",
    "                sc += 1\n",
    "\n",
    "            page_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            titles = page_soup.find_all(\"h3\")\n",
    "            for h in titles:\n",
    "                title = text_of(h)\n",
    "                if not title:\n",
    "                    continue\n",
    "\n",
    "                container = h\n",
    "                card_text = \"\"\n",
    "                link = \"\"\n",
    "                for _ in range(6):\n",
    "                    if container is None:\n",
    "                        break\n",
    "                    card_text = text_of(container)\n",
    "                    if \"₹\" in card_text or re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I):\n",
    "                        a = container.find(\"a\", href=True)\n",
    "                        if a:\n",
    "                            href = a[\"href\"]\n",
    "                            link = href if \"cardekho.com\" in href else urljoin(page_url, href)\n",
    "                            link = link.split(\"#\")[0].split(\"?utm\")[0]\n",
    "                        break\n",
    "                    container = container.parent\n",
    "\n",
    "                if not card_text:\n",
    "                    parent = h.parent\n",
    "                    card_text = text_of(parent) if parent else title\n",
    "\n",
    "                if (\"₹\" not in card_text) and (re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I) is None):\n",
    "                    continue\n",
    "\n",
    "                price_card = extract_price_from_text(card_text)\n",
    "                key = (title + \"||\" + (price_card or \"\")).strip()\n",
    "                if key in seen_keys:\n",
    "                    continue\n",
    "                seen_keys.add(key)\n",
    "\n",
    "                kms = extract_kms(card_text)\n",
    "                fuel = extract_fuel(card_text)\n",
    "                year = extract_year(title) or extract_year(card_text)\n",
    "                brand = \"\"\n",
    "                model = \"\"\n",
    "                try:\n",
    "                    brand, model = guess_brand_and_model(title)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                rows.append({\n",
    "                    \"Car_name\": title,\n",
    "                    \"brand\": brand,\n",
    "                    \"model\": model,\n",
    "                    \"kms_driven\": kms,\n",
    "                    \"mileage\": \"\",\n",
    "                    \"transmission\": \"\",\n",
    "                    \"fuel_type\": fuel,\n",
    "                    \"year_of_manufacture\": year,\n",
    "                    \"price\": price_card,\n",
    "                    \"detail_page\": link\n",
    "                })\n",
    "\n",
    "                if link:\n",
    "                    detail_links.append(link)\n",
    "\n",
    "            time.sleep(random.uniform(*PAGE_PAUSE))\n",
    "\n",
    "            if total_listings and len(seen_keys) >= total_listings:\n",
    "                print(\"Reached detected total listings; stopping page scan.\")\n",
    "                break\n",
    "\n",
    "            if p % 10 == 0:\n",
    "                print(f\"Scanned page {p}; rows so far: {len(rows)}\")\n",
    "\n",
    "        print(f\"Collected {len(rows)} card-level rows, detail links: {len(set(detail_links))}\")\n",
    "\n",
    "        # Now ensure price is filled: visit detail pages for any row missing price\n",
    "        if VISIT_DETAIL_PAGES and detail_links:\n",
    "            unique_detail_links = []\n",
    "            seen_dl = set()\n",
    "            for u in detail_links:\n",
    "                if u and u not in seen_dl:\n",
    "                    seen_dl.add(u)\n",
    "                    unique_detail_links.append(u)\n",
    "\n",
    "            # map link -> price (and optionally mileage/transmission)\n",
    "            detail_map = {}\n",
    "\n",
    "            for i, dl in enumerate(unique_detail_links):\n",
    "                # polite pause\n",
    "                if i > 0:\n",
    "                    time.sleep(random.uniform(*DETAIL_PAUSE))\n",
    "                attempt = 0\n",
    "                success = False\n",
    "                while attempt <= MAX_DETAIL_RETRIES and not success:\n",
    "                    try:\n",
    "                        driver.get(dl)\n",
    "                        time.sleep(1.0 + random.random()*0.8)\n",
    "                        dsoup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "                        # price from many possible places\n",
    "                        price_val = extract_price_from_soup(dsoup)\n",
    "                        # fallback to regex on page text\n",
    "                        if not price_val:\n",
    "                            price_val = extract_price_from_text(dsoup.get_text(\" \", strip=True))\n",
    "\n",
    "                        # mileage and transmission extraction as before\n",
    "                        page_text = dsoup.get_text(\" \", strip=True)\n",
    "                        # try meta-line near title for quick values\n",
    "                        h_tag = dsoup.find([\"h1\",\"h2\"])\n",
    "                        meta_line = \"\"\n",
    "                        if h_tag:\n",
    "                            nxt = h_tag.find_next()\n",
    "                            checks = 0\n",
    "                            while nxt and checks < 8:\n",
    "                                t = text_of(nxt)\n",
    "                                if t and ((\"kms\" in t.lower()) or (\"₹\" in t) or re.search(r'\\b\\d+\\s*(?:kmpl|km/kg|km/kwh|km/l|kpl)\\b', t, flags=re.I)):\n",
    "                                    meta_line = t\n",
    "                                    break\n",
    "                                nxt = nxt.find_next()\n",
    "                                checks += 1\n",
    "\n",
    "                        # mileage\n",
    "                        mileage_val = \"\"\n",
    "                        mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
    "                        if mnode:\n",
    "                            try:\n",
    "                                parent = mnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    mileage_val = text_of(sib)\n",
    "                            except:\n",
    "                                mileage_val = \"\"\n",
    "                        if not mileage_val:\n",
    "                            # check meta_line then page_text\n",
    "                            mileage_val = extract_mileage(meta_line or page_text) or extract_mileage(page_text)\n",
    "\n",
    "                        # transmission\n",
    "                        trans_val = \"\"\n",
    "                        tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n",
    "                        if tnode:\n",
    "                            try:\n",
    "                                parent = tnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    trans_val = text_of(sib)\n",
    "                            except:\n",
    "                                trans_val = \"\"\n",
    "                        if not trans_val:\n",
    "                            trans_val = extract_transmission(meta_line or page_text)\n",
    "\n",
    "                        detail_map[dl] = {\n",
    "                            \"price\": price_val or \"\",\n",
    "                            \"mileage\": mileage_val or \"\",\n",
    "                            \"transmission\": trans_val or \"\"\n",
    "                        }\n",
    "                        success = True\n",
    "                    except Exception as e:\n",
    "                        attempt += 1\n",
    "                        if attempt > MAX_DETAIL_RETRIES:\n",
    "                            detail_map[dl] = {\"price\": \"\", \"mileage\": \"\", \"transmission\": \"\"}\n",
    "                            success = True\n",
    "                        else:\n",
    "                            time.sleep(0.8)\n",
    "\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print(f\"Processed {i+1} detail pages...\")\n",
    "\n",
    "            # merge into rows\n",
    "            for r in rows:\n",
    "                link = r.get(\"detail_page\", \"\")\n",
    "                if link and link in detail_map:\n",
    "                    # prefer detail price if card-level empty\n",
    "                    if not r.get(\"price\"):\n",
    "                        r[\"price\"] = detail_map[link][\"price\"]\n",
    "                    # always try to fill mileage/trans if available\n",
    "                    if not r.get(\"mileage\"):\n",
    "                        r[\"mileage\"] = detail_map[link][\"mileage\"]\n",
    "                    if not r.get(\"transmission\"):\n",
    "                        r[\"transmission\"] = detail_map[link][\"transmission\"]\n",
    "\n",
    "        # final normalization\n",
    "        df = pd.DataFrame(rows, columns=[\n",
    "            \"Car_name\",\"brand\",\"model\",\"kms_driven\",\"mileage\",\"transmission\",\"fuel_type\",\"year_of_manufacture\",\"price\",\"detail_page\"\n",
    "        ])\n",
    "        df[\"kms_driven\"] = df[\"kms_driven\"].fillna(\"\").astype(str).apply(lambda x: re.sub(r'[^\\d\\.]', '', x))\n",
    "        df[\"mileage\"] = df[\"mileage\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"transmission\"] = df[\"transmission\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "        df[\"year_of_manufacture\"] = df[\"year_of_manufacture\"].fillna(\"\").astype(str).apply(lambda x: (re.search(r'\\b(19|20)\\d{2}\\b', x).group(0) if re.search(r'\\b(19|20)\\d{2}\\b', x) else \"\"))\n",
    "        df[\"price\"] = df[\"price\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"fuel_type\"] = df[\"fuel_type\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "\n",
    "        # dedupe\n",
    "        if \"detail_page\" in df.columns and df[\"detail_page\"].str.len().sum() > 0:\n",
    "            df = df.drop_duplicates(subset=[\"detail_page\"]).reset_index(drop=True)\n",
    "        else:\n",
    "            df = df.drop_duplicates(subset=[\"Car_name\",\"price\"]).reset_index(drop=True)\n",
    "\n",
    "        # save\n",
    "        df.to_csv(OUTPUT_CSV, index=False)\n",
    "        df.to_excel(OUTPUT_XLSX, index=False)\n",
    "        print(f\"Saved {len(df)} rows to {OUTPUT_CSV} and {OUTPUT_XLSX}\")\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# helpers used in detail extraction (mileage/transmission)\n",
    "def extract_mileage(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # reuse a robust regex set (common patterns)\n",
    "    m = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|km/kg|km/kwh|km/l|kpl|km)', text, flags=re.I)\n",
    "    if m:\n",
    "        return f\"{m.group(1)} {m.group(2)}\".strip()\n",
    "    m2 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(mpg)\\b', text, flags=re.I)\n",
    "    if m2:\n",
    "        return f\"{m2.group(1)} {m2.group(2)}\"\n",
    "    return \"\"\n",
    "\n",
    "def extract_transmission(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    for t in [\"Manual\",\"Automatic\",\"CVT\",\"AMT\",\"DCT\",\"AT\",\"MT\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', text, flags=re.I):\n",
    "            if t.upper() in (\"AT\",\"AMT\",\"CVT\",\"DCT\",\"MT\"):\n",
    "                return t.upper()\n",
    "            return t.title()\n",
    "    return \"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c302d482-8028-441e-ac7f-92a01fa40457",
   "metadata": {},
   "source": [
    "3rd stage of scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e0dbcc8-c280-4d84-b7fe-3885a635e6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected total_listings=2644, per_page_guess=66, total_pages_to_try=41\n",
      "Scanned page 10; collected cards so far: 256\n",
      "Scanned page 20; collected cards so far: 327\n",
      "Scanned page 30; collected cards so far: 397\n",
      "Scanned page 40; collected cards so far: 397\n",
      "Initial collection done: 408 card rows, detail links discovered: 381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_32952\\2270936370.py:285: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  label_kms = dsoup.find(text=re.compile(r'Kms\\s*Driven|Kms|Odometer', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_32952\\2270936370.py:302: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  label_fuel = dsoup.find(text=re.compile(r'Fuel\\s*Type|Fuel', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_32952\\2270936370.py:316: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  label_year = dsoup.find(text=re.compile(r'Year\\s*of\\s*Manufacture|Registration\\s*Year|Year', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_32952\\2270936370.py:339: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved after 200 detail visits: 203 rows.\n",
      "Saved cleaned output: cardekho_used_cars_pune_clean_fixed.csv and cardekho_used_cars_pune_clean_fixed.xlsx\n",
      "Total rows collected: 382\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_name</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>kms_driven</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>year_of_manufacture</th>\n",
       "      <th>price</th>\n",
       "      <th>mileage</th>\n",
       "      <th>detail_page</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025 MG Windsor EV Exclusive</td>\n",
       "      <td>MG</td>\n",
       "      <td>2025  Windsor EV Exclusive</td>\n",
       "      <td>2025147520252000073034848955597598891</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2025</td>\n",
       "      <td>₹14.75 Lakh</td>\n",
       "      <td>20,000 kms • Electric • Automatic • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022 Maruti Celerio VXI CNG</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2022  Celerio VXI CNG</td>\n",
       "      <td>2022998486202220172021203004868345361451023911...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2022</td>\n",
       "      <td>₹4.86 Lakh</td>\n",
       "      <td>20,307 kms • CNG • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022 Kia Sonet HTX Turbo iMT</td>\n",
       "      <td>Kia</td>\n",
       "      <td>2022  Sonet HTX Turbo iMT</td>\n",
       "      <td>20229989402022333009407973827146850488497</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2022</td>\n",
       "      <td>₹9.40 Lakh with Discounted</td>\n",
       "      <td>33,281 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>179 Used Cars Under 2 Lakh in Pune</td>\n",
       "      <td>179</td>\n",
       "      <td>Used Cars Under 2 Lakh in Pune</td>\n",
       "      <td>1792202</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2009</td>\n",
       "      <td>₹2 Lakh</td>\n",
       "      <td>179 used cars Under 2 Lakh are available for s...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+0-lakh-to-2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>330 Used Cars Under 3 Lakh in Pune</td>\n",
       "      <td>330</td>\n",
       "      <td>Used Cars Under 3 Lakh in Pune</td>\n",
       "      <td>3303323</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2012</td>\n",
       "      <td>₹2.10 Lakh</td>\n",
       "      <td>330 used cars Under 3 Lakh are available for s...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+2-lakh-to-3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>804 Used Cars Under 5 Lakh in Pune</td>\n",
       "      <td>804</td>\n",
       "      <td>Used Cars Under 5 Lakh in Pune</td>\n",
       "      <td>8045535</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2017</td>\n",
       "      <td>₹3.14 Lakh</td>\n",
       "      <td>804 used cars Under 5 Lakh are available for s...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+3-lakh-to-5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>654 Used Cars Under 8 Lakh in Pune</td>\n",
       "      <td>654</td>\n",
       "      <td>Used Cars Under 8 Lakh in Pune</td>\n",
       "      <td>6548858</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2022</td>\n",
       "      <td>₹6.50 Lakh</td>\n",
       "      <td>654 used cars Under 8 Lakh are available for s...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+5-lakh-to-8...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>222 Used Cars Under 10 Lakh in Pune</td>\n",
       "      <td>222</td>\n",
       "      <td>Used Cars Under 10 Lakh in Pune</td>\n",
       "      <td>2221010810</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2024</td>\n",
       "      <td>₹8.20 Lakh</td>\n",
       "      <td>222 used cars Under 10 Lakh are available for ...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+8-lakh-to-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>460 Used Cars Above 10 Lakh in Pune</td>\n",
       "      <td>460</td>\n",
       "      <td>Used Cars Above 10 Lakh in Pune</td>\n",
       "      <td>4601010105</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹11.50 Lakh</td>\n",
       "      <td>460 used cars Above 10 Lakh are available for ...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+10-lakh-to-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023 Kia Sonet HTX Turbo iMT</td>\n",
       "      <td>Kia</td>\n",
       "      <td>2023  Sonet HTX Turbo iMT</td>\n",
       "      <td>2023998962202325000962327717841480313906945</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2023</td>\n",
       "      <td>₹9.62 Lakh with Discounted</td>\n",
       "      <td>24,978 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024 Tata Nexon Creative Dark Diesel AMT</td>\n",
       "      <td>Tata</td>\n",
       "      <td>2024  Nexon Creative Dark Diesel AMT</td>\n",
       "      <td>2024132024100002886354460608390</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2024</td>\n",
       "      <td>₹13 Lakh</td>\n",
       "      <td>10,000 kms • Diesel • Automatic • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025 Mercedes-Benz GLC 220d</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>2025  GLC 220d</td>\n",
       "      <td>2025199372202522010000722209643214943207093692...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2025</td>\n",
       "      <td>₹72 Lakh with Almost New</td>\n",
       "      <td>10,000 kms • Diesel • Automatic • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022 Kia Seltos HTX</td>\n",
       "      <td>Kia</td>\n",
       "      <td>2022  Seltos HTX</td>\n",
       "      <td>20221497952202253009523805196049514915377</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2022</td>\n",
       "      <td>₹9.52 Lakh with Less Driven</td>\n",
       "      <td>5,291 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024 Kia Seltos HTX Diesel iMT</td>\n",
       "      <td>Kia</td>\n",
       "      <td>2024  Seltos HTX Diesel iMT</td>\n",
       "      <td>202417202420192023130003070054194548965646</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2024</td>\n",
       "      <td>₹17 Lakh</td>\n",
       "      <td>13,000 kms • Diesel • Automatic • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023 Maruti Grand Vitara Zeta</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2023  Grand Vitara Zeta</td>\n",
       "      <td>202312202323000823346957444929742592685</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2023</td>\n",
       "      <td>₹12 Lakh</td>\n",
       "      <td>23,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022 Jeep Compass 1.4 Anniversary Edition DCT ...</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>2022  Compass 1.4 Anniversary Edition DCT BSVI</td>\n",
       "      <td>20221575202214600001432034949456332774</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2022</td>\n",
       "      <td>₹15.75 Lakh</td>\n",
       "      <td>60,000 kms • Petrol • Automatic • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023 MG Astor Super MT</td>\n",
       "      <td>MG</td>\n",
       "      <td>2023  Astor Super MT</td>\n",
       "      <td>2023102023130000338676645848875223</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2023</td>\n",
       "      <td>₹10 Lakh</td>\n",
       "      <td>13,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2011 Hyundai i20 1.2 Sportz</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2011  i20 1.2 Sportz</td>\n",
       "      <td>2011202802011202010201212150000201271270242574...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2011</td>\n",
       "      <td>₹2.80 Lakh</td>\n",
       "      <td>1,50,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022 Honda City V MT</td>\n",
       "      <td>Honda</td>\n",
       "      <td>2022  City V MT</td>\n",
       "      <td>202285020222020202350000800416358442598841853961</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2022</td>\n",
       "      <td>₹8.50 Lakh</td>\n",
       "      <td>50,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021 Hyundai Alcazar Platinum 7-Seater Diesel ...</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2021  Alcazar Platinum 7-Seater Diesel BSVI</td>\n",
       "      <td>2021162021202120247400007194991540559177980605</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹16 Lakh</td>\n",
       "      <td>40,000 kms • Diesel • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022 Tata Nexon EV XZ Plus</td>\n",
       "      <td>Tata</td>\n",
       "      <td>2022  Nexon EV XZ Plus</td>\n",
       "      <td>2022875202220202023700007295620749394197127673</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2022</td>\n",
       "      <td>₹8.75 Lakh</td>\n",
       "      <td>70,000 kms • Electric • Automatic • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017 Ford Ecosport 1.0 Ecoboost Titanium Plus ...</td>\n",
       "      <td>Ford</td>\n",
       "      <td>2017  Ecosport 1.0 Ecoboost Titanium Plus BSIV</td>\n",
       "      <td>201747020172015202110780001087646243858354634004</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2017</td>\n",
       "      <td>₹4.70 Lakh</td>\n",
       "      <td>78,000 kms • Petrol • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>804 Used Cars Under 5 Lakh in Pune</td>\n",
       "      <td>804</td>\n",
       "      <td>Used Cars Under 5 Lakh in Pune</td>\n",
       "      <td>8045535</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2017</td>\n",
       "      <td>₹3.14 Lakh</td>\n",
       "      <td>804 used cars Under 5 Lakh are available for s...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+2-lakh-to-5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>211 Used Cars in Pune With Search Options</td>\n",
       "      <td>211</td>\n",
       "      <td>Used Cars in Pune With Search Options</td>\n",
       "      <td>020000</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2023</td>\n",
       "      <td>₹90,000  in Pune. The most popular used cars a...</td>\n",
       "      <td>000 km</td>\n",
       "      <td>https://www.cardekho.com/used-cars+0-20000-km+...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021 Kia Seltos HTX</td>\n",
       "      <td>Kia</td>\n",
       "      <td>2021  Seltos HTX</td>\n",
       "      <td>2021149781920213170081937118266492289570875100</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹8.19 Lakh with Discounted</td>\n",
       "      <td>31,717 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021 Renault Kiger RXZ</td>\n",
       "      <td>Renault</td>\n",
       "      <td>2021  Kiger RXZ</td>\n",
       "      <td>2021999598202120232025147005987021699949884217</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹5.98 Lakh with Less Driven</td>\n",
       "      <td>14,693 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023 Kia Seltos X-Line DCT</td>\n",
       "      <td>Kia</td>\n",
       "      <td>2023  Seltos X-Line DCT</td>\n",
       "      <td>20231520232019202330000034620910454953147694</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2023</td>\n",
       "      <td>₹15 Lakh</td>\n",
       "      <td>30,000 kms • Petrol • Automatic • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023 Maruti FRONX Zeta Turbo</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2023  FRONX Zeta Turbo</td>\n",
       "      <td>20239988792023258008793649419240899900802720923</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2023</td>\n",
       "      <td>₹8.79 Lakh</td>\n",
       "      <td>25,758 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023 Kia Seltos HTX IVT</td>\n",
       "      <td>Kia</td>\n",
       "      <td>2023  Seltos HTX IVT</td>\n",
       "      <td>202314971550202342400155040567424979219261238</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2023</td>\n",
       "      <td>₹15.50 Lakh</td>\n",
       "      <td>42,389 kms • Petrol • Automatic • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2015 Hyundai Creta 1.6 EX Petrol</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2015  Creta 1.6 EX Petrol</td>\n",
       "      <td>2015159160220152015202016573006021687237881424...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2015</td>\n",
       "      <td>₹6.02 Lakh</td>\n",
       "      <td>57,284 kms • Petrol • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020 Kia Seltos GTX Plus Diesel AT</td>\n",
       "      <td>Kia</td>\n",
       "      <td>2020  Seltos GTX Plus Diesel AT</td>\n",
       "      <td>20201250202020192023600000961204867740921</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2020</td>\n",
       "      <td>₹12.50 Lakh</td>\n",
       "      <td>60,000 kms • Diesel • Automatic • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021 Renault Kiger RXT Turbo</td>\n",
       "      <td>Renault</td>\n",
       "      <td>2021  Kiger RXT Turbo</td>\n",
       "      <td>202199959720212021202318500597237694823855540235</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹5.97 Lakh</td>\n",
       "      <td>18,496 kms • Petrol • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020 Maruti S-Presso VXI</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2020  S-Presso VXI</td>\n",
       "      <td>202099834420202790034465814237695722787</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2020</td>\n",
       "      <td>₹3.44 Lakh with Discounted</td>\n",
       "      <td>27,941 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021 Nissan Magnite XE BSVI</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>2021  Magnite XE BSVI</td>\n",
       "      <td>2021999415202120202024460004158865713459575434...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹4.15 Lakh</td>\n",
       "      <td>46,045 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2011 Maruti Wagon R VXI</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2011  Wagon R VXI</td>\n",
       "      <td>201199824220113330024219252234440696114978207</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2011</td>\n",
       "      <td>₹2.42 Lakh with Discounted</td>\n",
       "      <td>33,307 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2022 Skoda Kushaq 1.0 TSI Style BSVI</td>\n",
       "      <td>Skoda</td>\n",
       "      <td>2022  Kushaq 1.0 TSI Style BSVI</td>\n",
       "      <td>20221150202210170001082855567745436735508195</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2022</td>\n",
       "      <td>₹11.50 Lakh</td>\n",
       "      <td>17,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024 Toyota Glanza V</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>2024  Glanza V</td>\n",
       "      <td>202411978522024132008529909212345887013335</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2024</td>\n",
       "      <td>₹8.52 Lakh with Less Driven</td>\n",
       "      <td>13,191 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019 Honda Amaze V Petrol BSIV</td>\n",
       "      <td>Honda</td>\n",
       "      <td>2019  Amaze V Petrol BSIV</td>\n",
       "      <td>2019119957820192016202137000578694742373405691...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2019</td>\n",
       "      <td>₹5.78 Lakh</td>\n",
       "      <td>36,981 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2021 Maruti S-Presso VXI Plus AT 2019-2022</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2021  S-Presso VXI Plus AT 2019-2022</td>\n",
       "      <td>2021998372202120192022259003722019202283926057...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹3.72 Lakh with Discounted</td>\n",
       "      <td>25,937 kms • Petrol • Automatic • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/buy-used-car-details/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2014 Honda City i VTEC V</td>\n",
       "      <td>Honda</td>\n",
       "      <td>2014  City i VTEC V</td>\n",
       "      <td>201449020142014201561000347038614803784290</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2014</td>\n",
       "      <td>₹4.90 Lakh</td>\n",
       "      <td>61,000 kms • Petrol • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Car_name          brand  \\\n",
       "0                        2025 MG Windsor EV Exclusive             MG   \n",
       "1                         2022 Maruti Celerio VXI CNG         Maruti   \n",
       "2                        2022 Kia Sonet HTX Turbo iMT            Kia   \n",
       "3                  179 Used Cars Under 2 Lakh in Pune            179   \n",
       "4                  330 Used Cars Under 3 Lakh in Pune            330   \n",
       "5                  804 Used Cars Under 5 Lakh in Pune            804   \n",
       "6                  654 Used Cars Under 8 Lakh in Pune            654   \n",
       "7                 222 Used Cars Under 10 Lakh in Pune            222   \n",
       "8                 460 Used Cars Above 10 Lakh in Pune            460   \n",
       "9                        2023 Kia Sonet HTX Turbo iMT            Kia   \n",
       "10           2024 Tata Nexon Creative Dark Diesel AMT           Tata   \n",
       "11                        2025 Mercedes-Benz GLC 220d  Mercedes-Benz   \n",
       "12                                2022 Kia Seltos HTX            Kia   \n",
       "13                     2024 Kia Seltos HTX Diesel iMT            Kia   \n",
       "14                      2023 Maruti Grand Vitara Zeta         Maruti   \n",
       "15  2022 Jeep Compass 1.4 Anniversary Edition DCT ...           Jeep   \n",
       "16                             2023 MG Astor Super MT             MG   \n",
       "17                        2011 Hyundai i20 1.2 Sportz        Hyundai   \n",
       "18                               2022 Honda City V MT          Honda   \n",
       "19  2021 Hyundai Alcazar Platinum 7-Seater Diesel ...        Hyundai   \n",
       "20                         2022 Tata Nexon EV XZ Plus           Tata   \n",
       "21  2017 Ford Ecosport 1.0 Ecoboost Titanium Plus ...           Ford   \n",
       "22                 804 Used Cars Under 5 Lakh in Pune            804   \n",
       "23          211 Used Cars in Pune With Search Options            211   \n",
       "24                                2021 Kia Seltos HTX            Kia   \n",
       "25                             2021 Renault Kiger RXZ        Renault   \n",
       "26                         2023 Kia Seltos X-Line DCT            Kia   \n",
       "27                       2023 Maruti FRONX Zeta Turbo         Maruti   \n",
       "28                            2023 Kia Seltos HTX IVT            Kia   \n",
       "29                   2015 Hyundai Creta 1.6 EX Petrol        Hyundai   \n",
       "30                 2020 Kia Seltos GTX Plus Diesel AT            Kia   \n",
       "31                       2021 Renault Kiger RXT Turbo        Renault   \n",
       "32                           2020 Maruti S-Presso VXI         Maruti   \n",
       "33                        2021 Nissan Magnite XE BSVI         Nissan   \n",
       "34                            2011 Maruti Wagon R VXI         Maruti   \n",
       "35               2022 Skoda Kushaq 1.0 TSI Style BSVI          Skoda   \n",
       "36                               2024 Toyota Glanza V         Toyota   \n",
       "37                     2019 Honda Amaze V Petrol BSIV          Honda   \n",
       "38         2021 Maruti S-Presso VXI Plus AT 2019-2022         Maruti   \n",
       "39                           2014 Honda City i VTEC V          Honda   \n",
       "\n",
       "                                             model  \\\n",
       "0                       2025  Windsor EV Exclusive   \n",
       "1                            2022  Celerio VXI CNG   \n",
       "2                        2022  Sonet HTX Turbo iMT   \n",
       "3                   Used Cars Under 2 Lakh in Pune   \n",
       "4                   Used Cars Under 3 Lakh in Pune   \n",
       "5                   Used Cars Under 5 Lakh in Pune   \n",
       "6                   Used Cars Under 8 Lakh in Pune   \n",
       "7                  Used Cars Under 10 Lakh in Pune   \n",
       "8                  Used Cars Above 10 Lakh in Pune   \n",
       "9                        2023  Sonet HTX Turbo iMT   \n",
       "10            2024  Nexon Creative Dark Diesel AMT   \n",
       "11                                  2025  GLC 220d   \n",
       "12                                2022  Seltos HTX   \n",
       "13                     2024  Seltos HTX Diesel iMT   \n",
       "14                         2023  Grand Vitara Zeta   \n",
       "15  2022  Compass 1.4 Anniversary Edition DCT BSVI   \n",
       "16                            2023  Astor Super MT   \n",
       "17                            2011  i20 1.2 Sportz   \n",
       "18                                 2022  City V MT   \n",
       "19     2021  Alcazar Platinum 7-Seater Diesel BSVI   \n",
       "20                          2022  Nexon EV XZ Plus   \n",
       "21  2017  Ecosport 1.0 Ecoboost Titanium Plus BSIV   \n",
       "22                  Used Cars Under 5 Lakh in Pune   \n",
       "23           Used Cars in Pune With Search Options   \n",
       "24                                2021  Seltos HTX   \n",
       "25                                 2021  Kiger RXZ   \n",
       "26                         2023  Seltos X-Line DCT   \n",
       "27                          2023  FRONX Zeta Turbo   \n",
       "28                            2023  Seltos HTX IVT   \n",
       "29                       2015  Creta 1.6 EX Petrol   \n",
       "30                 2020  Seltos GTX Plus Diesel AT   \n",
       "31                           2021  Kiger RXT Turbo   \n",
       "32                              2020  S-Presso VXI   \n",
       "33                           2021  Magnite XE BSVI   \n",
       "34                               2011  Wagon R VXI   \n",
       "35                 2022  Kushaq 1.0 TSI Style BSVI   \n",
       "36                                  2024  Glanza V   \n",
       "37                       2019  Amaze V Petrol BSIV   \n",
       "38            2021  S-Presso VXI Plus AT 2019-2022   \n",
       "39                             2014  City i VTEC V   \n",
       "\n",
       "                                           kms_driven  \\\n",
       "0               2025147520252000073034848955597598891   \n",
       "1   2022998486202220172021203004868345361451023911...   \n",
       "2           20229989402022333009407973827146850488497   \n",
       "3                                             1792202   \n",
       "4                                             3303323   \n",
       "5                                             8045535   \n",
       "6                                             6548858   \n",
       "7                                          2221010810   \n",
       "8                                          4601010105   \n",
       "9         2023998962202325000962327717841480313906945   \n",
       "10                    2024132024100002886354460608390   \n",
       "11  2025199372202522010000722209643214943207093692...   \n",
       "12          20221497952202253009523805196049514915377   \n",
       "13         202417202420192023130003070054194548965646   \n",
       "14            202312202323000823346957444929742592685   \n",
       "15             20221575202214600001432034949456332774   \n",
       "16                 2023102023130000338676645848875223   \n",
       "17  2011202802011202010201212150000201271270242574...   \n",
       "18   202285020222020202350000800416358442598841853961   \n",
       "19     2021162021202120247400007194991540559177980605   \n",
       "20     2022875202220202023700007295620749394197127673   \n",
       "21   201747020172015202110780001087646243858354634004   \n",
       "22                                            8045535   \n",
       "23                                             020000   \n",
       "24     2021149781920213170081937118266492289570875100   \n",
       "25     2021999598202120232025147005987021699949884217   \n",
       "26       20231520232019202330000034620910454953147694   \n",
       "27    20239988792023258008793649419240899900802720923   \n",
       "28      202314971550202342400155040567424979219261238   \n",
       "29  2015159160220152015202016573006021687237881424...   \n",
       "30          20201250202020192023600000961204867740921   \n",
       "31   202199959720212021202318500597237694823855540235   \n",
       "32            202099834420202790034465814237695722787   \n",
       "33  2021999415202120202024460004158865713459575434...   \n",
       "34      201199824220113330024219252234440696114978207   \n",
       "35       20221150202210170001082855567745436735508195   \n",
       "36         202411978522024132008529909212345887013335   \n",
       "37  2019119957820192016202137000578694742373405691...   \n",
       "38  2021998372202120192022259003722019202283926057...   \n",
       "39         201449020142014201561000347038614803784290   \n",
       "\n",
       "                                            fuel_type year_of_manufacture  \\\n",
       "0   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2025   \n",
       "1   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2022   \n",
       "2   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2022   \n",
       "3   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2009   \n",
       "4   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2012   \n",
       "5   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2017   \n",
       "6   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2022   \n",
       "7   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2024   \n",
       "8   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "9   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2023   \n",
       "10  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2024   \n",
       "11  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2025   \n",
       "12  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2022   \n",
       "13  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2024   \n",
       "14  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2023   \n",
       "15  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2022   \n",
       "16  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2023   \n",
       "17  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2011   \n",
       "18  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2022   \n",
       "19  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "20  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2022   \n",
       "21  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2017   \n",
       "22  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2017   \n",
       "23  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2023   \n",
       "24  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "25  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "26  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2023   \n",
       "27  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2023   \n",
       "28  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2023   \n",
       "29  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2015   \n",
       "30  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2020   \n",
       "31  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "32  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2020   \n",
       "33  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "34  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2011   \n",
       "35  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2022   \n",
       "36  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2024   \n",
       "37  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2019   \n",
       "38  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "39  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2014   \n",
       "\n",
       "                                                price  \\\n",
       "0                                         ₹14.75 Lakh   \n",
       "1                                          ₹4.86 Lakh   \n",
       "2                          ₹9.40 Lakh with Discounted   \n",
       "3                                             ₹2 Lakh   \n",
       "4                                          ₹2.10 Lakh   \n",
       "5                                          ₹3.14 Lakh   \n",
       "6                                          ₹6.50 Lakh   \n",
       "7                                          ₹8.20 Lakh   \n",
       "8                                         ₹11.50 Lakh   \n",
       "9                          ₹9.62 Lakh with Discounted   \n",
       "10                                           ₹13 Lakh   \n",
       "11                           ₹72 Lakh with Almost New   \n",
       "12                        ₹9.52 Lakh with Less Driven   \n",
       "13                                           ₹17 Lakh   \n",
       "14                                           ₹12 Lakh   \n",
       "15                                        ₹15.75 Lakh   \n",
       "16                                           ₹10 Lakh   \n",
       "17                                         ₹2.80 Lakh   \n",
       "18                                         ₹8.50 Lakh   \n",
       "19                                           ₹16 Lakh   \n",
       "20                                         ₹8.75 Lakh   \n",
       "21                                         ₹4.70 Lakh   \n",
       "22                                         ₹3.14 Lakh   \n",
       "23  ₹90,000  in Pune. The most popular used cars a...   \n",
       "24                         ₹8.19 Lakh with Discounted   \n",
       "25                        ₹5.98 Lakh with Less Driven   \n",
       "26                                           ₹15 Lakh   \n",
       "27                                         ₹8.79 Lakh   \n",
       "28                                        ₹15.50 Lakh   \n",
       "29                                         ₹6.02 Lakh   \n",
       "30                                        ₹12.50 Lakh   \n",
       "31                                         ₹5.97 Lakh   \n",
       "32                         ₹3.44 Lakh with Discounted   \n",
       "33                                         ₹4.15 Lakh   \n",
       "34                         ₹2.42 Lakh with Discounted   \n",
       "35                                        ₹11.50 Lakh   \n",
       "36                        ₹8.52 Lakh with Less Driven   \n",
       "37                                         ₹5.78 Lakh   \n",
       "38                         ₹3.72 Lakh with Discounted   \n",
       "39                                         ₹4.90 Lakh   \n",
       "\n",
       "                                              mileage  \\\n",
       "0       20,000 kms • Electric • Automatic • 1st Owner   \n",
       "1               20,307 kms • CNG • Manual • 2nd Owner   \n",
       "2            33,281 kms • Petrol • Manual • 1st Owner   \n",
       "3   179 used cars Under 2 Lakh are available for s...   \n",
       "4   330 used cars Under 3 Lakh are available for s...   \n",
       "5   804 used cars Under 5 Lakh are available for s...   \n",
       "6   654 used cars Under 8 Lakh are available for s...   \n",
       "7   222 used cars Under 10 Lakh are available for ...   \n",
       "8   460 used cars Above 10 Lakh are available for ...   \n",
       "9            24,978 kms • Petrol • Manual • 1st Owner   \n",
       "10        10,000 kms • Diesel • Automatic • 1st Owner   \n",
       "11        10,000 kms • Diesel • Automatic • 1st Owner   \n",
       "12            5,291 kms • Petrol • Manual • 1st Owner   \n",
       "13        13,000 kms • Diesel • Automatic • 1st Owner   \n",
       "14           23,000 kms • Petrol • Manual • 1st Owner   \n",
       "15        60,000 kms • Petrol • Automatic • 1st Owner   \n",
       "16           13,000 kms • Petrol • Manual • 1st Owner   \n",
       "17         1,50,000 kms • Petrol • Manual • 1st Owner   \n",
       "18           50,000 kms • Petrol • Manual • 1st Owner   \n",
       "19           40,000 kms • Diesel • Manual • 1st Owner   \n",
       "20      70,000 kms • Electric • Automatic • 1st Owner   \n",
       "21           78,000 kms • Petrol • Manual • 2nd Owner   \n",
       "22  804 used cars Under 5 Lakh are available for s...   \n",
       "23                                             000 km   \n",
       "24           31,717 kms • Petrol • Manual • 1st Owner   \n",
       "25           14,693 kms • Petrol • Manual • 1st Owner   \n",
       "26        30,000 kms • Petrol • Automatic • 1st Owner   \n",
       "27           25,758 kms • Petrol • Manual • 1st Owner   \n",
       "28        42,389 kms • Petrol • Automatic • 1st Owner   \n",
       "29           57,284 kms • Petrol • Manual • 2nd Owner   \n",
       "30        60,000 kms • Diesel • Automatic • 1st Owner   \n",
       "31           18,496 kms • Petrol • Manual • 2nd Owner   \n",
       "32           27,941 kms • Petrol • Manual • 1st Owner   \n",
       "33           46,045 kms • Petrol • Manual • 1st Owner   \n",
       "34           33,307 kms • Petrol • Manual • 1st Owner   \n",
       "35           17,000 kms • Petrol • Manual • 1st Owner   \n",
       "36           13,191 kms • Petrol • Manual • 1st Owner   \n",
       "37           36,981 kms • Petrol • Manual • 1st Owner   \n",
       "38        25,937 kms • Petrol • Automatic • 1st Owner   \n",
       "39           61,000 kms • Petrol • Manual • 2nd Owner   \n",
       "\n",
       "                                          detail_page  page  \n",
       "0   https://www.cardekho.com/used-car-details/used...     1  \n",
       "1   https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "2   https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "3   https://www.cardekho.com/used-cars+0-lakh-to-2...     1  \n",
       "4   https://www.cardekho.com/used-cars+2-lakh-to-3...     1  \n",
       "5   https://www.cardekho.com/used-cars+3-lakh-to-5...     1  \n",
       "6   https://www.cardekho.com/used-cars+5-lakh-to-8...     1  \n",
       "7   https://www.cardekho.com/used-cars+8-lakh-to-1...     1  \n",
       "8   https://www.cardekho.com/used-cars+10-lakh-to-...     1  \n",
       "9   https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "10  https://www.cardekho.com/used-car-details/used...     1  \n",
       "11  https://www.cardekho.com/used-car-details/used...     1  \n",
       "12  https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "13  https://www.cardekho.com/used-car-details/used...     1  \n",
       "14  https://www.cardekho.com/used-car-details/used...     1  \n",
       "15  https://www.cardekho.com/used-car-details/used...     1  \n",
       "16  https://www.cardekho.com/used-car-details/used...     1  \n",
       "17  https://www.cardekho.com/used-car-details/used...     1  \n",
       "18  https://www.cardekho.com/used-car-details/used...     1  \n",
       "19  https://www.cardekho.com/used-car-details/used...     1  \n",
       "20  https://www.cardekho.com/used-car-details/used...     1  \n",
       "21  https://www.cardekho.com/used-car-details/used...     1  \n",
       "22  https://www.cardekho.com/used-cars+2-lakh-to-5...     1  \n",
       "23  https://www.cardekho.com/used-cars+0-20000-km+...     1  \n",
       "24  https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "25  https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "26  https://www.cardekho.com/used-car-details/used...     1  \n",
       "27  https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "28  https://www.cardekho.com/used-car-details/used...     1  \n",
       "29  https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "30  https://www.cardekho.com/used-car-details/used...     1  \n",
       "31  https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "32  https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "33  https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "34  https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "35  https://www.cardekho.com/used-car-details/used...     1  \n",
       "36  https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "37  https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "38  https://www.cardekho.com/buy-used-car-details/...     1  \n",
       "39  https://www.cardekho.com/used-car-details/used...     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Jupyter cell: Clean Selenium scraper (improved from your first working script) + mileage extraction\n",
    "# Produces: Car_name, brand, model, kms_driven, fuel_type, year_of_manufacture, price, mileage, detail_page\n",
    "# Saves to cardekho_used_cars_pune_clean_fixed.csv and .xlsx\n",
    "# Requirements: selenium, webdriver-manager, beautifulsoup4, pandas, openpyxl\n",
    "\n",
    "import re, time, random, math\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# -------------- CONFIG --------------\n",
    "START_URL = \"https://www.cardekho.com/used-cars+in+pune\"\n",
    "OUTPUT_CSV = \"cardekho_used_cars_pune_clean_fixed.csv\"\n",
    "OUTPUT_XLSX = \"cardekho_used_cars_pune_clean_fixed.xlsx\"\n",
    "HEADLESS = True               # set False to see browser for debugging\n",
    "MAX_PAGES_OVERRIDE = None     # set an int to force more pages, else auto-detect\n",
    "MAX_SCROLL_ROUNDS = 60        # number of scroll attempts per page (increase to load more)\n",
    "SCROLL_PAUSE = 0.6            # seconds between scrolls\n",
    "PAGE_PAUSE = (0.8, 1.6)       # jitter after loading a page\n",
    "# Basic brand list to split brand/model (optional)\n",
    "BRANDS = [\"Maruti\",\"Hyundai\",\"Tata\",\"Honda\",\"Toyota\",\"Mahindra\",\"Kia\",\"BMW\",\"Audi\",\"Mercedes-Benz\",\n",
    "          \"Renault\",\"MG\",\"Skoda\",\"Volkswagen\",\"Ford\",\"Nissan\",\"Jeep\",\"Volvo\",\"Land Rover\",\"Jaguar\",\n",
    "          \"Isuzu\",\"Datsun\",\"Chevrolet\",\"Opel\"]\n",
    "# -------------------------------------\n",
    "\n",
    "# helpers\n",
    "def guess_brand_and_model(title):\n",
    "    if not title: return \"\", \"\"\n",
    "    for b in BRANDS:\n",
    "        if b.lower() in title.lower():\n",
    "            brand = b\n",
    "            model = re.sub(re.escape(b), \"\", title, flags=re.IGNORECASE).strip()\n",
    "            model = re.sub(r'^[\\-\\:\\–\\—\\s]+','', model)\n",
    "            if not model:\n",
    "                model = title\n",
    "            return brand, model\n",
    "    parts = title.split()\n",
    "    return (parts[0], \" \".join(parts[1:])) if parts else (\"\",\"\")\n",
    "\n",
    "def clean_kms(k):\n",
    "    if not k: return \"\"\n",
    "    return re.sub(r'[^\\d\\.]', '', str(k))\n",
    "\n",
    "def find_rupee(text):\n",
    "    m = re.search(r'₹\\s*[\\d\\.,\\sA-Za-z]+', text)\n",
    "    return m.group(0).strip() if m else \"\"\n",
    "\n",
    "def find_kms(text):\n",
    "    m = re.search(r'([\\d,\\.]+)\\s*(?:kms|km)\\b', text, flags=re.I)\n",
    "    return m.group(1).replace(\",\",\"\") if m else \"\"\n",
    "\n",
    "def find_fuel(text):\n",
    "    for f in [\"Petrol\",\"Diesel\",\"CNG\",\"LPG\",\"Electric\",\"Hybrid\"]:\n",
    "        if re.search(r'\\b' + re.escape(f) + r'\\b', text, flags=re.I):\n",
    "            return f\n",
    "    return \"\"\n",
    "\n",
    "def find_year(text):\n",
    "    m = re.search(r'\\b(19|20)\\d{2}\\b', text)\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    "# NEW: mileage extraction helper (looks for kmpl / km/kg / km/kWh / etc.)\n",
    "def extract_mileage(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    txt = text.replace(\"\\xa0\",\" \").strip()\n",
    "    # common patterns like \"18.5 kmpl\", \"22 km/kg\", \"120 km/kWh\"\n",
    "    m = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|km/kg|km/kwh|km/l|kpl|km)', txt, flags=re.I)\n",
    "    if m:\n",
    "        val = m.group(1)\n",
    "        unit = m.group(2)\n",
    "        return f\"{val} {unit}\".strip()\n",
    "    # sometimes \"Mileage: 18.5 kmpl\" or \"18.5kmpl\" or \"ARAI mileage 18 kmpl\"\n",
    "    m2 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|kpl|km/kg|km/kwh|km/l)\\b', txt, flags=re.I)\n",
    "    if m2:\n",
    "        return f\"{m2.group(1)} {m2.group(2)}\"\n",
    "    # also check \"Mileage - 18.5\" followed by unit nearby\n",
    "    m3 = re.search(r'Mileage[:\\-\\s]*([\\d]{1,3}(?:\\.\\d+)?)', txt, flags=re.I)\n",
    "    if m3:\n",
    "        # try to find unit near the number\n",
    "        after = txt[m3.end(): m3.end()+12]\n",
    "        u = re.search(r'(kmpl|kpl|km/kg|km/kwh|km/l)', after, flags=re.I)\n",
    "        if u:\n",
    "            return f\"{m3.group(1)} {u.group(1)}\"\n",
    "        return m3.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Setup Selenium\n",
    "opts = Options()\n",
    "if HEADLESS:\n",
    "    opts.add_argument(\"--headless=new\")\n",
    "opts.add_argument(\"--no-sandbox\")\n",
    "opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "opts.add_argument(\"--window-size=1920,1080\")\n",
    "opts.add_argument(\"--disable-gpu\")\n",
    "# avoid automation flags where possible (helps some sites)\n",
    "opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=opts)\n",
    "\n",
    "try:\n",
    "    driver.get(START_URL)\n",
    "    time.sleep(2.0)\n",
    "\n",
    "    # detect total listings/pages (best-effort)\n",
    "    soup0 = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    text0 = soup0.get_text(\" \", strip=True)\n",
    "    total_listings = None\n",
    "    m = re.search(r'([\\d,]{2,})\\s+Second Hand Cars in Pune', text0, flags=re.I)\n",
    "    if not m:\n",
    "        m = re.search(r'of\\s+([\\d,]+)\\s+results', text0, flags=re.I)\n",
    "    if m:\n",
    "        total_listings = int(m.group(1).replace(\",\", \"\"))\n",
    "    per_page_guess = max(1, len(soup0.find_all(\"h3\")))\n",
    "    estimated_pages = math.ceil(total_listings / per_page_guess) if total_listings else None\n",
    "    total_pages = int(estimated_pages) if estimated_pages else 200\n",
    "    if MAX_PAGES_OVERRIDE:\n",
    "        total_pages = MAX_PAGES_OVERRIDE\n",
    "    print(f\"Detected total_listings={total_listings}, per_page_guess={per_page_guess}, total_pages_to_try={total_pages}\")\n",
    "\n",
    "    # --- collect all listing card containers (and their detail links where present) ---\n",
    "    detail_links = []\n",
    "    cards_collected = []\n",
    "    seen_links = set()\n",
    "    seen_keys = set()  # dedupe by title+price\n",
    "\n",
    "    for p in range(1, total_pages + 1):\n",
    "        page_url = START_URL.rstrip(\"/\") + \"?page=\" + str(p)\n",
    "        try:\n",
    "            driver.get(page_url)\n",
    "        except Exception:\n",
    "            time.sleep(1.0)\n",
    "            driver.get(page_url)\n",
    "        # aggressively scroll to trigger lazy-load\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        scroll_round = 0\n",
    "        while scroll_round < MAX_SCROLL_ROUNDS:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(SCROLL_PAUSE + random.random()*0.3)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                # small wiggle to force load\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight-400);\")\n",
    "                time.sleep(0.4)\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(0.4)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "            last_height = new_height\n",
    "            scroll_round += 1\n",
    "\n",
    "        # parse page to find listing *cards*\n",
    "        page_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # Heuristic: cards often contain a title (h3), price (₹) and kms text.\n",
    "        # We'll find all h3/title nodes and then locate the nearest card container around them.\n",
    "        titles = page_soup.find_all(\"h3\")\n",
    "        for h in titles:\n",
    "            title = h.get_text(\" \", strip=True)\n",
    "            if not title:\n",
    "                continue\n",
    "\n",
    "            # climb up parents to find a card-like container (max 6 levels)\n",
    "            parent = h\n",
    "            container_text = \"\"\n",
    "            detail_href = \"\"\n",
    "            for _ in range(6):\n",
    "                if parent is None:\n",
    "                    break\n",
    "                # gather text\n",
    "                txt = parent.get_text(\" \", strip=True)\n",
    "                if \"₹\" in txt or re.search(r'\\b\\d+\\s*(?:kms|km)\\b', txt, flags=re.I):\n",
    "                    container_text = txt\n",
    "                    # also try to find detail link inside this parent container\n",
    "                    a = parent.find(\"a\", href=True)\n",
    "                    if a:\n",
    "                        href = a[\"href\"]\n",
    "                        abs_href = href if \"cardekho.com\" in href else urljoin(page_url, href)\n",
    "                        detail_href = abs_href.split(\"#\")[0].split(\"?utm\")[0]\n",
    "                    break\n",
    "                parent = parent.parent\n",
    "\n",
    "            # fallback: if no container_text found, use h.get_text plus parent.get_text\n",
    "            if not container_text:\n",
    "                parent = h.parent\n",
    "                container_text = parent.get_text(\" \", strip=True) if parent else h.get_text(\" \", strip=True)\n",
    "\n",
    "            # ensure it's likely a listing: should have price or kms or both\n",
    "            if (\"₹\" not in container_text) and (re.search(r'\\b\\d+\\s*(?:kms|km)\\b', container_text, flags=re.I) is None):\n",
    "                continue\n",
    "\n",
    "            price = find_rupee(container_text)\n",
    "            kms = find_kms(container_text)\n",
    "            fuel = find_fuel(container_text)\n",
    "            year = find_year(title) or find_year(container_text)\n",
    "            mileage = extract_mileage(container_text)  # <-- extract mileage from card text\n",
    "\n",
    "            brand, model = guess_brand_and_model(title)\n",
    "\n",
    "            # dedupe key\n",
    "            unique_key = (title + \"||\" + (price or \"\")).strip()\n",
    "            if unique_key in seen_keys:\n",
    "                continue\n",
    "            seen_keys.add(unique_key)\n",
    "\n",
    "            if detail_href and detail_href not in seen_links:\n",
    "                seen_links.add(detail_href)\n",
    "            # append raw row (text-based) including mileage\n",
    "            cards_collected.append({\n",
    "                \"Car_name\": title,\n",
    "                \"brand\": brand,\n",
    "                \"model\": model,\n",
    "                \"kms_driven\": kms.replace(\",\",\"\"),\n",
    "                \"fuel_type\": fuel,\n",
    "                \"year_of_manufacture\": year,\n",
    "                \"price\": price,\n",
    "                \"mileage\": mileage,\n",
    "                \"detail_page\": detail_href,\n",
    "                \"page\": p\n",
    "            })\n",
    "\n",
    "        # small pause\n",
    "        time.sleep(random.uniform(*PAGE_PAUSE))\n",
    "\n",
    "        # early stop if we've collected at least detected total_listings\n",
    "        if total_listings and len(seen_keys) >= total_listings:\n",
    "            print(\"Collected detected total_listings, stopping page scan.\")\n",
    "            break\n",
    "\n",
    "        # small progress print every 10 pages\n",
    "        if p % 10 == 0:\n",
    "            print(f\"Scanned page {p}; collected cards so far: {len(cards_collected)}\")\n",
    "\n",
    "    print(f\"Initial collection done: {len(cards_collected)} card rows, detail links discovered: {len(seen_links)}\")\n",
    "\n",
    "    # If detail links exist, visit each detail page to extract more reliable fields (optional but recommended)\n",
    "    # We'll visit only pages that either lack kms/fuel/year/price/mileage to improve data quality.\n",
    "    # This block is slower; set visit_details=False to skip.\n",
    "    visit_details = True\n",
    "    improved_rows = []\n",
    "    visited = 0\n",
    "\n",
    "    if visit_details and len(seen_links) > 0:\n",
    "        for idx, row in enumerate(cards_collected):\n",
    "            # decide whether to open detail page: if any of main fields missing or no detail link present\n",
    "            need_detail = False\n",
    "            if not row[\"kms_driven\"] or not row[\"fuel_type\"] or not row[\"price\"] or not row[\"year_of_manufacture\"] or not row.get(\"mileage\"):\n",
    "                need_detail = True\n",
    "            if row[\"detail_page\"]:\n",
    "                detail_url = row[\"detail_page\"]\n",
    "            else:\n",
    "                detail_url = None\n",
    "            if not need_detail and detail_url:\n",
    "                # keep as is\n",
    "                improved_rows.append(row)\n",
    "                continue\n",
    "\n",
    "            if detail_url:\n",
    "                try:\n",
    "                    # open detail page\n",
    "                    driver.get(detail_url)\n",
    "                    # wait short while\n",
    "                    time.sleep(1.0 + random.random()*0.8)\n",
    "                    dsoup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                    page_text = dsoup.get_text(\" \", strip=True)\n",
    "\n",
    "                    # Title from h1/h2 if present\n",
    "                    ttag = dsoup.find([\"h1\",\"h2\"])\n",
    "                    if ttag:\n",
    "                        title_det = ttag.get_text(\" \", strip=True)\n",
    "                        if title_det:\n",
    "                            row[\"Car_name\"] = title_det\n",
    "                            brand, model = guess_brand_and_model(title_det)\n",
    "                            row[\"brand\"] = brand\n",
    "                            row[\"model\"] = model\n",
    "\n",
    "                    # Try to find labeled values first (reliable)\n",
    "                    # Kms (look for label 'Kms Driven' or 'Kms')\n",
    "                    label_kms = dsoup.find(text=re.compile(r'Kms\\s*Driven|Kms|Odometer', flags=re.I))\n",
    "                    if label_kms:\n",
    "                        try:\n",
    "                            val = label_kms.parent.find_next_sibling()\n",
    "                            if val:\n",
    "                                k = re.sub(r'[^\\d]', '', val.get_text(\" \", strip=True))\n",
    "                                if k:\n",
    "                                    row[\"kms_driven\"] = k\n",
    "                        except:\n",
    "                            pass\n",
    "                    # fallback to page text\n",
    "                    if not row[\"kms_driven\"]:\n",
    "                        kf = find_kms(page_text)\n",
    "                        if kf:\n",
    "                            row[\"kms_driven\"] = kf\n",
    "\n",
    "                    # fuel type label\n",
    "                    label_fuel = dsoup.find(text=re.compile(r'Fuel\\s*Type|Fuel', flags=re.I))\n",
    "                    if label_fuel:\n",
    "                        try:\n",
    "                            val = label_fuel.parent.find_next_sibling()\n",
    "                            if val:\n",
    "                                row[\"fuel_type\"] = val.get_text(\" \", strip=True)\n",
    "                        except:\n",
    "                            pass\n",
    "                    if not row[\"fuel_type\"]:\n",
    "                        ff = find_fuel(page_text)\n",
    "                        if ff:\n",
    "                            row[\"fuel_type\"] = ff\n",
    "\n",
    "                    # year\n",
    "                    label_year = dsoup.find(text=re.compile(r'Year\\s*of\\s*Manufacture|Registration\\s*Year|Year', flags=re.I))\n",
    "                    if label_year:\n",
    "                        try:\n",
    "                            val = label_year.parent.find_next_sibling()\n",
    "                            if val:\n",
    "                                yy = find_year(val.get_text(\" \", strip=True))\n",
    "                                if yy:\n",
    "                                    row[\"year_of_manufacture\"] = yy\n",
    "                        except:\n",
    "                            pass\n",
    "                    if not row[\"year_of_manufacture\"]:\n",
    "                        yy = find_year(row[\"Car_name\"]) or find_year(page_text)\n",
    "                        if yy:\n",
    "                            row[\"year_of_manufacture\"] = yy\n",
    "\n",
    "                    # price\n",
    "                    pr = find_rupee(page_text)\n",
    "                    if pr:\n",
    "                        row[\"price\"] = pr\n",
    "\n",
    "                    # MILEAGE extraction on detail page: labeled field or meta-line or page-wide fallback\n",
    "                    mileage_val = \"\"\n",
    "                    # 1) labeled field 'Mileage' or 'Avg. Mileage'\n",
    "                    mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
    "                    if mnode:\n",
    "                        try:\n",
    "                            parent = mnode.parent\n",
    "                            sib = parent.find_next_sibling()\n",
    "                            if sib:\n",
    "                                mileage_val = sib.get_text(\" \", strip=True)\n",
    "                        except:\n",
    "                            mileage_val = \"\"\n",
    "                    # 2) try meta-line near title\n",
    "                    if not mileage_val and ttag:\n",
    "                        nxt = ttag.find_next()\n",
    "                        checks = 0\n",
    "                        while nxt and checks < 8:\n",
    "                            txt = nxt.get_text(\" \", strip=True)\n",
    "                            if txt and ((\"kms\" in txt.lower()) or re.search(r'\\b\\d+\\s*(?:kmpl|km/kg|km/kwh|km/l|kpl)\\b', txt, flags=re.I)):\n",
    "                                mileage_val = txt\n",
    "                                break\n",
    "                            nxt = nxt.find_next()\n",
    "                            checks += 1\n",
    "                    # 3) fallback to page_text extraction\n",
    "                    if not mileage_val:\n",
    "                        mileage_val = extract_mileage(page_text)\n",
    "\n",
    "                    # normalize mileage\n",
    "                    if mileage_val:\n",
    "                        row[\"mileage\"] = mileage_val\n",
    "\n",
    "                except Exception as e:\n",
    "                    # if detail fetch fails, keep earlier extracted values\n",
    "                    pass\n",
    "\n",
    "                # tiny sleep between detail visits\n",
    "                time.sleep(random.uniform(0.35, 0.9))\n",
    "            improved_rows.append(row)\n",
    "            visited += 1\n",
    "\n",
    "            # checkpoint: save every 200 detail pages processed\n",
    "            if visited % 200 == 0:\n",
    "                df_ck = pd.DataFrame(improved_rows)\n",
    "                df_ck = df_ck.drop_duplicates(subset=[\"detail_page\",\"Car_name\",\"price\"])\n",
    "                df_ck.to_csv(OUTPUT_CSV, index=False)\n",
    "                df_ck.to_excel(OUTPUT_XLSX, index=False)\n",
    "                print(f\"Checkpoint saved after {visited} detail visits: {len(df_ck)} rows.\")\n",
    "\n",
    "    else:\n",
    "        improved_rows = cards_collected\n",
    "\n",
    "    # Final cleaning + dedupe\n",
    "    df = pd.DataFrame(improved_rows)\n",
    "    # normalize strings and numeric kms\n",
    "    for c in [\"Car_name\",\"brand\",\"model\",\"fuel_type\",\"price\",\"detail_page\",\"mileage\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna(\"\").astype(str).str.strip()\n",
    "    df[\"kms_driven\"] = df[\"kms_driven\"].apply(lambda x: clean_kms(x) if x else \"\")\n",
    "    df[\"year_of_manufacture\"] = df[\"year_of_manufacture\"].apply(lambda x: find_year(str(x)) if x else \"\")\n",
    "\n",
    "    # dedupe by detail_page if present else by Car_name+price\n",
    "    if \"detail_page\" in df.columns and df[\"detail_page\"].str.len().sum() > 0:\n",
    "        df = df.drop_duplicates(subset=[\"detail_page\"]).reset_index(drop=True)\n",
    "    else:\n",
    "        df = df.drop_duplicates(subset=[\"Car_name\",\"price\"]).reset_index(drop=True)\n",
    "\n",
    "    # Save\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    df.to_excel(OUTPUT_XLSX, index=False)\n",
    "    print(f\"Saved cleaned output: {OUTPUT_CSV} and {OUTPUT_XLSX}\")\n",
    "    print(\"Total rows collected:\", len(df))\n",
    "    display(df.head(40))\n",
    "\n",
    "finally:\n",
    "    try:\n",
    "        driver.quit()\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d3a13d-0b4f-4fe6-940c-0dc69356510f",
   "metadata": {},
   "source": [
    "4th stage of scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e9c312-7da1-487a-a19d-235a401f9b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 762 rows from cardekho_used_cars_pune_price_fixed.xlsx\n",
      "Rows flagged for repair: 1 (will visit detail pages)\n",
      "[1/1] Failed to load: nan\n",
      "Done. Updated 0 rows. Saved cleaned file to:\n",
      " - cardekho_used_cars_pune_price_fixed_cleaned.xlsx\n",
      " - cardekho_used_cars_pune_price_fixed_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Jupyter cell: Repair mileage & transmission for existing Cardekho file\n",
    "# - Loads /mnt/data/cardekho_used_cars_hyderabad_price_fixed.xlsx\n",
    "# - Visits detail_page for rows missing/invalid mileage or transmission\n",
    "# - Writes back cleaned file (CSV + XLSX)\n",
    "# Requirements: selenium, webdriver-manager, beautifulsoup4, pandas, openpyxl\n",
    "\n",
    "import re, time, random, os\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "INPUT_XLSX = \"cardekho_used_cars_pune_price_fixed.xlsx\"\n",
    "OUTPUT_XLSX = \"cardekho_used_cars_pune_price_fixed_cleaned.xlsx\"\n",
    "OUTPUT_CSV = \"cardekho_used_cars_pune_price_fixed_cleaned.csv\"\n",
    "\n",
    "HEADLESS = True                # set False to watch browser\n",
    "DELAY_BETWEEN = (0.6, 1.2)     # polite per-page pause\n",
    "CHECKPOINT_EVERY = 50          # save every N updated rows\n",
    "MAX_RETRIES = 1\n",
    "# --------------------------------\n",
    "\n",
    "if not os.path.exists(INPUT_XLSX):\n",
    "    raise FileNotFoundError(f\"Input file not found: {INPUT_XLSX}. Put your file at this path and re-run.\")\n",
    "\n",
    "# --- utility functions ---\n",
    "def text_of(elem):\n",
    "    return elem.get_text(\" \", strip=True) if elem else \"\"\n",
    "\n",
    "def normalize_mileage(raw):\n",
    "    if not raw:\n",
    "        return \"\"\n",
    "    s = str(raw).strip()\n",
    "    s = s.replace(\"\\xa0\",\" \").replace(\"\\n\",\" \").strip()\n",
    "    # try to capture number + unit (common)\n",
    "    m = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|kpl|km/kg|km/kwh|km/l|km|mpg)', s, flags=re.I)\n",
    "    if m:\n",
    "        val = m.group(1)\n",
    "        unit = m.group(2).lower()\n",
    "        # normalize unit names\n",
    "        unit = unit.replace(\"kpl\",\"kmpl\").replace(\"km/l\",\"kmpl\")\n",
    "        return f\"{val} {unit}\"\n",
    "    # tries like \"18.5\" then search for unit nearby\n",
    "    m2 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)', s)\n",
    "    if m2:\n",
    "        # if no unit, just return number\n",
    "        return m2.group(1)\n",
    "    return s\n",
    "\n",
    "def normalize_transmission(raw):\n",
    "    if not raw:\n",
    "        return \"\"\n",
    "    s = str(raw)\n",
    "    for t in [\"AMT\",\"CVT\",\"DCT\",\"AT\",\"MT\",\"Manual\",\"Automatic\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', s, flags=re.I):\n",
    "            # canonicalize\n",
    "            if t.upper() in (\"AMT\",\"CVT\",\"DCT\",\"AT\",\"MT\"):\n",
    "                return t.upper()\n",
    "            return t.title()\n",
    "    # last resort: find words\n",
    "    if re.search(r'\\bmanual\\b', s, flags=re.I):\n",
    "        return \"Manual\"\n",
    "    if re.search(r'\\bautomatic\\b', s, flags=re.I):\n",
    "        return \"Automatic\"\n",
    "    return s.strip()\n",
    "\n",
    "def extract_mileage_from_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # 1) direct patterns e.g. \"18.5 kmpl\"\n",
    "    m = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|kpl|km/kg|km/kwh|km/l|km|mpg)\\b', text, flags=re.I)\n",
    "    if m:\n",
    "        unit = m.group(2).lower().replace(\"kpl\",\"kmpl\").replace(\"km/l\",\"kmpl\")\n",
    "        return f\"{m.group(1)} {unit}\"\n",
    "    # 2) near 'mileage' keyword: capture window +/- 60 chars\n",
    "    for keyword in [\"mileage\",\"avg. mileage\",\"avg mileage\",\"city mileage\",\"claimed mileage\",\"average mileage\"]:\n",
    "        idx = text.lower().find(keyword)\n",
    "        if idx != -1:\n",
    "            start = max(0, idx-60)\n",
    "            end = min(len(text), idx+80)\n",
    "            ctx = text[start:end]\n",
    "            m2 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|kpl|km/kg|km/kwh|km/l|km|mpg)\\b', ctx, flags=re.I)\n",
    "            if m2:\n",
    "                unit = m2.group(2).lower().replace(\"kpl\",\"kmpl\").replace(\"km/l\",\"kmpl\")\n",
    "                return f\"{m2.group(1)} {unit}\"\n",
    "            # number only\n",
    "            m3 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)', ctx)\n",
    "            if m3:\n",
    "                return m3.group(1)\n",
    "    # 3) any number+unit elsewhere\n",
    "    m4 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|kpl|km/kg|km/kwh|km/l|km|mpg)\\b', text, flags=re.I)\n",
    "    if m4:\n",
    "        unit = m4.group(2).lower().replace(\"kpl\",\"kmpl\").replace(\"km/l\",\"kmpl\")\n",
    "        return f\"{m4.group(1)} {unit}\"\n",
    "    return \"\"\n",
    "\n",
    "def extract_trans_from_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # look for label/context words\n",
    "    for t in [\"Manual\",\"Automatic\",\"AMT\",\"CVT\",\"DCT\",\"AT\",\"MT\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', text, flags=re.I):\n",
    "            return normalize_transmission(t)\n",
    "    # also search near keywords 'transmission' or 'gearbox'\n",
    "    idx = text.lower().find(\"transmission\")\n",
    "    if idx == -1:\n",
    "        idx = text.lower().find(\"gearbox\")\n",
    "    if idx != -1:\n",
    "        start = max(0, idx-40)\n",
    "        end = min(len(text), idx+80)\n",
    "        ctx = text[start:end]\n",
    "        for t in [\"Manual\",\"Automatic\",\"AMT\",\"CVT\",\"DCT\",\"AT\",\"MT\"]:\n",
    "            if re.search(r'\\b' + re.escape(t) + r'\\b', ctx, flags=re.I):\n",
    "                return normalize_transmission(t)\n",
    "        # fallback to any word in ctx\n",
    "        m = re.search(r'\\b(Manual|Automatic|AMT|CVT|DCT|AT|MT)\\b', ctx, flags=re.I)\n",
    "        if m:\n",
    "            return normalize_transmission(m.group(1))\n",
    "    return \"\"\n",
    "\n",
    "# ----------------- load dataset -----------------\n",
    "df = pd.read_excel(INPUT_XLSX)\n",
    "print(f\"Loaded {len(df)} rows from {INPUT_XLSX}\")\n",
    "\n",
    "# identify rows that need fixing:\n",
    "# Criteria: mileage empty OR transmission empty OR mileage looks like URL/junk (contains 'http' or '/')\n",
    "def mileage_is_bad(val):\n",
    "    if not val or str(val).strip() == \"\":\n",
    "        return True\n",
    "    s = str(val).lower()\n",
    "    if \"http\" in s or \"/\" in s and len(s) > 10:   # simplistic junk heuristics\n",
    "        return True\n",
    "    # if it's non-numeric and non-unit, mark for check\n",
    "    if not re.search(r'\\d', s):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def transmission_is_bad(val):\n",
    "    if not val or str(val).strip() == \"\":\n",
    "        return True\n",
    "    s = str(val)\n",
    "    if re.search(r'http|\\/', s):\n",
    "        return True\n",
    "    # ok if contains known token\n",
    "    if re.search(r'\\b(Manual|Automatic|AMT|CVT|DCT|AT|MT)\\b', s, flags=re.I):\n",
    "        return False\n",
    "    return False  # conservative: if present assume ok\n",
    "\n",
    "# build list of indices to fix\n",
    "to_fix_idx = []\n",
    "for i, row in df.iterrows():\n",
    "    mismatch = False\n",
    "    if mileage_is_bad(row.get(\"mileage\", \"\")):\n",
    "        mismatch = True\n",
    "    if transmission_is_bad(row.get(\"transmission\", \"\")):\n",
    "        mismatch = True\n",
    "    # we will only attempt to fix those that have a valid detail_page URL\n",
    "    if mismatch and row.get(\"detail_page\"):\n",
    "        to_fix_idx.append(i)\n",
    "\n",
    "print(f\"Rows flagged for repair: {len(to_fix_idx)} (will visit detail pages)\")\n",
    "\n",
    "if len(to_fix_idx) == 0:\n",
    "    print(\"No rows need fixing. Exiting.\")\n",
    "else:\n",
    "    # Setup Selenium (headful or headless)\n",
    "    opts = Options()\n",
    "    if HEADLESS:\n",
    "        opts.add_argument(\"--headless=new\")\n",
    "    opts.add_argument(\"--no-sandbox\")\n",
    "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    opts.add_argument(\"--window-size=1200,900\")\n",
    "    opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)\n",
    "\n",
    "    updated = 0\n",
    "    try:\n",
    "        for batch_i, idx in enumerate(to_fix_idx, start=1):\n",
    "            row = df.loc[idx]\n",
    "            url = str(row.get(\"detail_page\")).strip()\n",
    "            if not url:\n",
    "                continue\n",
    "            # polite jitter\n",
    "            time.sleep(random.uniform(*DELAY_BETWEEN))\n",
    "            # fetch page\n",
    "            success = False\n",
    "            for attempt in range(MAX_RETRIES+1):\n",
    "                try:\n",
    "                    driver.get(url)\n",
    "                    # let JS run and content load\n",
    "                    time.sleep(1.0 + random.random()*0.8)\n",
    "                    page_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                    page_text = page_soup.get_text(\" \", strip=True)\n",
    "                    success = True\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    if attempt < MAX_RETRIES:\n",
    "                        time.sleep(0.6)\n",
    "                        continue\n",
    "                    else:\n",
    "                        success = False\n",
    "            if not success:\n",
    "                print(f\"[{batch_i}/{len(to_fix_idx)}] Failed to load: {url}\")\n",
    "                continue\n",
    "\n",
    "            # MULTIPLE extraction strategies, most-specific -> fallback\n",
    "            new_mileage = \"\"\n",
    "            new_trans = \"\"\n",
    "\n",
    "            # Strategy A: labeled dt/dd or table tr (common structure)\n",
    "            # dt/dd\n",
    "            try:\n",
    "                dts = page_soup.find_all(\"dt\")\n",
    "                if dts:\n",
    "                    for dt in dts:\n",
    "                        label = text_of(dt).lower()\n",
    "                        if \"mile\" in label:\n",
    "                            dd = dt.find_next_sibling(\"dd\")\n",
    "                            if dd:\n",
    "                                cand = text_of(dd)\n",
    "                                if cand:\n",
    "                                    new_mileage = extract_mileage_from_text(cand) or normalize_mileage(cand)\n",
    "                        if \"trans\" in label or \"gear\" in label:\n",
    "                            dd = dt.find_next_sibling(\"dd\")\n",
    "                            if dd:\n",
    "                                new_trans = extract_trans_from_text(text_of(dd)) or normalize_transmission(text_of(dd))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Strategy B: table rows <tr><th>Label</th><td>Value</td>\n",
    "            if not new_mileage or not new_trans:\n",
    "                try:\n",
    "                    for tr in page_soup.find_all(\"tr\"):\n",
    "                        th = tr.find([\"th\",\"td\"])\n",
    "                        tlabel = text_of(th).lower() if th else \"\"\n",
    "                        tvals = [text_of(x) for x in tr.find_all(\"td\")]\n",
    "                        tval = tvals[0] if tvals else \"\"\n",
    "                        if not new_mileage and (\"mileage\" in tlabel or \"avg\" in tlabel and \"mileage\" in tlabel):\n",
    "                            new_mileage = extract_mileage_from_text(tval) or normalize_mileage(tval)\n",
    "                        if not new_trans and (\"transmission\" in tlabel or \"gearbox\" in tlabel or \"gear\" in tlabel):\n",
    "                            new_trans = extract_trans_from_text(tval) or normalize_transmission(tval)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Strategy C: look for elements with class/id containing keywords\n",
    "            if not new_mileage:\n",
    "                try:\n",
    "                    mileage_nodes = page_soup.find_all(attrs={\"class\": re.compile(r\"mile|mileage|avg-mile|avgMileage\", flags=re.I)})\n",
    "                    for n in mileage_nodes:\n",
    "                        cand = text_of(n)\n",
    "                        cand_val = extract_mileage_from_text(cand) or normalize_mileage(cand)\n",
    "                        if cand_val:\n",
    "                            new_mileage = cand_val\n",
    "                            break\n",
    "                except Exception:\n",
    "                    pass\n",
    "            if not new_trans:\n",
    "                try:\n",
    "                    trans_nodes = page_soup.find_all(attrs={\"class\": re.compile(r\"trans|gear|gearbox\", flags=re.I)})\n",
    "                    for n in trans_nodes:\n",
    "                        cand = text_of(n)\n",
    "                        cand_val = extract_trans_from_text(cand) or normalize_transmission(cand)\n",
    "                        if cand_val:\n",
    "                            new_trans = cand_val\n",
    "                            break\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Strategy D: meta / data- attributes (rare)\n",
    "            if not new_mileage:\n",
    "                try:\n",
    "                    mtag = page_soup.find(\"meta\", attrs={\"name\": re.compile(r\"mileage\", flags=re.I)})\n",
    "                    if mtag and mtag.get(\"content\"):\n",
    "                        cand = mtag.get(\"content\")\n",
    "                        new_mileage = extract_mileage_from_text(cand) or normalize_mileage(cand)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Strategy E: near-title meta-line (many Cardekho detail pages show compact specs after title)\n",
    "            if not new_mileage or not new_trans:\n",
    "                try:\n",
    "                    htag = page_soup.find([\"h1\",\"h2\"])\n",
    "                    if htag:\n",
    "                        nxt = htag.find_next()\n",
    "                        checks = 0\n",
    "                        while nxt and checks < 10:\n",
    "                            txt = text_of(nxt)\n",
    "                            if txt and ((\"kms\" in txt.lower()) or (\"kmpl\" in txt.lower()) or (\"mileage\" in txt.lower()) or (\"transmission\" in txt.lower()) or (\"gear\" in txt.lower())):\n",
    "                                if not new_mileage:\n",
    "                                    new_mileage = extract_mileage_from_text(txt) or normalize_mileage(txt)\n",
    "                                if not new_trans:\n",
    "                                    new_trans = extract_trans_from_text(txt) or normalize_transmission(txt)\n",
    "                                break\n",
    "                            nxt = nxt.find_next()\n",
    "                            checks += 1\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Strategy F: page-wide regex fallback (last resort)\n",
    "            if not new_mileage:\n",
    "                new_mileage = extract_mileage_from_text(page_text)\n",
    "            if not new_trans:\n",
    "                new_trans = extract_trans_from_text(page_text)\n",
    "\n",
    "            # Final normalization\n",
    "            new_mileage = normalize_mileage(new_mileage)\n",
    "            new_trans = normalize_transmission(new_trans)\n",
    "\n",
    "            # If still empty, try card-level existing values as fallback (do not overwrite good existing)\n",
    "            existing_mileage = df.at[idx, \"mileage\"] if \"mileage\" in df.columns else \"\"\n",
    "            existing_trans = df.at[idx, \"transmission\"] if \"transmission\" in df.columns else \"\"\n",
    "            if not new_mileage and existing_mileage and not mileage_is_bad(existing_mileage):\n",
    "                new_mileage = existing_mileage\n",
    "            if not new_trans and existing_trans and existing_trans.strip():\n",
    "                new_trans = existing_trans\n",
    "\n",
    "            # write back if changed\n",
    "            changed = False\n",
    "            if new_mileage and (str(df.at[idx, \"mileage\"]) != new_mileage):\n",
    "                df.at[idx, \"mileage\"] = new_mileage\n",
    "                changed = True\n",
    "            if new_trans and (str(df.at[idx, \"transmission\"]) != new_trans):\n",
    "                df.at[idx, \"transmission\"] = new_trans\n",
    "                changed = True\n",
    "\n",
    "            if changed:\n",
    "                updated += 1\n",
    "                print(f\"[{batch_i}/{len(to_fix_idx)}] Updated idx={idx}: mileage='{new_mileage}' transmission='{new_trans}'\")\n",
    "            else:\n",
    "                print(f\"[{batch_i}/{len(to_fix_idx)}] No new data for idx={idx}\")\n",
    "\n",
    "            # checkpointing\n",
    "            if updated and updated % CHECKPOINT_EVERY == 0:\n",
    "                df.to_csv(OUTPUT_CSV, index=False)\n",
    "                df.to_excel(OUTPUT_XLSX, index=False)\n",
    "                print(f\"Checkpoint saved after {updated} updates.\")\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # final save\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    df.to_excel(OUTPUT_XLSX, index=False)\n",
    "    print(f\"Done. Updated {updated} rows. Saved cleaned file to:\\n - {OUTPUT_XLSX}\\n - {OUTPUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a8f7e-b1a4-428c-ba2f-c9ceb34e702d",
   "metadata": {},
   "source": [
    "5th stage off scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b42a178d-1361-4897-8015-ce7ef6fdcc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected total_listings=2644, per_page_guess=58, total_pages=46\n",
      "Scanned page 10; rows so far: 814\n",
      "Scanned page 20; rows so far: 828\n",
      "Scanned page 30; rows so far: 858\n",
      "Scanned page 40; rows so far: 859\n",
      "Collected 863 card-level rows, detail links: 824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_32952\\2142946770.py:461: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_32952\\2142946770.py:476: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 detail pages...\n",
      "Processed 200 detail pages...\n",
      "Processed 300 detail pages...\n",
      "Processed 400 detail pages...\n",
      "Processed 500 detail pages...\n",
      "Processed 600 detail pages...\n",
      "Processed 700 detail pages...\n",
      "Processed 800 detail pages...\n",
      "Saved 825 rows to cardekho_used_cars_pune_price_fixed.csv and cardekho_used_cars_pune_price_fixed.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "cardekho_with_price_fix.py\n",
    "\n",
    "Improved scraper for CarDekho used cars (Hyderabad) with robust price extraction.\n",
    "Only mileage logic improved — rest unchanged.\n",
    "Requires: selenium, webdriver-manager, beautifulsoup4, pandas, openpyxl\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ---------------------------\n",
    "# Path to uploaded file (local). Use this path if you want to read the previously saved file.\n",
    "# Downstream systems can convert this local path into a downloadable URL if needed.\n",
    "UPLOADED_FILE_PATH = \"cardekho_used_cars_pune_price_fixed_cleaned.xlsx\"\n",
    "# ---------------------------\n",
    "\n",
    "# -------- CONFIG ----------\n",
    "START_URL = \"https://www.cardekho.com/used-cars+in+pune\"\n",
    "OUTPUT_CSV = \"cardekho_used_cars_pune_price_fixed.csv\"\n",
    "OUTPUT_XLSX = \"cardekho_used_cars_pune_price_fixed.xlsx\"\n",
    "\n",
    "HEADLESS = True\n",
    "MAX_PAGES_OVERRIDE = None\n",
    "MAX_SCROLLS = 40\n",
    "SCROLL_PAUSE = 0.7\n",
    "PAGE_PAUSE = (0.6, 1.4)\n",
    "VISIT_DETAIL_PAGES = True\n",
    "DETAIL_PAUSE = (0.6, 1.2)\n",
    "MAX_DETAIL_RETRIES = 1\n",
    "\n",
    "BRANDS = [\n",
    "    \"Maruti\", \"Hyundai\", \"Tata\", \"Honda\", \"Toyota\", \"Mahindra\", \"Kia\",\n",
    "    \"BMW\", \"Audi\", \"Mercedes-Benz\", \"Mercedes\", \"Renault\", \"MG\", \"Skoda\",\n",
    "    \"Volkswagen\", \"Ford\", \"Nissan\", \"Jeep\", \"Volvo\", \"Land Rover\", \"Jaguar\",\n",
    "    \"Isuzu\", \"Datsun\", \"Chevrolet\", \"Opel\"\n",
    "]\n",
    "# --------------------------\n",
    "\n",
    "def text_of(elem):\n",
    "    return elem.get_text(\" \", strip=True) if elem else \"\"\n",
    "\n",
    "def guess_brand_and_model(name):\n",
    "    if not name:\n",
    "        return \"\", \"\"\n",
    "    for b in BRANDS:\n",
    "        if b.lower() in name.lower():\n",
    "            model = re.sub(re.escape(b), \"\", name, flags=re.IGNORECASE).strip()\n",
    "            model = re.sub(r'^[\\-\\:\\–\\—\\s]+', '', model)\n",
    "            return b, model or name\n",
    "    parts = name.split()\n",
    "    return (parts[0], \" \".join(parts[1:]) if len(parts) > 1 else \"\") if parts else (\"\",\"\")\n",
    "\n",
    "def extract_kms(text):\n",
    "    m = re.search(r'([\\d,\\.]+)\\s*(?:kms|km)\\b', text, flags=re.I)\n",
    "    if m:\n",
    "        return m.group(1).replace(\",\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "def extract_fuel(text):\n",
    "    for f in [\"Petrol\", \"Diesel\", \"CNG\", \"LPG\", \"Electric\", \"Hybrid\"]:\n",
    "        if re.search(r'\\b' + re.escape(f) + r'\\b', text, flags=re.I):\n",
    "            return f\n",
    "    return \"\"\n",
    "\n",
    "# ----------------------\n",
    "# IMPROVED MILEAGE LOGIC\n",
    "# ----------------------\n",
    "\n",
    "# convert mpg to kmpl factor\n",
    "_MPG_TO_KMPL = 0.425144\n",
    "\n",
    "def _try_parse_number(s):\n",
    "    \"\"\"Return float or None for first numeric group found.\"\"\"\n",
    "    if not s:\n",
    "        return None\n",
    "    s2 = str(s).replace(\",\", \"\").replace(\"\\xa0\",\" \").strip()\n",
    "    m = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)', s2)\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return float(m.group(1))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_mileage(text):\n",
    "    \"\"\"\n",
    "    Robust mileage extraction that:\n",
    "     - prefers explicit units (kmpl, km/l, kpl)\n",
    "     - converts mpg -> kmpl\n",
    "     - ignores pure distance values like '120 km' (treat as invalid)\n",
    "     - returns standardized string like '18.5 kmpl' or '' if not found\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    s = str(text).replace(\"\\xa0\",\" \").strip()\n",
    "    low = s.lower()\n",
    "\n",
    "    # 1) explicit kmpl / km/l / kpl patterns\n",
    "    m = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)\\s*(km\\s*/\\s*l|kmpl|kpl|kmperlitre|km per litre)\\b', low, flags=re.I)\n",
    "    if m:\n",
    "        num = float(m.group(1))\n",
    "        # format number: remove .0 if integer else keep up to 2 decimals\n",
    "        num_fmt = int(num) if num.is_integer() else round(num, 2)\n",
    "        return f\"{num_fmt} kmpl\"\n",
    "\n",
    "    # 2) mpg -> convert to kmpl\n",
    "    m_mpg = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)\\s*mpg\\b', low, flags=re.I)\n",
    "    if m_mpg:\n",
    "        mpg = float(m_mpg.group(1))\n",
    "        kmpl = round(mpg * _MPG_TO_KMPL, 2)\n",
    "        kmpl_fmt = int(kmpl) if float(kmpl).is_integer() else kmpl\n",
    "        return f\"{kmpl_fmt} kmpl\"\n",
    "\n",
    "    # 3) patterns like \"18.5 kmpl\" without spaces or with units in mixed-case\n",
    "    m2 = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)\\s*(kmpl|kpl|km/l)\\b', low, flags=re.I)\n",
    "    if m2:\n",
    "        num = float(m2.group(1))\n",
    "        num_fmt = int(num) if num.is_integer() else round(num, 2)\n",
    "        return f\"{num_fmt} kmpl\"\n",
    "\n",
    "    # 4) look for 'mileage' keyword and numbers near it\n",
    "    for keyword in (\"mileage\", \"avg. mileage\", \"avg mileage\", \"claimed mileage\", \"claimed fuel economy\"):\n",
    "        idx = low.find(keyword)\n",
    "        if idx != -1:\n",
    "            window = low[max(0, idx-50): idx+80]\n",
    "            m3 = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)\\s*(kmpl|kpl|km/l|mpg)?', window, flags=re.I)\n",
    "            if m3:\n",
    "                num = float(m3.group(1))\n",
    "                unit = m3.group(2)\n",
    "                if unit and \"mpg\" in unit:\n",
    "                    kmpl = round(num * _MPG_TO_KMPL, 2)\n",
    "                    kmpl_fmt = int(kmpl) if float(kmpl).is_integer() else kmpl\n",
    "                    return f\"{kmpl_fmt} kmpl\"\n",
    "                # if unit absent, only accept if number plausible for kmpl\n",
    "                if not unit:\n",
    "                    if num <= 50:  # treat as kmpl\n",
    "                        num_fmt = int(num) if float(num).is_integer() else round(num, 2)\n",
    "                        return f\"{num_fmt} kmpl\"\n",
    "                else:\n",
    "                    # if unit is kmpl-like handled above; fallback\n",
    "                    num_fmt = int(num) if float(num).is_integer() else round(num, 2)\n",
    "                    return f\"{num_fmt} kmpl\"\n",
    "\n",
    "    # 5) generic number+unit elsewhere on page\n",
    "    m4 = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)\\s*(kmpl|kpl|km/l|mpg)\\b', low, flags=re.I)\n",
    "    if m4:\n",
    "        val = float(m4.group(1))\n",
    "        unit = m4.group(2)\n",
    "        if 'mpg' in unit:\n",
    "            kmpl = round(val * _MPG_TO_KMPL, 2)\n",
    "            kmpl_fmt = int(kmpl) if float(kmpl).is_integer() else kmpl\n",
    "            return f\"{kmpl_fmt} kmpl\"\n",
    "        num_fmt = int(val) if val.is_integer() else round(val, 2)\n",
    "        return f\"{num_fmt} kmpl\"\n",
    "\n",
    "    # 6) numeric-only fallback: if page has a single small number (<50) assume kmpl\n",
    "    num = _try_parse_number(s)\n",
    "    if num is not None and num <= 50:\n",
    "        num_fmt = int(num) if float(num).is_integer() else round(num, 2)\n",
    "        return f\"{num_fmt} kmpl\"\n",
    "\n",
    "    # 7) otherwise likely a distance or invalid — return empty\n",
    "    return \"\"\n",
    "\n",
    "# helper used by the fallback detail extraction (kept unchanged)\n",
    "def extract_mileage_from_text(text):\n",
    "    # reuse improved extract_mileage\n",
    "    return extract_mileage(text)\n",
    "\n",
    "def extract_transmission(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    for t in [\"Manual\",\"Automatic\",\"CVT\",\"AMT\",\"DCT\",\"AT\",\"MT\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', text, flags=re.I):\n",
    "            if t.upper() in (\"AT\",\"AMT\",\"CVT\",\"DCT\",\"MT\"):\n",
    "                return t.upper()\n",
    "            return t.title()\n",
    "    return \"\"\n",
    "\n",
    "# ----------------------\n",
    "# existing other helpers unchanged\n",
    "# ----------------------\n",
    "\n",
    "def extract_price_from_soup(soup):\n",
    "    # 1. meta tags\n",
    "    meta_selectors = [\n",
    "        ('meta', {'property': 'og:price:amount'}),\n",
    "        ('meta', {'itemprop': 'price'}),\n",
    "        ('meta', {'name': 'price'}),\n",
    "    ]\n",
    "    for tag, attrs in meta_selectors:\n",
    "        mtag = soup.find(tag, attrs=attrs)\n",
    "        if mtag:\n",
    "            val = mtag.get('content') or mtag.get('value') or \"\"\n",
    "            if val:\n",
    "                if re.search(r'[\\d]', val) and '₹' not in val:\n",
    "                    return \"₹ \" + val.strip()\n",
    "                return val.strip()\n",
    "\n",
    "    # 2. attributes that often store price\n",
    "    for attr in ('data-price', 'data-offer-price', 'data-srp', 'data-amount', 'data-price-value'):\n",
    "        el = soup.find(attrs={attr: True})\n",
    "        if el:\n",
    "            val = el.get(attr)\n",
    "            if val:\n",
    "                if re.search(r'[\\d]', val) and '₹' not in val:\n",
    "                    return \"₹ \" + val.strip()\n",
    "                return val.strip()\n",
    "\n",
    "    # 3. elements with class or id containing 'price' or 'amount'\n",
    "    px = soup.find(lambda tag: tag.name in (\"div\",\"span\",\"p\",\"strong\") and (\n",
    "        tag.get(\"class\") or tag.get(\"id\")\n",
    "    ) and re.search(r'price|amount|selling|srp|finalPrice|carPrice|actual-price', \" \".join((tag.get(\"class\") or []) + [tag.get(\"id\") or \"\"]), flags=re.I))\n",
    "    if px:\n",
    "        txt = text_of(px)\n",
    "        pr = find_rupee_in_text(txt)\n",
    "        if pr:\n",
    "            return pr\n",
    "        if txt:\n",
    "            return txt.strip()\n",
    "\n",
    "    # 4. any visible text near top with rupee sign\n",
    "    top_region = \"\"\n",
    "    head_candidates = soup.find_all([\"header\", \"section\", \"div\"], limit=6)\n",
    "    for c in head_candidates:\n",
    "        t = text_of(c)\n",
    "        if '₹' in t:\n",
    "            top_region = t\n",
    "            break\n",
    "    if not top_region:\n",
    "        top_region = soup.get_text(\" \", strip=True)\n",
    "\n",
    "    pr = find_rupee_in_text(top_region)\n",
    "    if pr:\n",
    "        return pr\n",
    "\n",
    "    # 5. fallback regex on whole page (Lakh/Crore)\n",
    "    p2 = re.search(r'[\\d\\.,]+\\s*(?:Lakh|lakh|Lakhs|lakhs|Crore|crore|Cr)\\b', soup.get_text(\" \", strip=True))\n",
    "    if p2:\n",
    "        return p2.group(0).strip()\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def find_rupee_in_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    m = re.search(r'₹\\s*[\\d\\.,\\sA-Za-z]+', text)\n",
    "    if m:\n",
    "        return m.group(0).strip()\n",
    "    m2 = re.search(r'[\\d\\.,]+\\s*(Lakh|lakh|Lakhs|lakhs|Crore|crore|Cr)\\b', text)\n",
    "    if m2:\n",
    "        return m2.group(0).strip()\n",
    "    return \"\"\n",
    "\n",
    "def extract_price_from_text(text):\n",
    "    p = find_rupee_in_text(text)\n",
    "    return p\n",
    "\n",
    "def extract_year(text):\n",
    "    m = re.search(r'\\b(19|20)\\d{2}\\b', text)\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    "# ----------------------\n",
    "# main scraping flow (unchanged)\n",
    "# ----------------------\n",
    "\n",
    "def main():\n",
    "    chrome_opts = Options()\n",
    "    if HEADLESS:\n",
    "        chrome_opts.add_argument(\"--headless=new\")\n",
    "    chrome_opts.add_argument(\"--no-sandbox\")\n",
    "    chrome_opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_opts.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_opts)\n",
    "\n",
    "    try:\n",
    "        driver.get(START_URL)\n",
    "        time.sleep(2.0)\n",
    "        soup0 = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        text0 = soup0.get_text(\" \", strip=True)\n",
    "\n",
    "        total_listings = None\n",
    "        m = re.search(r'([\\d,]{2,})\\s+Second Hand Cars in Pune', text0, flags=re.I)\n",
    "        if not m:\n",
    "            m = re.search(r'of\\s+([\\d,]+)\\s+results', text0, flags=re.I)\n",
    "        if m:\n",
    "            total_listings = int(m.group(1).replace(\",\", \"\"))\n",
    "\n",
    "        per_page_guess = max(1, len(soup0.find_all(\"h3\")))\n",
    "        estimated_pages = math.ceil(total_listings / per_page_guess) if total_listings else None\n",
    "        total_pages = int(estimated_pages) if estimated_pages else 200\n",
    "        if MAX_PAGES_OVERRIDE:\n",
    "            total_pages = MAX_PAGES_OVERRIDE\n",
    "\n",
    "        print(f\"Detected total_listings={total_listings}, per_page_guess={per_page_guess}, total_pages={total_pages}\")\n",
    "\n",
    "        rows = []\n",
    "        seen_keys = set()\n",
    "        detail_links = []\n",
    "\n",
    "        for p in range(1, total_pages + 1):\n",
    "            page_url = START_URL.rstrip(\"/\") + \"?page=\" + str(p)\n",
    "            try:\n",
    "                driver.get(page_url)\n",
    "            except Exception:\n",
    "                time.sleep(1.0)\n",
    "                driver.get(page_url)\n",
    "\n",
    "            # scroll aggressively\n",
    "            last_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            sc = 0\n",
    "            while sc < MAX_SCROLLS:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(SCROLL_PAUSE)\n",
    "                new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_h == last_h:\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight-400);\")\n",
    "                    time.sleep(0.4)\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    time.sleep(0.4)\n",
    "                    new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                    if new_h == last_h:\n",
    "                        break\n",
    "                last_h = new_h\n",
    "                sc += 1\n",
    "\n",
    "            page_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            titles = page_soup.find_all(\"h3\")\n",
    "            for h in titles:\n",
    "                title = text_of(h)\n",
    "                if not title:\n",
    "                    continue\n",
    "\n",
    "                container = h\n",
    "                card_text = \"\"\n",
    "                link = \"\"\n",
    "                for _ in range(6):\n",
    "                    if container is None:\n",
    "                        break\n",
    "                    card_text = text_of(container)\n",
    "                    if \"₹\" in card_text or re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I):\n",
    "                        a = container.find(\"a\", href=True)\n",
    "                        if a:\n",
    "                            href = a[\"href\"]\n",
    "                            link = href if \"cardekho.com\" in href else urljoin(page_url, href)\n",
    "                            link = link.split(\"#\")[0].split(\"?utm\")[0]\n",
    "                        break\n",
    "                    container = container.parent\n",
    "\n",
    "                if not card_text:\n",
    "                    parent = h.parent\n",
    "                    card_text = text_of(parent) if parent else title\n",
    "\n",
    "                if (\"₹\" not in card_text) and (re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I) is None):\n",
    "                    continue\n",
    "\n",
    "                price_card = extract_price_from_text(card_text)\n",
    "                key = (title + \"||\" + (price_card or \"\")).strip()\n",
    "                if key in seen_keys:\n",
    "                    continue\n",
    "                seen_keys.add(key)\n",
    "\n",
    "                kms = extract_kms(card_text)\n",
    "                fuel = extract_fuel(card_text)\n",
    "                year = extract_year(title) or extract_year(card_text)\n",
    "                brand = \"\"\n",
    "                model = \"\"\n",
    "                try:\n",
    "                    brand, model = guess_brand_and_model(title)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                rows.append({\n",
    "                    \"Car_name\": title,\n",
    "                    \"brand\": brand,\n",
    "                    \"model\": model,\n",
    "                    \"kms_driven\": kms,\n",
    "                    \"mileage\": \"\",             # will be filled from detail page if available\n",
    "                    \"transmission\": \"\",\n",
    "                    \"fuel_type\": fuel,\n",
    "                    \"year_of_manufacture\": year,\n",
    "                    \"price\": price_card,\n",
    "                    \"detail_page\": link\n",
    "                })\n",
    "\n",
    "                if link:\n",
    "                    detail_links.append(link)\n",
    "\n",
    "            time.sleep(random.uniform(*PAGE_PAUSE))\n",
    "\n",
    "            if total_listings and len(seen_keys) >= total_listings:\n",
    "                print(\"Reached detected total listings; stopping page scan.\")\n",
    "                break\n",
    "\n",
    "            if p % 10 == 0:\n",
    "                print(f\"Scanned page {p}; rows so far: {len(rows)}\")\n",
    "\n",
    "        print(f\"Collected {len(rows)} card-level rows, detail links: {len(set(detail_links))}\")\n",
    "\n",
    "        # Now ensure price/mileage/transmission are filled: visit detail pages for any row missing price/mileage/trans\n",
    "        if VISIT_DETAIL_PAGES and detail_links:\n",
    "            unique_detail_links = []\n",
    "            seen_dl = set()\n",
    "            for u in detail_links:\n",
    "                if u and u not in seen_dl:\n",
    "                    seen_dl.add(u)\n",
    "                    unique_detail_links.append(u)\n",
    "\n",
    "            # map link -> price/mileage/transmission\n",
    "            detail_map = {}\n",
    "\n",
    "            for i, dl in enumerate(unique_detail_links):\n",
    "                # polite pause\n",
    "                if i > 0:\n",
    "                    time.sleep(random.uniform(*DETAIL_PAUSE))\n",
    "                attempt = 0\n",
    "                success = False\n",
    "                while attempt <= MAX_DETAIL_RETRIES and not success:\n",
    "                    try:\n",
    "                        driver.get(dl)\n",
    "                        time.sleep(1.0 + random.random()*0.8)\n",
    "                        dsoup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "                        # price from many possible places\n",
    "                        price_val = extract_price_from_soup(dsoup)\n",
    "                        if not price_val:\n",
    "                            price_val = extract_price_from_text(dsoup.get_text(\" \", strip=True))\n",
    "\n",
    "                        # mileage and transmission extraction now uses improved functions\n",
    "                        page_text = dsoup.get_text(\" \", strip=True)\n",
    "                        # try meta-line near title for quick values\n",
    "                        h_tag = dsoup.find([\"h1\",\"h2\"])\n",
    "                        meta_line = \"\"\n",
    "                        if h_tag:\n",
    "                            nxt = h_tag.find_next()\n",
    "                            checks = 0\n",
    "                            while nxt and checks < 8:\n",
    "                                t = text_of(nxt)\n",
    "                                if t and ((\"kms\" in t.lower()) or (\"₹\" in t) or re.search(r'\\b\\d+\\s*(?:kmpl|km/kg|km/kwh|km/l|kpl)\\b', t, flags=re.I)):\n",
    "                                    meta_line = t\n",
    "                                    break\n",
    "                                nxt = nxt.find_next()\n",
    "                                checks += 1\n",
    "\n",
    "                        # mileage: improved extraction\n",
    "                        mileage_val = \"\"\n",
    "                        mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
    "                        if mnode:\n",
    "                            try:\n",
    "                                parent = mnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    mileage_val = text_of(sib)\n",
    "                            except:\n",
    "                                mileage_val = \"\"\n",
    "                        if not mileage_val:\n",
    "                            # check meta_line then page_text using improved extract_mileage\n",
    "                            mileage_val = extract_mileage(meta_line or page_text) or extract_mileage(page_text)\n",
    "\n",
    "                        # transmission\n",
    "                        trans_val = \"\"\n",
    "                        tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n",
    "                        if tnode:\n",
    "                            try:\n",
    "                                parent = tnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    trans_val = text_of(sib)\n",
    "                            except:\n",
    "                                trans_val = \"\"\n",
    "                        if not trans_val:\n",
    "                            trans_val = extract_transmission(meta_line or page_text)\n",
    "\n",
    "                        # normalize mileage into consistent 'X kmpl' format (handled by extract_mileage)\n",
    "                        mileage_clean = extract_mileage(mileage_val or \"\")\n",
    "                        detail_map[dl] = {\n",
    "                            \"price\": price_val or \"\",\n",
    "                            \"mileage\": mileage_clean or \"\",\n",
    "                            \"transmission\": trans_val or \"\"\n",
    "                        }\n",
    "                        success = True\n",
    "                    except Exception as e:\n",
    "                        attempt += 1\n",
    "                        if attempt > MAX_DETAIL_RETRIES:\n",
    "                            detail_map[dl] = {\"price\": \"\", \"mileage\": \"\", \"transmission\": \"\"}\n",
    "                            success = True\n",
    "                        else:\n",
    "                            time.sleep(0.8)\n",
    "\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print(f\"Processed {i+1} detail pages...\")\n",
    "\n",
    "            # merge into rows\n",
    "            for r in rows:\n",
    "                link = r.get(\"detail_page\", \"\")\n",
    "                if link and link in detail_map:\n",
    "                    if not r.get(\"price\"):\n",
    "                        r[\"price\"] = detail_map[link][\"price\"]\n",
    "                    # set mileage/transmission from detail\n",
    "                    if detail_map[link].get(\"mileage\"):\n",
    "                        r[\"mileage\"] = detail_map[link][\"mileage\"]\n",
    "                    if detail_map[link].get(\"transmission\"):\n",
    "                        r[\"transmission\"] = detail_map[link][\"transmission\"]\n",
    "\n",
    "        # final normalization\n",
    "        df = pd.DataFrame(rows, columns=[\n",
    "            \"Car_name\",\"brand\",\"model\",\"kms_driven\",\"mileage\",\"transmission\",\"fuel_type\",\"year_of_manufacture\",\"price\",\"detail_page\"\n",
    "        ])\n",
    "        df[\"kms_driven\"] = df[\"kms_driven\"].fillna(\"\").astype(str).apply(lambda x: re.sub(r'[^\\d\\.]', '', x))\n",
    "        df[\"mileage\"] = df[\"mileage\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"transmission\"] = df[\"transmission\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "        df[\"year_of_manufacture\"] = df[\"year_of_manufacture\"].fillna(\"\").astype(str).apply(lambda x: (re.search(r'\\b(19|20)\\d{2}\\b', x).group(0) if re.search(r'\\b(19|20)\\d{2}\\b', x) else \"\"))\n",
    "        df[\"price\"] = df[\"price\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"fuel_type\"] = df[\"fuel_type\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "\n",
    "        # dedupe\n",
    "        if \"detail_page\" in df.columns and df[\"detail_page\"].str.len().sum() > 0:\n",
    "            df = df.drop_duplicates(subset=[\"detail_page\"]).reset_index(drop=True)\n",
    "        else:\n",
    "            df = df.drop_duplicates(subset=[\"Car_name\",\"price\"]).reset_index(drop=True)\n",
    "\n",
    "        # save\n",
    "        df.to_csv(OUTPUT_CSV, index=False)\n",
    "        df.to_excel(OUTPUT_XLSX, index=False)\n",
    "        print(f\"Saved {len(df)} rows to {OUTPUT_CSV} and {OUTPUT_XLSX}\")\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# helpers used in detail extraction (note: improved extract_mileage used above)\n",
    "def extract_mileage_fallback(text):\n",
    "    # kept for compatibility; call improved extractor\n",
    "    return extract_mileage(text)\n",
    "\n",
    "def extract_transmission(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    for t in [\"Manual\",\"Automatic\",\"CVT\",\"AMT\",\"DCT\",\"AT\",\"MT\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', text, flags=re.I):\n",
    "            if t.upper() in (\"AT\",\"AMT\",\"CVT\",\"DCT\",\"MT\"):\n",
    "                return t.upper()\n",
    "            return t.title()\n",
    "    return \"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec5ea06-c0be-4b7d-b85f-d8a0c180723e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

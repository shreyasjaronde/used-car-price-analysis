{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9ed91d-edee-44c7-80da-7323e9656838",
   "metadata": {},
   "source": [
    "Stage 1 of Indore Data Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e24204-5782-4a33-ad4d-13ea434a6a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected total_listings=505, per_page_guess=66, total_pages=8\n",
      "Collected 492 card-level rows, discovered 474 detail links.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_20916\\1987449390.py:316: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_20916\\1987449390.py:332: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 detail pages...\n",
      "Processed 200 detail pages...\n",
      "Processed 300 detail pages...\n",
      "Processed 400 detail pages...\n",
      "Done. Collected 475 rows. Saved to cardekho_used_cars_indore_with_mileage.csv and cardekho_used_cars_indore_with_mileage.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "cardekho_used_indore_scraper_with_mileage.py\n",
    "\n",
    "Scrapes https://www.cardekho.com/used-cars+in+indore and writes CSV + Excel.\n",
    "Extracted columns:\n",
    "Car_name, brand, model, kms_driven, mileage, transmission, fuel_type, year_of_manufacture, price, detail_page\n",
    "\n",
    "Requires: selenium, beautifulsoup4, pandas, openpyxl, webdriver-manager\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# -------- CONFIG ----------\n",
    "# START_URL = \"https://www.cardekho.com/used-cars+in+hyderabad\"\n",
    "START_URL = \"https://www.cardekho.com/used-cars+in+indore\"   # URL for indore\n",
    "OUTPUT_CSV = \"cardekho_used_cars_indore_with_mileage.csv\"\n",
    "OUTPUT_XLSX = \"cardekho_used_cars_indore_with_mileage.xlsx\"\n",
    "\n",
    "HEADLESS = True                 # Set False to watch browser\n",
    "MAX_PAGES_OVERRIDE = None       # Set to int to force how many result pages to scan; None -> auto-detect\n",
    "MAX_SCROLLS = 40                # scroll rounds per search-result page\n",
    "SCROLL_PAUSE = 0.7\n",
    "PAGE_PAUSE = (0.6, 1.4)\n",
    "VISIT_DETAIL_PAGES = True       # True -> open each listing detail page for mileage/transmission accuracy\n",
    "DETAIL_PAUSE = (0.6, 1.2)\n",
    "MAX_DETAIL_RETRIES = 1         # retry detail page once on failure\n",
    "# Brands to help split brand/model\n",
    "BRANDS = [\n",
    "    \"Maruti\", \"Hyundai\", \"Tata\", \"Honda\", \"Toyota\", \"Mahindra\", \"Kia\",\n",
    "    \"BMW\", \"Audi\", \"Mercedes-Benz\", \"Mercedes\", \"Renault\", \"MG\", \"Skoda\",\n",
    "    \"Volkswagen\", \"Ford\", \"Nissan\", \"Jeep\", \"Volvo\", \"Land Rover\", \"Jaguar\",\n",
    "    \"Isuzu\", \"Datsun\", \"Chevrolet\", \"Opel\"\n",
    "]\n",
    "# --------------------------\n",
    "\n",
    "# Helper parsers\n",
    "def guess_brand_and_model(name):\n",
    "    if not name:\n",
    "        return \"\", \"\"\n",
    "    for b in BRANDS:\n",
    "        if b.lower() in name.lower():\n",
    "            model = re.sub(re.escape(b), \"\", name, flags=re.IGNORECASE).strip()\n",
    "            model = re.sub(r'^[\\-\\:\\–\\—\\s]+', '', model)\n",
    "            return b, model or name\n",
    "    parts = name.split()\n",
    "    return (parts[0], \" \".join(parts[1:]) if len(parts) > 1 else \"\") if parts else (\"\",\"\")\n",
    "\n",
    "def extract_kms(text):\n",
    "    m = re.search(r'([\\d,\\.]+)\\s*(?:kms|km)\\b', text, flags=re.I)\n",
    "    if m:\n",
    "        return m.group(1).replace(\",\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "def extract_fuel(text):\n",
    "    for f in [\"Petrol\", \"Diesel\", \"CNG\", \"LPG\", \"Electric\", \"Hybrid\"]:\n",
    "        if re.search(r'\\b' + re.escape(f) + r'\\b', text, flags=re.I):\n",
    "            return f\n",
    "    return \"\"\n",
    "\n",
    "def extract_price(text):\n",
    "    m = re.search(r'₹\\s*[\\d\\.,\\sA-Za-z]+', text)\n",
    "    if m:\n",
    "        return m.group(0).strip()\n",
    "    m2 = re.search(r'[\\d\\.,]+\\s*(Lakh|lakh|Lakhs|lakhs|Crore|crore|Cr)\\b', text)\n",
    "    if m2:\n",
    "        return m2.group(0)\n",
    "    return \"\"\n",
    "\n",
    "def extract_year(text):\n",
    "    m = re.search(r'\\b(19|20)\\d{2}\\b', text)\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    "# mileage pattern examples:\n",
    "# 18.5 kmpl, 22 km/kg, 120 km/kWh, 18 kmpl (ARAI), 25.6 kmpl\n",
    "MILEAGE_REGEXES = [\n",
    "    re.compile(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|km/kg|km/kwh|km/l|kmperlitre|km/gal|km/100km|kml|kpl)\\b', flags=re.I),\n",
    "    re.compile(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(km(?:/kwh|/kg|pl)?)\\b', flags=re.I),\n",
    "    re.compile(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(mpg|mpg\\;)', flags=re.I)\n",
    "]\n",
    "\n",
    "def extract_mileage(text):\n",
    "    txt = text.replace(\"\\xa0\",\" \").strip()\n",
    "    for rx in MILEAGE_REGEXES:\n",
    "        m = rx.search(txt)\n",
    "        if m:\n",
    "            val = m.group(1)\n",
    "            unit = m.group(2)\n",
    "            return f\"{val} {unit}\".strip()\n",
    "    # sometimes written like \"Mileage: 18.5 kmpl\" or \"18.5kmpl\"\n",
    "    m2 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|km/kg|km/kwh|km|kpl|km/l)\\b', txt, flags=re.I)\n",
    "    if m2:\n",
    "        return f\"{m2.group(1)} {m2.group(2)}\"\n",
    "    return \"\"\n",
    "\n",
    "# transmission extraction\n",
    "def extract_transmission(text):\n",
    "    for t in [\"Manual\", \"Automatic\", \"CVT\", \"AMT\", \"DCT\", \"AT\", \"MT\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', text, flags=re.I):\n",
    "            # normalize common variants\n",
    "            if t.upper() in (\"AT\",\"AMT\",\"CVT\",\"DCT\",\"MT\"):\n",
    "                return t.upper()\n",
    "            return t.title()\n",
    "    return \"\"\n",
    "\n",
    "# safe text extractor for BeautifulSoup element\n",
    "def text_of(elem):\n",
    "    return elem.get_text(\" \", strip=True) if elem else \"\"\n",
    "\n",
    "# ---------- main ----------\n",
    "def main():\n",
    "    # Setup Selenium Chrome\n",
    "    chrome_opts = Options()\n",
    "    if HEADLESS:\n",
    "        chrome_opts.add_argument(\"--headless=new\")\n",
    "    chrome_opts.add_argument(\"--no-sandbox\")\n",
    "    chrome_opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_opts.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_opts.add_argument(\"--disable-gpu\")\n",
    "    chrome_opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_opts)\n",
    "\n",
    "    try:\n",
    "        # load first page and detect pages count\n",
    "        driver.get(START_URL)\n",
    "        time.sleep(2.0)\n",
    "        soup0 = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        page_text = soup0.get_text(\" \", strip=True)\n",
    "\n",
    "        total_listings = None\n",
    "        m = re.search(r'([\\d,]{2,})\\s+Second Hand Cars in Indore', page_text, flags=re.I)\n",
    "        if not m:\n",
    "            m = re.search(r'of\\s+([\\d,]+)\\s+results', page_text, flags=re.I)\n",
    "        if m:\n",
    "            total_listings = int(m.group(1).replace(\",\", \"\"))\n",
    "\n",
    "        per_page_guess = max(1, len(soup0.find_all(\"h3\")))\n",
    "        estimated_pages = math.ceil(total_listings / per_page_guess) if total_listings else None\n",
    "        total_pages = int(estimated_pages) if estimated_pages else 200\n",
    "        if MAX_PAGES_OVERRIDE:\n",
    "            total_pages = MAX_PAGES_OVERRIDE\n",
    "\n",
    "        print(f\"Detected total_listings={total_listings}, per_page_guess={per_page_guess}, total_pages={total_pages}\")\n",
    "\n",
    "        rows = []\n",
    "        seen_keys = set()\n",
    "        detail_links = []\n",
    "\n",
    "        # iterate search result pages\n",
    "        for p in range(1, total_pages + 1):\n",
    "            page_url = START_URL.rstrip(\"/\") + \"?page=\" + str(p)\n",
    "            try:\n",
    "                driver.get(page_url)\n",
    "            except Exception:\n",
    "                time.sleep(1.0)\n",
    "                driver.get(page_url)\n",
    "\n",
    "            # aggressively scroll to let lazy content load\n",
    "            last_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            scroll_count = 0\n",
    "            while scroll_count < MAX_SCROLLS:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(SCROLL_PAUSE)\n",
    "                new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_h == last_h:\n",
    "                    # wiggle\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight-400);\")\n",
    "                    time.sleep(0.4)\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    time.sleep(0.4)\n",
    "                    new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                    if new_h == last_h:\n",
    "                        break\n",
    "                last_h = new_h\n",
    "                scroll_count += 1\n",
    "\n",
    "            page_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "            # find title nodes (h3) and extract card container text\n",
    "            titles = page_soup.find_all(\"h3\")\n",
    "            for h in titles:\n",
    "                title = text_of(h)\n",
    "                if not title:\n",
    "                    continue\n",
    "\n",
    "                # climb up to find a container with price or kms present\n",
    "                container = h\n",
    "                card_text = \"\"\n",
    "                link = \"\"\n",
    "                for _ in range(6):\n",
    "                    if container is None:\n",
    "                        break\n",
    "                    card_text = text_of(container)\n",
    "                    if \"₹\" in card_text or re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I):\n",
    "                        # find anchor inside container for detail link if present\n",
    "                        a = container.find(\"a\", href=True)\n",
    "                        if a:\n",
    "                            href = a[\"href\"]\n",
    "                            link = href if \"cardekho.com\" in href else urljoin(page_url, href)\n",
    "                            link = link.split(\"#\")[0].split(\"?utm\")[0]\n",
    "                        break\n",
    "                    container = container.parent\n",
    "\n",
    "                if not card_text:\n",
    "                    # fallback to grabbing parent text\n",
    "                    parent = h.parent\n",
    "                    card_text = text_of(parent) if parent else title\n",
    "\n",
    "                # check minimal heuristics: price or kms exist\n",
    "                if (\"₹\" not in card_text) and (re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I) is None):\n",
    "                    continue\n",
    "\n",
    "                # dedupe by title+price\n",
    "                price_snip = extract_price(card_text)\n",
    "                key = (title + \"||\" + price_snip).strip()\n",
    "                if key in seen_keys:\n",
    "                    continue\n",
    "                seen_keys.add(key)\n",
    "\n",
    "                kms = extract_kms(card_text)\n",
    "                fuel = extract_fuel(card_text)\n",
    "                year = extract_year(title) or extract_year(card_text)\n",
    "                brand, model = guess_brand_and_model(title)\n",
    "                price = price_snip\n",
    "\n",
    "                # prepare base row (mileage/transmission may be blank now; fill from detail page if VISIT_DETAIL_PAGES)\n",
    "                rows.append({\n",
    "                    \"Car_name\": title,\n",
    "                    \"brand\": brand,\n",
    "                    \"model\": model,\n",
    "                    \"kms_driven\": kms,\n",
    "                    \"mileage\": \"\",             # to fill\n",
    "                    \"transmission\": \"\",       # to fill\n",
    "                    \"fuel_type\": fuel,\n",
    "                    \"year_of_manufacture\": year,\n",
    "                    \"price\": price,\n",
    "                    \"detail_page\": link\n",
    "                })\n",
    "\n",
    "                if link:\n",
    "                    detail_links.append(link)\n",
    "\n",
    "            # jitter between pages\n",
    "            time.sleep(random.uniform(*PAGE_PAUSE))\n",
    "\n",
    "            # early stop if found >= total_listings\n",
    "            if total_listings and len(seen_keys) >= total_listings:\n",
    "                print(\"Reached detected total listings; stopping page scan.\")\n",
    "                break\n",
    "\n",
    "            # small progress print\n",
    "            if p % 10 == 0:\n",
    "                print(f\"Scanned page {p}; collected rows so far: {len(rows)}\")\n",
    "\n",
    "        print(f\"Collected {len(rows)} card-level rows, discovered {len(set(detail_links))} detail links.\")\n",
    "\n",
    "        # Optionally visit detail pages for mileage + transmission (more accurate)\n",
    "        if VISIT_DETAIL_PAGES and detail_links:\n",
    "            unique_detail_links = []\n",
    "            seen_dl = set()\n",
    "            for u in detail_links:\n",
    "                if u and u not in seen_dl:\n",
    "                    seen_dl.add(u)\n",
    "                    unique_detail_links.append(u)\n",
    "\n",
    "            # map detail_link -> parsed fields\n",
    "            detail_map = {}\n",
    "\n",
    "            for i, dl in enumerate(unique_detail_links):\n",
    "                # small polite wait\n",
    "                if i > 0:\n",
    "                    time.sleep(random.uniform(*DETAIL_PAUSE))\n",
    "\n",
    "                # retry loop\n",
    "                attempt = 0\n",
    "                success = False\n",
    "                while attempt <= MAX_DETAIL_RETRIES and not success:\n",
    "                    try:\n",
    "                        driver.get(dl)\n",
    "                        time.sleep(1.0 + random.random()*0.8)  # allow JS\n",
    "                        dsoup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                        page_text = dsoup.get_text(\" \", strip=True)\n",
    "\n",
    "                        # Try structured lookups:\n",
    "                        # 1) meta-line near the H1/H2 (often contains \"kms • Petrol • 2019 • 18.5 kmpl • Automatic\")\n",
    "                        h_tag = dsoup.find([\"h1\",\"h2\"])\n",
    "                        meta_line = \"\"\n",
    "                        if h_tag:\n",
    "                            nxt = h_tag.find_next()\n",
    "                            checks = 0\n",
    "                            while nxt and checks < 8:\n",
    "                                t = text_of(nxt)\n",
    "                                if t and ((\"kms\" in t.lower()) or (\"₹\" in t) or re.search(r'\\b\\d+\\s*(?:kmpl|km/kg|km/kwh|km/l|kpl)\\b', t, flags=re.I)):\n",
    "                                    meta_line = t\n",
    "                                    break\n",
    "                                nxt = nxt.find_next()\n",
    "                                checks += 1\n",
    "\n",
    "                        # 2) labeled field lookup: look for text nodes like 'Mileage' or 'Transmission' and read siblings\n",
    "                        # Mileage\n",
    "                        mileage_val = \"\"\n",
    "                        # find text nodes \"Mileage\" or \"Avg. Mileage\" etc.\n",
    "                        mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
    "                        if mnode:\n",
    "                            try:\n",
    "                                # sibling / next element may contain value\n",
    "                                parent = mnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    mileage_val = text_of(sib)\n",
    "                            except:\n",
    "                                mileage_val = \"\"\n",
    "                        if not mileage_val:\n",
    "                            # try meta_line and page_text\n",
    "                            mileage_val = extract_mileage(meta_line or page_text) or extract_mileage(page_text)\n",
    "\n",
    "                        # Transmission\n",
    "                        trans_val = \"\"\n",
    "                        tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n",
    "                        if tnode:\n",
    "                            try:\n",
    "                                parent = tnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    trans_val = text_of(sib)\n",
    "                            except:\n",
    "                                trans_val = \"\"\n",
    "                        if not trans_val:\n",
    "                            trans_val = extract_transmission(meta_line or page_text)\n",
    "\n",
    "                        # Normalize/massage values\n",
    "                        mileage_clean = extract_mileage(mileage_val or \"\")\n",
    "                        transmission_clean = extract_transmission(trans_val or \"\")\n",
    "\n",
    "                        # fallback: sometimes card-level has mileage like '18 kmpl' in small text — try to extract from page text\n",
    "                        if not mileage_clean:\n",
    "                            mileage_clean = extract_mileage(page_text)\n",
    "\n",
    "                        # store\n",
    "                        detail_map[dl] = {\n",
    "                            \"mileage\": mileage_clean,\n",
    "                            \"transmission\": transmission_clean\n",
    "                        }\n",
    "                        success = True\n",
    "                    except Exception as e:\n",
    "                        attempt += 1\n",
    "                        if attempt > MAX_DETAIL_RETRIES:\n",
    "                            # give empty values on failure\n",
    "                            detail_map[dl] = {\"mileage\": \"\", \"transmission\": \"\"}\n",
    "                            success = True\n",
    "                        else:\n",
    "                            time.sleep(0.8)\n",
    "\n",
    "                # progress print occasionally\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print(f\"Processed {i+1} detail pages...\")\n",
    "\n",
    "            # Now merge detail_map into rows\n",
    "            for r in rows:\n",
    "                link = r.get(\"detail_page\", \"\")\n",
    "                if link and link in detail_map:\n",
    "                    r[\"mileage\"] = detail_map[link][\"mileage\"]\n",
    "                    r[\"transmission\"] = detail_map[link][\"transmission\"]\n",
    "                else:\n",
    "                    # attempt to find mileage/trans in the card text (already tried earlier)\n",
    "                    # leave empty if not found\n",
    "                    if not r[\"mileage\"]:\n",
    "                        # try to infer from model/name\n",
    "                        r[\"mileage\"] = \"\"\n",
    "                    if not r[\"transmission\"]:\n",
    "                        r[\"transmission\"] = \"\"\n",
    "\n",
    "        # build DataFrame and clean\n",
    "        df = pd.DataFrame(rows, columns=[\n",
    "            \"Car_name\", \"brand\", \"model\", \"kms_driven\", \"mileage\", \"transmission\",\n",
    "            \"fuel_type\", \"year_of_manufacture\", \"price\", \"detail_page\"\n",
    "        ])\n",
    "\n",
    "        # normalize\n",
    "        df[\"kms_driven\"] = df[\"kms_driven\"].fillna(\"\").astype(str).apply(lambda x: re.sub(r'[^\\d\\.]', '', x))\n",
    "        df[\"mileage\"] = df[\"mileage\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"transmission\"] = df[\"transmission\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "        df[\"year_of_manufacture\"] = df[\"year_of_manufacture\"].fillna(\"\").astype(str).apply(lambda x: (re.search(r'\\b(19|20)\\d{2}\\b', x).group(0) if re.search(r'\\b(19|20)\\d{2}\\b', x) else \"\"))\n",
    "        df[\"price\"] = df[\"price\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"fuel_type\"] = df[\"fuel_type\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "\n",
    "        # dedupe by detail_link if present else by Car_name+price\n",
    "        if df[\"detail_page\"].notnull().sum() > 0:\n",
    "            df = df.drop_duplicates(subset=[\"detail_page\"]).reset_index(drop=True)\n",
    "        else:\n",
    "            df = df.drop_duplicates(subset=[\"Car_name\", \"price\"]).reset_index(drop=True)\n",
    "\n",
    "        # save\n",
    "        df.to_csv(OUTPUT_CSV, index=False)\n",
    "        df.to_excel(OUTPUT_XLSX, index=False)\n",
    "        print(f\"Done. Collected {len(df)} rows. Saved to {OUTPUT_CSV} and {OUTPUT_XLSX}\")\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93149b59-3efd-4045-aaa3-ed5792ded0af",
   "metadata": {},
   "source": [
    "2nd Stage of Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395a4eaf-1f9a-4f89-9536-5f684921a953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected total_listings=504, per_page_guess=66, total_pages=8\n",
      "Collected 495 card-level rows, detail links: 473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_20916\\2403242897.py:339: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_20916\\2403242897.py:354: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 detail pages...\n",
      "Processed 200 detail pages...\n",
      "Processed 300 detail pages...\n",
      "Processed 400 detail pages...\n",
      "Saved 474 rows to cardekho_used_cars_indore_price_fixed.csv and cardekho_used_cars_indore_price_fixed.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "cardekho_with_price_fix.py\n",
    "\n",
    "Improved scraper for CarDekho used cars (Indore) with robust price extraction.\n",
    "Requires: selenium, webdriver-manager, beautifulsoup4, pandas, openpyxl\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# -------- CONFIG ----------\n",
    "START_URL = \"https://www.cardekho.com/used-cars+in+indore\"\n",
    "OUTPUT_CSV = \"cardekho_used_cars_indore_price_fixed.csv\"\n",
    "OUTPUT_XLSX = \"cardekho_used_cars_indore_price_fixed.xlsx\"\n",
    "\n",
    "HEADLESS = True\n",
    "MAX_PAGES_OVERRIDE = None\n",
    "MAX_SCROLLS = 40\n",
    "SCROLL_PAUSE = 0.7\n",
    "PAGE_PAUSE = (0.6, 1.4)\n",
    "VISIT_DETAIL_PAGES = True\n",
    "DETAIL_PAUSE = (0.6, 1.2)\n",
    "MAX_DETAIL_RETRIES = 1\n",
    "\n",
    "BRANDS = [\n",
    "    \"Maruti\", \"Hyundai\", \"Tata\", \"Honda\", \"Toyota\", \"Mahindra\", \"Kia\",\n",
    "    \"BMW\", \"Audi\", \"Mercedes-Benz\", \"Mercedes\", \"Renault\", \"MG\", \"Skoda\",\n",
    "    \"Volkswagen\", \"Ford\", \"Nissan\", \"Jeep\", \"Volvo\", \"Land Rover\", \"Jaguar\",\n",
    "    \"Isuzu\", \"Datsun\", \"Chevrolet\", \"Opel\"\n",
    "]\n",
    "# --------------------------\n",
    "\n",
    "def text_of(elem):\n",
    "    return elem.get_text(\" \", strip=True) if elem else \"\"\n",
    "\n",
    "def guess_brand_and_model(name):\n",
    "    if not name:\n",
    "        return \"\", \"\"\n",
    "    for b in BRANDS:\n",
    "        if b.lower() in name.lower():\n",
    "            model = re.sub(re.escape(b), \"\", name, flags=re.IGNORECASE).strip()\n",
    "            model = re.sub(r'^[\\-\\:\\–\\—\\s]+', '', model)\n",
    "            return b, model or name\n",
    "    parts = name.split()\n",
    "    return (parts[0], \" \".join(parts[1:]) if len(parts) > 1 else \"\") if parts else (\"\",\"\")\n",
    "\n",
    "def extract_kms(text):\n",
    "    m = re.search(r'([\\d,\\.]+)\\s*(?:kms|km)\\b', text, flags=re.I)\n",
    "    if m:\n",
    "        return m.group(1).replace(\",\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "def extract_fuel(text):\n",
    "    for f in [\"Petrol\", \"Diesel\", \"CNG\", \"LPG\", \"Electric\", \"Hybrid\"]:\n",
    "        if re.search(r'\\b' + re.escape(f) + r'\\b', text, flags=re.I):\n",
    "            return f\n",
    "    return \"\"\n",
    "\n",
    "# NEW: robust price extraction from soup and raw text\n",
    "def extract_price_from_soup(soup):\n",
    "    # 1. meta tags\n",
    "    meta_selectors = [\n",
    "        ('meta', {'property': 'og:price:amount'}),\n",
    "        ('meta', {'itemprop': 'price'}),\n",
    "        ('meta', {'name': 'price'}),\n",
    "    ]\n",
    "    for tag, attrs in meta_selectors:\n",
    "        mtag = soup.find(tag, attrs=attrs)\n",
    "        if mtag:\n",
    "            val = mtag.get('content') or mtag.get('value') or \"\"\n",
    "            if val:\n",
    "                # normalize: prepend ₹ if numeric and no symbol\n",
    "                if re.search(r'[\\d]', val) and '₹' not in val:\n",
    "                    return \"₹ \" + val.strip()\n",
    "                return val.strip()\n",
    "\n",
    "    # 2. attributes that often store price\n",
    "    for attr in ('data-price', 'data-offer-price', 'data-srp', 'data-amount', 'data-price-value'):\n",
    "        el = soup.find(attrs={attr: True})\n",
    "        if el:\n",
    "            val = el.get(attr)\n",
    "            if val:\n",
    "                if re.search(r'[\\d]', val) and '₹' not in val:\n",
    "                    return \"₹ \" + val.strip()\n",
    "                return val.strip()\n",
    "\n",
    "    # 3. elements with class or id containing 'price' or 'amount'\n",
    "    px = soup.find(lambda tag: tag.name in (\"div\",\"span\",\"p\",\"strong\") and (\n",
    "        tag.get(\"class\") or tag.get(\"id\")\n",
    "    ) and re.search(r'price|amount|selling|srp|finalPrice|carPrice|actual-price', \" \".join((tag.get(\"class\") or []) + [tag.get(\"id\") or \"\"]), flags=re.I))\n",
    "    if px:\n",
    "        txt = text_of(px)\n",
    "        pr = find_rupee_in_text(txt)\n",
    "        if pr:\n",
    "            return pr\n",
    "        if txt:\n",
    "            return txt.strip()\n",
    "\n",
    "    # 4. any visible text near top with rupee sign\n",
    "    top_region = \"\"\n",
    "    # try header / top sections\n",
    "    head_candidates = soup.find_all([\"header\", \"section\", \"div\"], limit=6)\n",
    "    for c in head_candidates:\n",
    "        t = text_of(c)\n",
    "        if '₹' in t:\n",
    "            top_region = t\n",
    "            break\n",
    "    if not top_region:\n",
    "        # fallback full page text (takes last resort)\n",
    "        top_region = soup.get_text(\" \", strip=True)\n",
    "\n",
    "    pr = find_rupee_in_text(top_region)\n",
    "    if pr:\n",
    "        return pr\n",
    "\n",
    "    # 5. fallback regex on whole page (Lakh/Crore)\n",
    "    p2 = re.search(r'[\\d\\.,]+\\s*(?:Lakh|lakh|Lakhs|lakhs|Crore|crore|Cr)\\b', soup.get_text(\" \", strip=True))\n",
    "    if p2:\n",
    "        return p2.group(0).strip()\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def find_rupee_in_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    m = re.search(r'₹\\s*[\\d\\.,\\sA-Za-z]+', text)\n",
    "    if m:\n",
    "        return m.group(0).strip()\n",
    "    # sometimes rupee symbol is missing but values use lakh/crore\n",
    "    m2 = re.search(r'[\\d\\.,]+\\s*(Lakh|lakh|Lakhs|lakhs|Crore|crore|Cr)\\b', text)\n",
    "    if m2:\n",
    "        return m2.group(0).strip()\n",
    "    return \"\"\n",
    "\n",
    "def extract_price_from_text(text):\n",
    "    # ensures same fallback when only raw text available\n",
    "    p = find_rupee_in_text(text)\n",
    "    return p\n",
    "\n",
    "def extract_year(text):\n",
    "    m = re.search(r'\\b(19|20)\\d{2}\\b', text)\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    "# main\n",
    "def main():\n",
    "    chrome_opts = Options()\n",
    "    if HEADLESS:\n",
    "        chrome_opts.add_argument(\"--headless=new\")\n",
    "    chrome_opts.add_argument(\"--no-sandbox\")\n",
    "    chrome_opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_opts.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_opts)\n",
    "\n",
    "    try:\n",
    "        driver.get(START_URL)\n",
    "        time.sleep(2.0)\n",
    "        soup0 = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        text0 = soup0.get_text(\" \", strip=True)\n",
    "\n",
    "        total_listings = None\n",
    "        m = re.search(r'([\\d,]{2,})\\s+Second Hand Cars in Indore', text0, flags=re.I)\n",
    "        if not m:\n",
    "            m = re.search(r'of\\s+([\\d,]+)\\s+results', text0, flags=re.I)\n",
    "        if m:\n",
    "            total_listings = int(m.group(1).replace(\",\", \"\"))\n",
    "\n",
    "        per_page_guess = max(1, len(soup0.find_all(\"h3\")))\n",
    "        estimated_pages = math.ceil(total_listings / per_page_guess) if total_listings else None\n",
    "        total_pages = int(estimated_pages) if estimated_pages else 200\n",
    "        if MAX_PAGES_OVERRIDE:\n",
    "            total_pages = MAX_PAGES_OVERRIDE\n",
    "\n",
    "        print(f\"Detected total_listings={total_listings}, per_page_guess={per_page_guess}, total_pages={total_pages}\")\n",
    "\n",
    "        rows = []\n",
    "        seen_keys = set()\n",
    "        detail_links = []\n",
    "\n",
    "        for p in range(1, total_pages + 1):\n",
    "            page_url = START_URL.rstrip(\"/\") + \"?page=\" + str(p)\n",
    "            try:\n",
    "                driver.get(page_url)\n",
    "            except Exception:\n",
    "                time.sleep(1.0)\n",
    "                driver.get(page_url)\n",
    "\n",
    "            # scroll aggressively\n",
    "            last_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            sc = 0\n",
    "            while sc < MAX_SCROLLS:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(SCROLL_PAUSE)\n",
    "                new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_h == last_h:\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight-400);\")\n",
    "                    time.sleep(0.4)\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    time.sleep(0.4)\n",
    "                    new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                    if new_h == last_h:\n",
    "                        break\n",
    "                last_h = new_h\n",
    "                sc += 1\n",
    "\n",
    "            page_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            titles = page_soup.find_all(\"h3\")\n",
    "            for h in titles:\n",
    "                title = text_of(h)\n",
    "                if not title:\n",
    "                    continue\n",
    "\n",
    "                container = h\n",
    "                card_text = \"\"\n",
    "                link = \"\"\n",
    "                for _ in range(6):\n",
    "                    if container is None:\n",
    "                        break\n",
    "                    card_text = text_of(container)\n",
    "                    if \"₹\" in card_text or re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I):\n",
    "                        a = container.find(\"a\", href=True)\n",
    "                        if a:\n",
    "                            href = a[\"href\"]\n",
    "                            link = href if \"cardekho.com\" in href else urljoin(page_url, href)\n",
    "                            link = link.split(\"#\")[0].split(\"?utm\")[0]\n",
    "                        break\n",
    "                    container = container.parent\n",
    "\n",
    "                if not card_text:\n",
    "                    parent = h.parent\n",
    "                    card_text = text_of(parent) if parent else title\n",
    "\n",
    "                if (\"₹\" not in card_text) and (re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I) is None):\n",
    "                    continue\n",
    "\n",
    "                price_card = extract_price_from_text(card_text)\n",
    "                key = (title + \"||\" + (price_card or \"\")).strip()\n",
    "                if key in seen_keys:\n",
    "                    continue\n",
    "                seen_keys.add(key)\n",
    "\n",
    "                kms = extract_kms(card_text)\n",
    "                fuel = extract_fuel(card_text)\n",
    "                year = extract_year(title) or extract_year(card_text)\n",
    "                brand = \"\"\n",
    "                model = \"\"\n",
    "                try:\n",
    "                    brand, model = guess_brand_and_model(title)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                rows.append({\n",
    "                    \"Car_name\": title,\n",
    "                    \"brand\": brand,\n",
    "                    \"model\": model,\n",
    "                    \"kms_driven\": kms,\n",
    "                    \"mileage\": \"\",\n",
    "                    \"transmission\": \"\",\n",
    "                    \"fuel_type\": fuel,\n",
    "                    \"year_of_manufacture\": year,\n",
    "                    \"price\": price_card,\n",
    "                    \"detail_page\": link\n",
    "                })\n",
    "\n",
    "                if link:\n",
    "                    detail_links.append(link)\n",
    "\n",
    "            time.sleep(random.uniform(*PAGE_PAUSE))\n",
    "\n",
    "            if total_listings and len(seen_keys) >= total_listings:\n",
    "                print(\"Reached detected total listings; stopping page scan.\")\n",
    "                break\n",
    "\n",
    "            if p % 10 == 0:\n",
    "                print(f\"Scanned page {p}; rows so far: {len(rows)}\")\n",
    "\n",
    "        print(f\"Collected {len(rows)} card-level rows, detail links: {len(set(detail_links))}\")\n",
    "\n",
    "        # Now ensure price is filled: visit detail pages for any row missing price\n",
    "        if VISIT_DETAIL_PAGES and detail_links:\n",
    "            unique_detail_links = []\n",
    "            seen_dl = set()\n",
    "            for u in detail_links:\n",
    "                if u and u not in seen_dl:\n",
    "                    seen_dl.add(u)\n",
    "                    unique_detail_links.append(u)\n",
    "\n",
    "            # map link -> price (and optionally mileage/transmission)\n",
    "            detail_map = {}\n",
    "\n",
    "            for i, dl in enumerate(unique_detail_links):\n",
    "                # polite pause\n",
    "                if i > 0:\n",
    "                    time.sleep(random.uniform(*DETAIL_PAUSE))\n",
    "                attempt = 0\n",
    "                success = False\n",
    "                while attempt <= MAX_DETAIL_RETRIES and not success:\n",
    "                    try:\n",
    "                        driver.get(dl)\n",
    "                        time.sleep(1.0 + random.random()*0.8)\n",
    "                        dsoup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "                        # price from many possible places\n",
    "                        price_val = extract_price_from_soup(dsoup)\n",
    "                        # fallback to regex on page text\n",
    "                        if not price_val:\n",
    "                            price_val = extract_price_from_text(dsoup.get_text(\" \", strip=True))\n",
    "\n",
    "                        # mileage and transmission extraction as before\n",
    "                        page_text = dsoup.get_text(\" \", strip=True)\n",
    "                        # try meta-line near title for quick values\n",
    "                        h_tag = dsoup.find([\"h1\",\"h2\"])\n",
    "                        meta_line = \"\"\n",
    "                        if h_tag:\n",
    "                            nxt = h_tag.find_next()\n",
    "                            checks = 0\n",
    "                            while nxt and checks < 8:\n",
    "                                t = text_of(nxt)\n",
    "                                if t and ((\"kms\" in t.lower()) or (\"₹\" in t) or re.search(r'\\b\\d+\\s*(?:kmpl|km/kg|km/kwh|km/l|kpl)\\b', t, flags=re.I)):\n",
    "                                    meta_line = t\n",
    "                                    break\n",
    "                                nxt = nxt.find_next()\n",
    "                                checks += 1\n",
    "\n",
    "                        # mileage\n",
    "                        mileage_val = \"\"\n",
    "                        mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
    "                        if mnode:\n",
    "                            try:\n",
    "                                parent = mnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    mileage_val = text_of(sib)\n",
    "                            except:\n",
    "                                mileage_val = \"\"\n",
    "                        if not mileage_val:\n",
    "                            # check meta_line then page_text\n",
    "                            mileage_val = extract_mileage(meta_line or page_text) or extract_mileage(page_text)\n",
    "\n",
    "                        # transmission\n",
    "                        trans_val = \"\"\n",
    "                        tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n",
    "                        if tnode:\n",
    "                            try:\n",
    "                                parent = tnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    trans_val = text_of(sib)\n",
    "                            except:\n",
    "                                trans_val = \"\"\n",
    "                        if not trans_val:\n",
    "                            trans_val = extract_transmission(meta_line or page_text)\n",
    "\n",
    "                        detail_map[dl] = {\n",
    "                            \"price\": price_val or \"\",\n",
    "                            \"mileage\": mileage_val or \"\",\n",
    "                            \"transmission\": trans_val or \"\"\n",
    "                        }\n",
    "                        success = True\n",
    "                    except Exception as e:\n",
    "                        attempt += 1\n",
    "                        if attempt > MAX_DETAIL_RETRIES:\n",
    "                            detail_map[dl] = {\"price\": \"\", \"mileage\": \"\", \"transmission\": \"\"}\n",
    "                            success = True\n",
    "                        else:\n",
    "                            time.sleep(0.8)\n",
    "\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print(f\"Processed {i+1} detail pages...\")\n",
    "\n",
    "            # merge into rows\n",
    "            for r in rows:\n",
    "                link = r.get(\"detail_page\", \"\")\n",
    "                if link and link in detail_map:\n",
    "                    # prefer detail price if card-level empty\n",
    "                    if not r.get(\"price\"):\n",
    "                        r[\"price\"] = detail_map[link][\"price\"]\n",
    "                    # always try to fill mileage/trans if available\n",
    "                    if not r.get(\"mileage\"):\n",
    "                        r[\"mileage\"] = detail_map[link][\"mileage\"]\n",
    "                    if not r.get(\"transmission\"):\n",
    "                        r[\"transmission\"] = detail_map[link][\"transmission\"]\n",
    "\n",
    "        # final normalization\n",
    "        df = pd.DataFrame(rows, columns=[\n",
    "            \"Car_name\",\"brand\",\"model\",\"kms_driven\",\"mileage\",\"transmission\",\"fuel_type\",\"year_of_manufacture\",\"price\",\"detail_page\"\n",
    "        ])\n",
    "        df[\"kms_driven\"] = df[\"kms_driven\"].fillna(\"\").astype(str).apply(lambda x: re.sub(r'[^\\d\\.]', '', x))\n",
    "        df[\"mileage\"] = df[\"mileage\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"transmission\"] = df[\"transmission\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "        df[\"year_of_manufacture\"] = df[\"year_of_manufacture\"].fillna(\"\").astype(str).apply(lambda x: (re.search(r'\\b(19|20)\\d{2}\\b', x).group(0) if re.search(r'\\b(19|20)\\d{2}\\b', x) else \"\"))\n",
    "        df[\"price\"] = df[\"price\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"fuel_type\"] = df[\"fuel_type\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "\n",
    "        # dedupe\n",
    "        if \"detail_page\" in df.columns and df[\"detail_page\"].str.len().sum() > 0:\n",
    "            df = df.drop_duplicates(subset=[\"detail_page\"]).reset_index(drop=True)\n",
    "        else:\n",
    "            df = df.drop_duplicates(subset=[\"Car_name\",\"price\"]).reset_index(drop=True)\n",
    "\n",
    "        # save\n",
    "        df.to_csv(OUTPUT_CSV, index=False)\n",
    "        df.to_excel(OUTPUT_XLSX, index=False)\n",
    "        print(f\"Saved {len(df)} rows to {OUTPUT_CSV} and {OUTPUT_XLSX}\")\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# helpers used in detail extraction (mileage/transmission)\n",
    "def extract_mileage(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # reuse a robust regex set (common patterns)\n",
    "    m = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|km/kg|km/kwh|km/l|kpl|km)', text, flags=re.I)\n",
    "    if m:\n",
    "        return f\"{m.group(1)} {m.group(2)}\".strip()\n",
    "    m2 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(mpg)\\b', text, flags=re.I)\n",
    "    if m2:\n",
    "        return f\"{m2.group(1)} {m2.group(2)}\"\n",
    "    return \"\"\n",
    "\n",
    "def extract_transmission(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    for t in [\"Manual\",\"Automatic\",\"CVT\",\"AMT\",\"DCT\",\"AT\",\"MT\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', text, flags=re.I):\n",
    "            if t.upper() in (\"AT\",\"AMT\",\"CVT\",\"DCT\",\"MT\"):\n",
    "                return t.upper()\n",
    "            return t.title()\n",
    "    return \"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0211f24-7f71-4e3a-99f3-5a8ad4e21c8a",
   "metadata": {},
   "source": [
    "3rd stage of scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de68e667-59b0-4b1a-9a6e-b82e796f135b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected total_listings=504, per_page_guess=66, total_pages_to_try=8\n",
      "Initial collection done: 495 card rows, detail links discovered: 473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_20916\\772352960.py:285: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  label_kms = dsoup.find(text=re.compile(r'Kms\\s*Driven|Kms|Odometer', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_20916\\772352960.py:302: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  label_fuel = dsoup.find(text=re.compile(r'Fuel\\s*Type|Fuel', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_20916\\772352960.py:316: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  label_year = dsoup.find(text=re.compile(r'Year\\s*of\\s*Manufacture|Registration\\s*Year|Year', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_20916\\772352960.py:339: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved after 200 detail visits: 195 rows.\n",
      "Checkpoint saved after 400 detail visits: 395 rows.\n",
      "Saved cleaned output: cardekho_used_cars_indore_clean_fixed.csv and cardekho_used_cars_indore_clean_fixed.xlsx\n",
      "Total rows collected: 474\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_name</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>kms_driven</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>year_of_manufacture</th>\n",
       "      <th>price</th>\n",
       "      <th>mileage</th>\n",
       "      <th>detail_page</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011 Hyundai i20 1.2 Magna</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2011  i20 1.2 Magna</td>\n",
       "      <td>2011202201120201020121216000020121656856934769...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2011</td>\n",
       "      <td>₹2 Lakh</td>\n",
       "      <td>1,60,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017 Maruti Alto K10 LXI Optional</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2017  Alto K10 LXI Optional</td>\n",
       "      <td>2017109983152017102014202032000315108101174559...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2017</td>\n",
       "      <td>₹3.15 Lakh</td>\n",
       "      <td>32,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017 Maruti Swift Dzire LXI</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2017  Swift Dzire LXI</td>\n",
       "      <td>2017119753520172015201772000535958783760498116...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2017</td>\n",
       "      <td>₹5.35 Lakh</td>\n",
       "      <td>72,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49 Used Cars Under 2 Lakh in Indore</td>\n",
       "      <td>49</td>\n",
       "      <td>Used Cars Under 2 Lakh in Indore</td>\n",
       "      <td>492202</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2012</td>\n",
       "      <td>₹1.70 Lakh</td>\n",
       "      <td>49 used cars Under 2 Lakh are available for sa...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+0-lakh-to-2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36 Used Cars Under 3 Lakh in Indore</td>\n",
       "      <td>36</td>\n",
       "      <td>Used Cars Under 3 Lakh in Indore</td>\n",
       "      <td>363323</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2012</td>\n",
       "      <td>₹2.85 Lakh</td>\n",
       "      <td>36 used cars Under 3 Lakh are available for sa...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+2-lakh-to-3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>117 Used Cars Under 5 Lakh in Indore</td>\n",
       "      <td>117</td>\n",
       "      <td>Used Cars Under 5 Lakh in Indore</td>\n",
       "      <td>1175535</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2014</td>\n",
       "      <td>₹3.11 Lakh</td>\n",
       "      <td>117 used cars Under 5 Lakh are available for s...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+3-lakh-to-5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>153 Used Cars Under 8 Lakh in Indore</td>\n",
       "      <td>153</td>\n",
       "      <td>Used Cars Under 8 Lakh in Indore</td>\n",
       "      <td>1538858</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2015</td>\n",
       "      <td>₹5.50 Lakh</td>\n",
       "      <td>153 used cars Under 8 Lakh are available for s...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+5-lakh-to-8...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39 Used Cars Under 10 Lakh in Indore</td>\n",
       "      <td>39</td>\n",
       "      <td>Used Cars Under 10 Lakh in Indore</td>\n",
       "      <td>391010810</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹8.51 Lakh</td>\n",
       "      <td>39 used cars Under 10 Lakh are available for s...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+8-lakh-to-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>110 Used Cars Above 10 Lakh in Indore</td>\n",
       "      <td>110</td>\n",
       "      <td>Used Cars Above 10 Lakh in Indore</td>\n",
       "      <td>1101010105</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2018</td>\n",
       "      <td>₹11 Lakh</td>\n",
       "      <td>110 used cars Above 10 Lakh are available for ...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+10-lakh-to-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019 Ford Ecosport 1.5 Diesel Trend Plus BSIV</td>\n",
       "      <td>Ford</td>\n",
       "      <td>2019  Ecosport 1.5 Diesel Trend Plus BSIV</td>\n",
       "      <td>2019149858020192015202115800005801573617344410...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2019</td>\n",
       "      <td>₹5.80 Lakh</td>\n",
       "      <td>80,000 kms • Diesel • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2008 Maruti Alto 800 LXi BSIII</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2008  Alto 800 LXi BSIII</td>\n",
       "      <td>2008115200820052010113000800549053945253218857572</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2008</td>\n",
       "      <td>₹1.15 Lakh</td>\n",
       "      <td>1,13,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020 Kia Seltos HTK Plus D</td>\n",
       "      <td>Kia</td>\n",
       "      <td>2020  Seltos HTK Plus D</td>\n",
       "      <td>2020149311752020201920238000011759275523439701...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2020</td>\n",
       "      <td>₹11.75 Lakh</td>\n",
       "      <td>80,000 kms • Diesel • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023 Hyundai Venue SX</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2023  Venue SX</td>\n",
       "      <td>20231197920231800097835030342014440</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2023</td>\n",
       "      <td>₹9 Lakh</td>\n",
       "      <td>18,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018 Audi Q3 30 TDI Premium FWD</td>\n",
       "      <td>Audi</td>\n",
       "      <td>2018  Q3 30 TDI Premium FWD</td>\n",
       "      <td>2018319681350201832015202030730001350330816809...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2018</td>\n",
       "      <td>₹13.50 Lakh</td>\n",
       "      <td>73,000 kms • Diesel • Automatic • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021 Maruti Ertiga VXI</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2021  Ertiga VXI</td>\n",
       "      <td>202195020212015202210000000538591435867790144</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹9.50 Lakh</td>\n",
       "      <td>1,00,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014 Ford Ecosport 1.5 DV5 MT Titanium Optional</td>\n",
       "      <td>Ford</td>\n",
       "      <td>2014  Ecosport 1.5 DV5 MT Titanium Optional</td>\n",
       "      <td>201436020142013201515510000015589910847074799927</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2014</td>\n",
       "      <td>₹3.60 Lakh</td>\n",
       "      <td>1,00,000 kms • Diesel • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023 Maruti Swift VXI AMT</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2023  Swift VXI AMT</td>\n",
       "      <td>20236752023202120242000001580988956488849362973</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2023</td>\n",
       "      <td>₹6.75 Lakh</td>\n",
       "      <td>20,000 kms • Petrol • Automatic • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2008 Chevrolet OptraSRV 2.0 TCDi</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>2008  OptraSRV 2.0 TCDi</td>\n",
       "      <td>200835020082080000209560982493919344255749</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2008</td>\n",
       "      <td>₹3.50 Lakh</td>\n",
       "      <td>80,000 kms • Diesel • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023 Maruti Eeco 5 Seater AC BSVI</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2023  Eeco 5 Seater AC BSVI</td>\n",
       "      <td>2023540202352000053980416802578188045</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2023</td>\n",
       "      <td>₹5.40 Lakh</td>\n",
       "      <td>20,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019 MG Hector Sharp DCT</td>\n",
       "      <td>MG</td>\n",
       "      <td>2019  Hector Sharp DCT</td>\n",
       "      <td>201912201920192021400003537437583346878442</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2019</td>\n",
       "      <td>₹12 Lakh</td>\n",
       "      <td>40,000 kms • Petrol • Automatic • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2012 Maruti Ertiga VDI</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2012  Ertiga VDI</td>\n",
       "      <td>20124502012201220151250001484764544131177426</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2012</td>\n",
       "      <td>₹4.50 Lakh</td>\n",
       "      <td>1,25,000 kms • Diesel • Manual • 3rd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021 Toyota Glanza G</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>2021  Glanza G</td>\n",
       "      <td>2021550202120192022800009848324142554032348209</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹5.50 Lakh</td>\n",
       "      <td>80,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>117 Used Cars Under 5 Lakh in Indore</td>\n",
       "      <td>117</td>\n",
       "      <td>Used Cars Under 5 Lakh in Indore</td>\n",
       "      <td>1175535</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2014</td>\n",
       "      <td>₹3.11 Lakh</td>\n",
       "      <td>117 used cars Under 5 Lakh are available for s...</td>\n",
       "      <td>https://www.cardekho.com/used-cars+2-lakh-to-5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>34 Used Cars in Indore With Search Options</td>\n",
       "      <td>34</td>\n",
       "      <td>Used Cars in Indore With Search Options</td>\n",
       "      <td>020000</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2022</td>\n",
       "      <td>₹1 Lakh in Indore. The most popular used cars ...</td>\n",
       "      <td>000 km</td>\n",
       "      <td>https://www.cardekho.com/used-cars+0-20000-km+...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019 Hyundai i20 Petrol Asta</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2019  i20 Petrol Asta</td>\n",
       "      <td>2019201197550201920201720205400055020679176644...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2019</td>\n",
       "      <td>₹5.50 Lakh</td>\n",
       "      <td>54,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019 Hyundai Grand i10 1.2 Kappa Asta</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2019  Grand i10 1.2 Kappa Asta</td>\n",
       "      <td>2019101197525201910126000052510125988723498217...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2019</td>\n",
       "      <td>₹5.25 Lakh</td>\n",
       "      <td>60,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021 Volkswagen Taigun 1.0 Highline AT</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>2021  Taigun 1.0 Highline AT</td>\n",
       "      <td>2022999921202210170009211030438604108267112</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹9.21 Lakh</td>\n",
       "      <td>17,000 kms • Petrol • Automatic • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2024 Tata Nexon Pure</td>\n",
       "      <td>Tata</td>\n",
       "      <td>2024  Nexon Pure</td>\n",
       "      <td>20248902024350047771784808641444257</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2024</td>\n",
       "      <td>₹8.90 Lakh</td>\n",
       "      <td>3,500 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2012 Hyundai Santro Xing GL Plus</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2012  Santro Xing GL Plus</td>\n",
       "      <td>2012108617520125500017588754519636277111</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2012</td>\n",
       "      <td>₹1.75 Lakh</td>\n",
       "      <td>55,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023 MG Astor Smart MT</td>\n",
       "      <td>MG</td>\n",
       "      <td>2023  Astor Smart MT</td>\n",
       "      <td>2024149811752024860011757570330195468578593</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2023</td>\n",
       "      <td>₹11.75 Lakh with Less Driven</td>\n",
       "      <td>8,588 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2014 Hyundai Grand i10 Sportz</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2014  Grand i10 Sportz</td>\n",
       "      <td>2014101197325201410201320163500032510386558405...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2014</td>\n",
       "      <td>₹3.25 Lakh with GST Benefit</td>\n",
       "      <td>35,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2015 Maruti Swift Dzire ZXI</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2015  Swift Dzire ZXI</td>\n",
       "      <td>2016119747520162015201750000475544735779949914...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2015</td>\n",
       "      <td>₹4.75 Lakh</td>\n",
       "      <td>50,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018 Maruti Baleno 1.2 Delta</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2018  Baleno 1.2 Delta</td>\n",
       "      <td>2018119748520182015202212880004851224432493571...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2018</td>\n",
       "      <td>₹4.85 Lakh</td>\n",
       "      <td>88,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2025 Maruti Dzire VXI</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2025  Dzire VXI</td>\n",
       "      <td>202511977202025350007205824734082051133744</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2025</td>\n",
       "      <td>₹7.20 Lakh with Almost New</td>\n",
       "      <td>35,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2017 Hyundai Creta 1.4 CRDi S Plus</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2017  Creta 1.4 CRDi S Plus</td>\n",
       "      <td>2017139671120172015202014830007111448823735845...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2017</td>\n",
       "      <td>₹7.11 Lakh</td>\n",
       "      <td>83,000 kms • Diesel • Manual • 2nd Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2017 Honda Jazz 1.2 S AT i VTEC</td>\n",
       "      <td>Honda</td>\n",
       "      <td>2017  Jazz 1.2 S AT i VTEC</td>\n",
       "      <td>2017119952520172014202012690005251247873418791...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2017</td>\n",
       "      <td>₹5.25 Lakh with Discounted</td>\n",
       "      <td>69,000 kms • Petrol • Automatic • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2023 Hyundai i20 Asta</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2023  i20 Asta</td>\n",
       "      <td>2023201197795202320202020233720079520034757845...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2023</td>\n",
       "      <td>₹7.95 Lakh</td>\n",
       "      <td>37,202 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2021 Mahindra XUV500 W7</td>\n",
       "      <td>Mahindra</td>\n",
       "      <td>2021  XUV500 W7</td>\n",
       "      <td>202150011502021500760000500745533612468567312916</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹11.50 Lakh</td>\n",
       "      <td>60,000 kms • Diesel • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2021 Maruti Swift Dzire VXI BSVI</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>2021  Swift Dzire VXI BSVI</td>\n",
       "      <td>2021119767520212020202480000675748983704475788...</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2021</td>\n",
       "      <td>₹6.75 Lakh</td>\n",
       "      <td>80,000 kms • Petrol • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2012 Fiat Punto 1.3 Active</td>\n",
       "      <td>2012</td>\n",
       "      <td>Fiat Punto 1.3 Active</td>\n",
       "      <td>2012124817520121366000175133669272084222072259580</td>\n",
       "      <td>{\"@context\":\"https://schema.org\",\"@type\":\"WebP...</td>\n",
       "      <td>2012</td>\n",
       "      <td>₹1.75 Lakh with GST Benefit</td>\n",
       "      <td>66,000 kms • Diesel • Manual • 1st Owner</td>\n",
       "      <td>https://www.cardekho.com/used-car-details/used...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Car_name       brand  \\\n",
       "0                        2011 Hyundai i20 1.2 Magna     Hyundai   \n",
       "1                 2017 Maruti Alto K10 LXI Optional      Maruti   \n",
       "2                       2017 Maruti Swift Dzire LXI      Maruti   \n",
       "3               49 Used Cars Under 2 Lakh in Indore          49   \n",
       "4               36 Used Cars Under 3 Lakh in Indore          36   \n",
       "5              117 Used Cars Under 5 Lakh in Indore         117   \n",
       "6              153 Used Cars Under 8 Lakh in Indore         153   \n",
       "7              39 Used Cars Under 10 Lakh in Indore          39   \n",
       "8             110 Used Cars Above 10 Lakh in Indore         110   \n",
       "9     2019 Ford Ecosport 1.5 Diesel Trend Plus BSIV        Ford   \n",
       "10                   2008 Maruti Alto 800 LXi BSIII      Maruti   \n",
       "11                       2020 Kia Seltos HTK Plus D         Kia   \n",
       "12                            2023 Hyundai Venue SX     Hyundai   \n",
       "13                  2018 Audi Q3 30 TDI Premium FWD        Audi   \n",
       "14                           2021 Maruti Ertiga VXI      Maruti   \n",
       "15  2014 Ford Ecosport 1.5 DV5 MT Titanium Optional        Ford   \n",
       "16                        2023 Maruti Swift VXI AMT      Maruti   \n",
       "17                 2008 Chevrolet OptraSRV 2.0 TCDi   Chevrolet   \n",
       "18                2023 Maruti Eeco 5 Seater AC BSVI      Maruti   \n",
       "19                         2019 MG Hector Sharp DCT          MG   \n",
       "20                           2012 Maruti Ertiga VDI      Maruti   \n",
       "21                             2021 Toyota Glanza G      Toyota   \n",
       "22             117 Used Cars Under 5 Lakh in Indore         117   \n",
       "23       34 Used Cars in Indore With Search Options          34   \n",
       "24                     2019 Hyundai i20 Petrol Asta     Hyundai   \n",
       "25            2019 Hyundai Grand i10 1.2 Kappa Asta     Hyundai   \n",
       "26           2021 Volkswagen Taigun 1.0 Highline AT  Volkswagen   \n",
       "27                             2024 Tata Nexon Pure        Tata   \n",
       "28                 2012 Hyundai Santro Xing GL Plus     Hyundai   \n",
       "29                           2023 MG Astor Smart MT          MG   \n",
       "30                    2014 Hyundai Grand i10 Sportz     Hyundai   \n",
       "31                      2015 Maruti Swift Dzire ZXI      Maruti   \n",
       "32                     2018 Maruti Baleno 1.2 Delta      Maruti   \n",
       "33                            2025 Maruti Dzire VXI      Maruti   \n",
       "34               2017 Hyundai Creta 1.4 CRDi S Plus     Hyundai   \n",
       "35                  2017 Honda Jazz 1.2 S AT i VTEC       Honda   \n",
       "36                            2023 Hyundai i20 Asta     Hyundai   \n",
       "37                          2021 Mahindra XUV500 W7    Mahindra   \n",
       "38                 2021 Maruti Swift Dzire VXI BSVI      Maruti   \n",
       "39                       2012 Fiat Punto 1.3 Active        2012   \n",
       "\n",
       "                                          model  \\\n",
       "0                           2011  i20 1.2 Magna   \n",
       "1                   2017  Alto K10 LXI Optional   \n",
       "2                         2017  Swift Dzire LXI   \n",
       "3              Used Cars Under 2 Lakh in Indore   \n",
       "4              Used Cars Under 3 Lakh in Indore   \n",
       "5              Used Cars Under 5 Lakh in Indore   \n",
       "6              Used Cars Under 8 Lakh in Indore   \n",
       "7             Used Cars Under 10 Lakh in Indore   \n",
       "8             Used Cars Above 10 Lakh in Indore   \n",
       "9     2019  Ecosport 1.5 Diesel Trend Plus BSIV   \n",
       "10                     2008  Alto 800 LXi BSIII   \n",
       "11                      2020  Seltos HTK Plus D   \n",
       "12                               2023  Venue SX   \n",
       "13                  2018  Q3 30 TDI Premium FWD   \n",
       "14                             2021  Ertiga VXI   \n",
       "15  2014  Ecosport 1.5 DV5 MT Titanium Optional   \n",
       "16                          2023  Swift VXI AMT   \n",
       "17                      2008  OptraSRV 2.0 TCDi   \n",
       "18                  2023  Eeco 5 Seater AC BSVI   \n",
       "19                       2019  Hector Sharp DCT   \n",
       "20                             2012  Ertiga VDI   \n",
       "21                               2021  Glanza G   \n",
       "22             Used Cars Under 5 Lakh in Indore   \n",
       "23      Used Cars in Indore With Search Options   \n",
       "24                        2019  i20 Petrol Asta   \n",
       "25               2019  Grand i10 1.2 Kappa Asta   \n",
       "26                 2021  Taigun 1.0 Highline AT   \n",
       "27                             2024  Nexon Pure   \n",
       "28                    2012  Santro Xing GL Plus   \n",
       "29                         2023  Astor Smart MT   \n",
       "30                       2014  Grand i10 Sportz   \n",
       "31                        2015  Swift Dzire ZXI   \n",
       "32                       2018  Baleno 1.2 Delta   \n",
       "33                              2025  Dzire VXI   \n",
       "34                  2017  Creta 1.4 CRDi S Plus   \n",
       "35                   2017  Jazz 1.2 S AT i VTEC   \n",
       "36                               2023  i20 Asta   \n",
       "37                              2021  XUV500 W7   \n",
       "38                   2021  Swift Dzire VXI BSVI   \n",
       "39                        Fiat Punto 1.3 Active   \n",
       "\n",
       "                                           kms_driven  \\\n",
       "0   2011202201120201020121216000020121656856934769...   \n",
       "1   2017109983152017102014202032000315108101174559...   \n",
       "2   2017119753520172015201772000535958783760498116...   \n",
       "3                                              492202   \n",
       "4                                              363323   \n",
       "5                                             1175535   \n",
       "6                                             1538858   \n",
       "7                                           391010810   \n",
       "8                                          1101010105   \n",
       "9   2019149858020192015202115800005801573617344410...   \n",
       "10  2008115200820052010113000800549053945253218857572   \n",
       "11  2020149311752020201920238000011759275523439701...   \n",
       "12                20231197920231800097835030342014440   \n",
       "13  2018319681350201832015202030730001350330816809...   \n",
       "14      202195020212015202210000000538591435867790144   \n",
       "15   201436020142013201515510000015589910847074799927   \n",
       "16    20236752023202120242000001580988956488849362973   \n",
       "17         200835020082080000209560982493919344255749   \n",
       "18              2023540202352000053980416802578188045   \n",
       "19         201912201920192021400003537437583346878442   \n",
       "20       20124502012201220151250001484764544131177426   \n",
       "21     2021550202120192022800009848324142554032348209   \n",
       "22                                            1175535   \n",
       "23                                             020000   \n",
       "24  2019201197550201920201720205400055020679176644...   \n",
       "25  2019101197525201910126000052510125988723498217...   \n",
       "26        2022999921202210170009211030438604108267112   \n",
       "27                20248902024350047771784808641444257   \n",
       "28           2012108617520125500017588754519636277111   \n",
       "29        2024149811752024860011757570330195468578593   \n",
       "30  2014101197325201410201320163500032510386558405...   \n",
       "31  2016119747520162015201750000475544735779949914...   \n",
       "32  2018119748520182015202212880004851224432493571...   \n",
       "33         202511977202025350007205824734082051133744   \n",
       "34  2017139671120172015202014830007111448823735845...   \n",
       "35  2017119952520172014202012690005251247873418791...   \n",
       "36  2023201197795202320202020233720079520034757845...   \n",
       "37   202150011502021500760000500745533612468567312916   \n",
       "38  2021119767520212020202480000675748983704475788...   \n",
       "39  2012124817520121366000175133669272084222072259580   \n",
       "\n",
       "                                            fuel_type year_of_manufacture  \\\n",
       "0   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2011   \n",
       "1   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2017   \n",
       "2   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2017   \n",
       "3   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2012   \n",
       "4   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2012   \n",
       "5   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2014   \n",
       "6   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2015   \n",
       "7   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "8   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2018   \n",
       "9   {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2019   \n",
       "10  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2008   \n",
       "11  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2020   \n",
       "12  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2023   \n",
       "13  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2018   \n",
       "14  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "15  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2014   \n",
       "16  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2023   \n",
       "17  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2008   \n",
       "18  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2023   \n",
       "19  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2019   \n",
       "20  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2012   \n",
       "21  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "22  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2014   \n",
       "23  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2022   \n",
       "24  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2019   \n",
       "25  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2019   \n",
       "26  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "27  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2024   \n",
       "28  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2012   \n",
       "29  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2023   \n",
       "30  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2014   \n",
       "31  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2015   \n",
       "32  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2018   \n",
       "33  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2025   \n",
       "34  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2017   \n",
       "35  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2017   \n",
       "36  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2023   \n",
       "37  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "38  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2021   \n",
       "39  {\"@context\":\"https://schema.org\",\"@type\":\"WebP...                2012   \n",
       "\n",
       "                                                price  \\\n",
       "0                                             ₹2 Lakh   \n",
       "1                                          ₹3.15 Lakh   \n",
       "2                                          ₹5.35 Lakh   \n",
       "3                                          ₹1.70 Lakh   \n",
       "4                                          ₹2.85 Lakh   \n",
       "5                                          ₹3.11 Lakh   \n",
       "6                                          ₹5.50 Lakh   \n",
       "7                                          ₹8.51 Lakh   \n",
       "8                                            ₹11 Lakh   \n",
       "9                                          ₹5.80 Lakh   \n",
       "10                                         ₹1.15 Lakh   \n",
       "11                                        ₹11.75 Lakh   \n",
       "12                                            ₹9 Lakh   \n",
       "13                                        ₹13.50 Lakh   \n",
       "14                                         ₹9.50 Lakh   \n",
       "15                                         ₹3.60 Lakh   \n",
       "16                                         ₹6.75 Lakh   \n",
       "17                                         ₹3.50 Lakh   \n",
       "18                                         ₹5.40 Lakh   \n",
       "19                                           ₹12 Lakh   \n",
       "20                                         ₹4.50 Lakh   \n",
       "21                                         ₹5.50 Lakh   \n",
       "22                                         ₹3.11 Lakh   \n",
       "23  ₹1 Lakh in Indore. The most popular used cars ...   \n",
       "24                                         ₹5.50 Lakh   \n",
       "25                                         ₹5.25 Lakh   \n",
       "26                                         ₹9.21 Lakh   \n",
       "27                                         ₹8.90 Lakh   \n",
       "28                                         ₹1.75 Lakh   \n",
       "29                       ₹11.75 Lakh with Less Driven   \n",
       "30                        ₹3.25 Lakh with GST Benefit   \n",
       "31                                         ₹4.75 Lakh   \n",
       "32                                         ₹4.85 Lakh   \n",
       "33                         ₹7.20 Lakh with Almost New   \n",
       "34                                         ₹7.11 Lakh   \n",
       "35                         ₹5.25 Lakh with Discounted   \n",
       "36                                         ₹7.95 Lakh   \n",
       "37                                        ₹11.50 Lakh   \n",
       "38                                         ₹6.75 Lakh   \n",
       "39                        ₹1.75 Lakh with GST Benefit   \n",
       "\n",
       "                                              mileage  \\\n",
       "0          1,60,000 kms • Petrol • Manual • 1st Owner   \n",
       "1            32,000 kms • Petrol • Manual • 1st Owner   \n",
       "2            72,000 kms • Petrol • Manual • 1st Owner   \n",
       "3   49 used cars Under 2 Lakh are available for sa...   \n",
       "4   36 used cars Under 3 Lakh are available for sa...   \n",
       "5   117 used cars Under 5 Lakh are available for s...   \n",
       "6   153 used cars Under 8 Lakh are available for s...   \n",
       "7   39 used cars Under 10 Lakh are available for s...   \n",
       "8   110 used cars Above 10 Lakh are available for ...   \n",
       "9            80,000 kms • Diesel • Manual • 1st Owner   \n",
       "10         1,13,000 kms • Petrol • Manual • 1st Owner   \n",
       "11           80,000 kms • Diesel • Manual • 1st Owner   \n",
       "12           18,000 kms • Petrol • Manual • 1st Owner   \n",
       "13        73,000 kms • Diesel • Automatic • 1st Owner   \n",
       "14         1,00,000 kms • Petrol • Manual • 1st Owner   \n",
       "15         1,00,000 kms • Diesel • Manual • 1st Owner   \n",
       "16        20,000 kms • Petrol • Automatic • 1st Owner   \n",
       "17           80,000 kms • Diesel • Manual • 2nd Owner   \n",
       "18           20,000 kms • Petrol • Manual • 1st Owner   \n",
       "19        40,000 kms • Petrol • Automatic • 2nd Owner   \n",
       "20         1,25,000 kms • Diesel • Manual • 3rd Owner   \n",
       "21           80,000 kms • Petrol • Manual • 1st Owner   \n",
       "22  117 used cars Under 5 Lakh are available for s...   \n",
       "23                                             000 km   \n",
       "24           54,000 kms • Petrol • Manual • 1st Owner   \n",
       "25           60,000 kms • Petrol • Manual • 1st Owner   \n",
       "26        17,000 kms • Petrol • Automatic • 1st Owner   \n",
       "27            3,500 kms • Petrol • Manual • 1st Owner   \n",
       "28           55,000 kms • Petrol • Manual • 1st Owner   \n",
       "29            8,588 kms • Petrol • Manual • 1st Owner   \n",
       "30           35,000 kms • Petrol • Manual • 1st Owner   \n",
       "31           50,000 kms • Petrol • Manual • 1st Owner   \n",
       "32           88,000 kms • Petrol • Manual • 1st Owner   \n",
       "33           35,000 kms • Petrol • Manual • 1st Owner   \n",
       "34           83,000 kms • Diesel • Manual • 2nd Owner   \n",
       "35        69,000 kms • Petrol • Automatic • 1st Owner   \n",
       "36           37,202 kms • Petrol • Manual • 1st Owner   \n",
       "37           60,000 kms • Diesel • Manual • 1st Owner   \n",
       "38           80,000 kms • Petrol • Manual • 1st Owner   \n",
       "39           66,000 kms • Diesel • Manual • 1st Owner   \n",
       "\n",
       "                                          detail_page  page  \n",
       "0   https://www.cardekho.com/used-car-details/used...     1  \n",
       "1   https://www.cardekho.com/used-car-details/used...     1  \n",
       "2   https://www.cardekho.com/used-car-details/used...     1  \n",
       "3   https://www.cardekho.com/used-cars+0-lakh-to-2...     1  \n",
       "4   https://www.cardekho.com/used-cars+2-lakh-to-3...     1  \n",
       "5   https://www.cardekho.com/used-cars+3-lakh-to-5...     1  \n",
       "6   https://www.cardekho.com/used-cars+5-lakh-to-8...     1  \n",
       "7   https://www.cardekho.com/used-cars+8-lakh-to-1...     1  \n",
       "8   https://www.cardekho.com/used-cars+10-lakh-to-...     1  \n",
       "9   https://www.cardekho.com/used-car-details/used...     1  \n",
       "10  https://www.cardekho.com/used-car-details/used...     1  \n",
       "11  https://www.cardekho.com/used-car-details/used...     1  \n",
       "12  https://www.cardekho.com/used-car-details/used...     1  \n",
       "13  https://www.cardekho.com/used-car-details/used...     1  \n",
       "14  https://www.cardekho.com/used-car-details/used...     1  \n",
       "15  https://www.cardekho.com/used-car-details/used...     1  \n",
       "16  https://www.cardekho.com/used-car-details/used...     1  \n",
       "17  https://www.cardekho.com/used-car-details/used...     1  \n",
       "18  https://www.cardekho.com/used-car-details/used...     1  \n",
       "19  https://www.cardekho.com/used-car-details/used...     1  \n",
       "20  https://www.cardekho.com/used-car-details/used...     1  \n",
       "21  https://www.cardekho.com/used-car-details/used...     1  \n",
       "22  https://www.cardekho.com/used-cars+2-lakh-to-5...     1  \n",
       "23  https://www.cardekho.com/used-cars+0-20000-km+...     1  \n",
       "24  https://www.cardekho.com/used-car-details/used...     1  \n",
       "25  https://www.cardekho.com/used-car-details/used...     1  \n",
       "26  https://www.cardekho.com/used-car-details/used...     1  \n",
       "27  https://www.cardekho.com/used-car-details/used...     1  \n",
       "28  https://www.cardekho.com/used-car-details/used...     1  \n",
       "29  https://www.cardekho.com/used-car-details/used...     1  \n",
       "30  https://www.cardekho.com/used-car-details/used...     1  \n",
       "31  https://www.cardekho.com/used-car-details/used...     1  \n",
       "32  https://www.cardekho.com/used-car-details/used...     1  \n",
       "33  https://www.cardekho.com/used-car-details/used...     1  \n",
       "34  https://www.cardekho.com/used-car-details/used...     1  \n",
       "35  https://www.cardekho.com/used-car-details/used...     1  \n",
       "36  https://www.cardekho.com/used-car-details/used...     1  \n",
       "37  https://www.cardekho.com/used-car-details/used...     1  \n",
       "38  https://www.cardekho.com/used-car-details/used...     1  \n",
       "39  https://www.cardekho.com/used-car-details/used...     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Jupyter cell: Clean Selenium scraper (improved from your first working script) + mileage extraction\n",
    "# Produces: Car_name, brand, model, kms_driven, fuel_type, year_of_manufacture, price, mileage, detail_page\n",
    "# Saves to cardekho_used_cars_hyderabad_clean_fixed.csv and .xlsx\n",
    "# Requirements: selenium, webdriver-manager, beautifulsoup4, pandas, openpyxl\n",
    "\n",
    "import re, time, random, math\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# -------------- CONFIG --------------\n",
    "START_URL = \"https://www.cardekho.com/used-cars+in+indore\"\n",
    "OUTPUT_CSV = \"cardekho_used_cars_indore_clean_fixed.csv\"\n",
    "OUTPUT_XLSX = \"cardekho_used_cars_indore_clean_fixed.xlsx\"\n",
    "HEADLESS = True               # set False to see browser for debugging\n",
    "MAX_PAGES_OVERRIDE = None     # set an int to force more pages, else auto-detect\n",
    "MAX_SCROLL_ROUNDS = 60        # number of scroll attempts per page (increase to load more)\n",
    "SCROLL_PAUSE = 0.6            # seconds between scrolls\n",
    "PAGE_PAUSE = (0.8, 1.6)       # jitter after loading a page\n",
    "# Basic brand list to split brand/model (optional)\n",
    "BRANDS = [\"Maruti\",\"Hyundai\",\"Tata\",\"Honda\",\"Toyota\",\"Mahindra\",\"Kia\",\"BMW\",\"Audi\",\"Mercedes-Benz\",\n",
    "          \"Renault\",\"MG\",\"Skoda\",\"Volkswagen\",\"Ford\",\"Nissan\",\"Jeep\",\"Volvo\",\"Land Rover\",\"Jaguar\",\n",
    "          \"Isuzu\",\"Datsun\",\"Chevrolet\",\"Opel\"]\n",
    "# -------------------------------------\n",
    "\n",
    "# helpers\n",
    "def guess_brand_and_model(title):\n",
    "    if not title: return \"\", \"\"\n",
    "    for b in BRANDS:\n",
    "        if b.lower() in title.lower():\n",
    "            brand = b\n",
    "            model = re.sub(re.escape(b), \"\", title, flags=re.IGNORECASE).strip()\n",
    "            model = re.sub(r'^[\\-\\:\\–\\—\\s]+','', model)\n",
    "            if not model:\n",
    "                model = title\n",
    "            return brand, model\n",
    "    parts = title.split()\n",
    "    return (parts[0], \" \".join(parts[1:])) if parts else (\"\",\"\")\n",
    "\n",
    "def clean_kms(k):\n",
    "    if not k: return \"\"\n",
    "    return re.sub(r'[^\\d\\.]', '', str(k))\n",
    "\n",
    "def find_rupee(text):\n",
    "    m = re.search(r'₹\\s*[\\d\\.,\\sA-Za-z]+', text)\n",
    "    return m.group(0).strip() if m else \"\"\n",
    "\n",
    "def find_kms(text):\n",
    "    m = re.search(r'([\\d,\\.]+)\\s*(?:kms|km)\\b', text, flags=re.I)\n",
    "    return m.group(1).replace(\",\",\"\") if m else \"\"\n",
    "\n",
    "def find_fuel(text):\n",
    "    for f in [\"Petrol\",\"Diesel\",\"CNG\",\"LPG\",\"Electric\",\"Hybrid\"]:\n",
    "        if re.search(r'\\b' + re.escape(f) + r'\\b', text, flags=re.I):\n",
    "            return f\n",
    "    return \"\"\n",
    "\n",
    "def find_year(text):\n",
    "    m = re.search(r'\\b(19|20)\\d{2}\\b', text)\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    "# NEW: mileage extraction helper (looks for kmpl / km/kg / km/kWh / etc.)\n",
    "def extract_mileage(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    txt = text.replace(\"\\xa0\",\" \").strip()\n",
    "    # common patterns like \"18.5 kmpl\", \"22 km/kg\", \"120 km/kWh\"\n",
    "    m = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|km/kg|km/kwh|km/l|kpl|km)', txt, flags=re.I)\n",
    "    if m:\n",
    "        val = m.group(1)\n",
    "        unit = m.group(2)\n",
    "        return f\"{val} {unit}\".strip()\n",
    "    # sometimes \"Mileage: 18.5 kmpl\" or \"18.5kmpl\" or \"ARAI mileage 18 kmpl\"\n",
    "    m2 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|kpl|km/kg|km/kwh|km/l)\\b', txt, flags=re.I)\n",
    "    if m2:\n",
    "        return f\"{m2.group(1)} {m2.group(2)}\"\n",
    "    # also check \"Mileage - 18.5\" followed by unit nearby\n",
    "    m3 = re.search(r'Mileage[:\\-\\s]*([\\d]{1,3}(?:\\.\\d+)?)', txt, flags=re.I)\n",
    "    if m3:\n",
    "        # try to find unit near the number\n",
    "        after = txt[m3.end(): m3.end()+12]\n",
    "        u = re.search(r'(kmpl|kpl|km/kg|km/kwh|km/l)', after, flags=re.I)\n",
    "        if u:\n",
    "            return f\"{m3.group(1)} {u.group(1)}\"\n",
    "        return m3.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Setup Selenium\n",
    "opts = Options()\n",
    "if HEADLESS:\n",
    "    opts.add_argument(\"--headless=new\")\n",
    "opts.add_argument(\"--no-sandbox\")\n",
    "opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "opts.add_argument(\"--window-size=1920,1080\")\n",
    "opts.add_argument(\"--disable-gpu\")\n",
    "# avoid automation flags where possible (helps some sites)\n",
    "opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=opts)\n",
    "\n",
    "try:\n",
    "    driver.get(START_URL)\n",
    "    time.sleep(2.0)\n",
    "\n",
    "    # detect total listings/pages (best-effort)\n",
    "    soup0 = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    text0 = soup0.get_text(\" \", strip=True)\n",
    "    total_listings = None\n",
    "    m = re.search(r'([\\d,]{2,})\\s+Second Hand Cars in Indore', text0, flags=re.I)\n",
    "    if not m:\n",
    "        m = re.search(r'of\\s+([\\d,]+)\\s+results', text0, flags=re.I)\n",
    "    if m:\n",
    "        total_listings = int(m.group(1).replace(\",\", \"\"))\n",
    "    per_page_guess = max(1, len(soup0.find_all(\"h3\")))\n",
    "    estimated_pages = math.ceil(total_listings / per_page_guess) if total_listings else None\n",
    "    total_pages = int(estimated_pages) if estimated_pages else 200\n",
    "    if MAX_PAGES_OVERRIDE:\n",
    "        total_pages = MAX_PAGES_OVERRIDE\n",
    "    print(f\"Detected total_listings={total_listings}, per_page_guess={per_page_guess}, total_pages_to_try={total_pages}\")\n",
    "\n",
    "    # --- collect all listing card containers (and their detail links where present) ---\n",
    "    detail_links = []\n",
    "    cards_collected = []\n",
    "    seen_links = set()\n",
    "    seen_keys = set()  # dedupe by title+price\n",
    "\n",
    "    for p in range(1, total_pages + 1):\n",
    "        page_url = START_URL.rstrip(\"/\") + \"?page=\" + str(p)\n",
    "        try:\n",
    "            driver.get(page_url)\n",
    "        except Exception:\n",
    "            time.sleep(1.0)\n",
    "            driver.get(page_url)\n",
    "        # aggressively scroll to trigger lazy-load\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        scroll_round = 0\n",
    "        while scroll_round < MAX_SCROLL_ROUNDS:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(SCROLL_PAUSE + random.random()*0.3)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                # small wiggle to force load\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight-400);\")\n",
    "                time.sleep(0.4)\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(0.4)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "            last_height = new_height\n",
    "            scroll_round += 1\n",
    "\n",
    "        # parse page to find listing *cards*\n",
    "        page_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # Heuristic: cards often contain a title (h3), price (₹) and kms text.\n",
    "        # We'll find all h3/title nodes and then locate the nearest card container around them.\n",
    "        titles = page_soup.find_all(\"h3\")\n",
    "        for h in titles:\n",
    "            title = h.get_text(\" \", strip=True)\n",
    "            if not title:\n",
    "                continue\n",
    "\n",
    "            # climb up parents to find a card-like container (max 6 levels)\n",
    "            parent = h\n",
    "            container_text = \"\"\n",
    "            detail_href = \"\"\n",
    "            for _ in range(6):\n",
    "                if parent is None:\n",
    "                    break\n",
    "                # gather text\n",
    "                txt = parent.get_text(\" \", strip=True)\n",
    "                if \"₹\" in txt or re.search(r'\\b\\d+\\s*(?:kms|km)\\b', txt, flags=re.I):\n",
    "                    container_text = txt\n",
    "                    # also try to find detail link inside this parent container\n",
    "                    a = parent.find(\"a\", href=True)\n",
    "                    if a:\n",
    "                        href = a[\"href\"]\n",
    "                        abs_href = href if \"cardekho.com\" in href else urljoin(page_url, href)\n",
    "                        detail_href = abs_href.split(\"#\")[0].split(\"?utm\")[0]\n",
    "                    break\n",
    "                parent = parent.parent\n",
    "\n",
    "            # fallback: if no container_text found, use h.get_text plus parent.get_text\n",
    "            if not container_text:\n",
    "                parent = h.parent\n",
    "                container_text = parent.get_text(\" \", strip=True) if parent else h.get_text(\" \", strip=True)\n",
    "\n",
    "            # ensure it's likely a listing: should have price or kms or both\n",
    "            if (\"₹\" not in container_text) and (re.search(r'\\b\\d+\\s*(?:kms|km)\\b', container_text, flags=re.I) is None):\n",
    "                continue\n",
    "\n",
    "            price = find_rupee(container_text)\n",
    "            kms = find_kms(container_text)\n",
    "            fuel = find_fuel(container_text)\n",
    "            year = find_year(title) or find_year(container_text)\n",
    "            mileage = extract_mileage(container_text)  # <-- extract mileage from card text\n",
    "\n",
    "            brand, model = guess_brand_and_model(title)\n",
    "\n",
    "            # dedupe key\n",
    "            unique_key = (title + \"||\" + (price or \"\")).strip()\n",
    "            if unique_key in seen_keys:\n",
    "                continue\n",
    "            seen_keys.add(unique_key)\n",
    "\n",
    "            if detail_href and detail_href not in seen_links:\n",
    "                seen_links.add(detail_href)\n",
    "            # append raw row (text-based) including mileage\n",
    "            cards_collected.append({\n",
    "                \"Car_name\": title,\n",
    "                \"brand\": brand,\n",
    "                \"model\": model,\n",
    "                \"kms_driven\": kms.replace(\",\",\"\"),\n",
    "                \"fuel_type\": fuel,\n",
    "                \"year_of_manufacture\": year,\n",
    "                \"price\": price,\n",
    "                \"mileage\": mileage,\n",
    "                \"detail_page\": detail_href,\n",
    "                \"page\": p\n",
    "            })\n",
    "\n",
    "        # small pause\n",
    "        time.sleep(random.uniform(*PAGE_PAUSE))\n",
    "\n",
    "        # early stop if we've collected at least detected total_listings\n",
    "        if total_listings and len(seen_keys) >= total_listings:\n",
    "            print(\"Collected detected total_listings, stopping page scan.\")\n",
    "            break\n",
    "\n",
    "        # small progress print every 10 pages\n",
    "        if p % 10 == 0:\n",
    "            print(f\"Scanned page {p}; collected cards so far: {len(cards_collected)}\")\n",
    "\n",
    "    print(f\"Initial collection done: {len(cards_collected)} card rows, detail links discovered: {len(seen_links)}\")\n",
    "\n",
    "    # If detail links exist, visit each detail page to extract more reliable fields (optional but recommended)\n",
    "    # We'll visit only pages that either lack kms/fuel/year/price/mileage to improve data quality.\n",
    "    # This block is slower; set visit_details=False to skip.\n",
    "    visit_details = True\n",
    "    improved_rows = []\n",
    "    visited = 0\n",
    "\n",
    "    if visit_details and len(seen_links) > 0:\n",
    "        for idx, row in enumerate(cards_collected):\n",
    "            # decide whether to open detail page: if any of main fields missing or no detail link present\n",
    "            need_detail = False\n",
    "            if not row[\"kms_driven\"] or not row[\"fuel_type\"] or not row[\"price\"] or not row[\"year_of_manufacture\"] or not row.get(\"mileage\"):\n",
    "                need_detail = True\n",
    "            if row[\"detail_page\"]:\n",
    "                detail_url = row[\"detail_page\"]\n",
    "            else:\n",
    "                detail_url = None\n",
    "            if not need_detail and detail_url:\n",
    "                # keep as is\n",
    "                improved_rows.append(row)\n",
    "                continue\n",
    "\n",
    "            if detail_url:\n",
    "                try:\n",
    "                    # open detail page\n",
    "                    driver.get(detail_url)\n",
    "                    # wait short while\n",
    "                    time.sleep(1.0 + random.random()*0.8)\n",
    "                    dsoup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                    page_text = dsoup.get_text(\" \", strip=True)\n",
    "\n",
    "                    # Title from h1/h2 if present\n",
    "                    ttag = dsoup.find([\"h1\",\"h2\"])\n",
    "                    if ttag:\n",
    "                        title_det = ttag.get_text(\" \", strip=True)\n",
    "                        if title_det:\n",
    "                            row[\"Car_name\"] = title_det\n",
    "                            brand, model = guess_brand_and_model(title_det)\n",
    "                            row[\"brand\"] = brand\n",
    "                            row[\"model\"] = model\n",
    "\n",
    "                    # Try to find labeled values first (reliable)\n",
    "                    # Kms (look for label 'Kms Driven' or 'Kms')\n",
    "                    label_kms = dsoup.find(text=re.compile(r'Kms\\s*Driven|Kms|Odometer', flags=re.I))\n",
    "                    if label_kms:\n",
    "                        try:\n",
    "                            val = label_kms.parent.find_next_sibling()\n",
    "                            if val:\n",
    "                                k = re.sub(r'[^\\d]', '', val.get_text(\" \", strip=True))\n",
    "                                if k:\n",
    "                                    row[\"kms_driven\"] = k\n",
    "                        except:\n",
    "                            pass\n",
    "                    # fallback to page text\n",
    "                    if not row[\"kms_driven\"]:\n",
    "                        kf = find_kms(page_text)\n",
    "                        if kf:\n",
    "                            row[\"kms_driven\"] = kf\n",
    "\n",
    "                    # fuel type label\n",
    "                    label_fuel = dsoup.find(text=re.compile(r'Fuel\\s*Type|Fuel', flags=re.I))\n",
    "                    if label_fuel:\n",
    "                        try:\n",
    "                            val = label_fuel.parent.find_next_sibling()\n",
    "                            if val:\n",
    "                                row[\"fuel_type\"] = val.get_text(\" \", strip=True)\n",
    "                        except:\n",
    "                            pass\n",
    "                    if not row[\"fuel_type\"]:\n",
    "                        ff = find_fuel(page_text)\n",
    "                        if ff:\n",
    "                            row[\"fuel_type\"] = ff\n",
    "\n",
    "                    # year\n",
    "                    label_year = dsoup.find(text=re.compile(r'Year\\s*of\\s*Manufacture|Registration\\s*Year|Year', flags=re.I))\n",
    "                    if label_year:\n",
    "                        try:\n",
    "                            val = label_year.parent.find_next_sibling()\n",
    "                            if val:\n",
    "                                yy = find_year(val.get_text(\" \", strip=True))\n",
    "                                if yy:\n",
    "                                    row[\"year_of_manufacture\"] = yy\n",
    "                        except:\n",
    "                            pass\n",
    "                    if not row[\"year_of_manufacture\"]:\n",
    "                        yy = find_year(row[\"Car_name\"]) or find_year(page_text)\n",
    "                        if yy:\n",
    "                            row[\"year_of_manufacture\"] = yy\n",
    "\n",
    "                    # price\n",
    "                    pr = find_rupee(page_text)\n",
    "                    if pr:\n",
    "                        row[\"price\"] = pr\n",
    "\n",
    "                    # MILEAGE extraction on detail page: labeled field or meta-line or page-wide fallback\n",
    "                    mileage_val = \"\"\n",
    "                    # 1) labeled field 'Mileage' or 'Avg. Mileage'\n",
    "                    mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
    "                    if mnode:\n",
    "                        try:\n",
    "                            parent = mnode.parent\n",
    "                            sib = parent.find_next_sibling()\n",
    "                            if sib:\n",
    "                                mileage_val = sib.get_text(\" \", strip=True)\n",
    "                        except:\n",
    "                            mileage_val = \"\"\n",
    "                    # 2) try meta-line near title\n",
    "                    if not mileage_val and ttag:\n",
    "                        nxt = ttag.find_next()\n",
    "                        checks = 0\n",
    "                        while nxt and checks < 8:\n",
    "                            txt = nxt.get_text(\" \", strip=True)\n",
    "                            if txt and ((\"kms\" in txt.lower()) or re.search(r'\\b\\d+\\s*(?:kmpl|km/kg|km/kwh|km/l|kpl)\\b', txt, flags=re.I)):\n",
    "                                mileage_val = txt\n",
    "                                break\n",
    "                            nxt = nxt.find_next()\n",
    "                            checks += 1\n",
    "                    # 3) fallback to page_text extraction\n",
    "                    if not mileage_val:\n",
    "                        mileage_val = extract_mileage(page_text)\n",
    "\n",
    "                    # normalize mileage\n",
    "                    if mileage_val:\n",
    "                        row[\"mileage\"] = mileage_val\n",
    "\n",
    "                except Exception as e:\n",
    "                    # if detail fetch fails, keep earlier extracted values\n",
    "                    pass\n",
    "\n",
    "                # tiny sleep between detail visits\n",
    "                time.sleep(random.uniform(0.35, 0.9))\n",
    "            improved_rows.append(row)\n",
    "            visited += 1\n",
    "\n",
    "            # checkpoint: save every 200 detail pages processed\n",
    "            if visited % 200 == 0:\n",
    "                df_ck = pd.DataFrame(improved_rows)\n",
    "                df_ck = df_ck.drop_duplicates(subset=[\"detail_page\",\"Car_name\",\"price\"])\n",
    "                df_ck.to_csv(OUTPUT_CSV, index=False)\n",
    "                df_ck.to_excel(OUTPUT_XLSX, index=False)\n",
    "                print(f\"Checkpoint saved after {visited} detail visits: {len(df_ck)} rows.\")\n",
    "\n",
    "    else:\n",
    "        improved_rows = cards_collected\n",
    "\n",
    "    # Final cleaning + dedupe\n",
    "    df = pd.DataFrame(improved_rows)\n",
    "    # normalize strings and numeric kms\n",
    "    for c in [\"Car_name\",\"brand\",\"model\",\"fuel_type\",\"price\",\"detail_page\",\"mileage\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna(\"\").astype(str).str.strip()\n",
    "    df[\"kms_driven\"] = df[\"kms_driven\"].apply(lambda x: clean_kms(x) if x else \"\")\n",
    "    df[\"year_of_manufacture\"] = df[\"year_of_manufacture\"].apply(lambda x: find_year(str(x)) if x else \"\")\n",
    "\n",
    "    # dedupe by detail_page if present else by Car_name+price\n",
    "    if \"detail_page\" in df.columns and df[\"detail_page\"].str.len().sum() > 0:\n",
    "        df = df.drop_duplicates(subset=[\"detail_page\"]).reset_index(drop=True)\n",
    "    else:\n",
    "        df = df.drop_duplicates(subset=[\"Car_name\",\"price\"]).reset_index(drop=True)\n",
    "\n",
    "    # Save\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    df.to_excel(OUTPUT_XLSX, index=False)\n",
    "    print(f\"Saved cleaned output: {OUTPUT_CSV} and {OUTPUT_XLSX}\")\n",
    "    print(\"Total rows collected:\", len(df))\n",
    "    display(df.head(40))\n",
    "\n",
    "finally:\n",
    "    try:\n",
    "        driver.quit()\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8239fa0a-7875-4ac0-9aa3-2e44d0a8d120",
   "metadata": {},
   "source": [
    "4th Stage of Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04a08582-e871-4a4c-966b-7c061b31f6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 474 rows from cardekho_used_cars_indore_price_fixed.xlsx\n",
      "Rows flagged for repair: 1 (will visit detail pages)\n",
      "[1/1] Failed to load: nan\n",
      "Done. Updated 0 rows. Saved cleaned file to:\n",
      " - cardekho_used_cars_indore_price_fixed_cleaned.xlsx\n",
      " - cardekho_used_cars_indore_price_fixed_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Jupyter cell: Repair mileage & transmission for existing Cardekho file\n",
    "# - Loads /mnt/data/cardekho_used_cars_hyderabad_price_fixed.xlsx\n",
    "# - Visits detail_page for rows missing/invalid mileage or transmission\n",
    "# - Writes back cleaned file (CSV + XLSX)\n",
    "# Requirements: selenium, webdriver-manager, beautifulsoup4, pandas, openpyxl\n",
    "\n",
    "import re, time, random, os\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "INPUT_XLSX = \"cardekho_used_cars_indore_price_fixed.xlsx\"\n",
    "OUTPUT_XLSX = \"cardekho_used_cars_indore_price_fixed_cleaned.xlsx\"\n",
    "OUTPUT_CSV = \"cardekho_used_cars_indore_price_fixed_cleaned.csv\"\n",
    "\n",
    "HEADLESS = True                # set False to watch browser\n",
    "DELAY_BETWEEN = (0.6, 1.2)     # polite per-page pause\n",
    "CHECKPOINT_EVERY = 50          # save every N updated rows\n",
    "MAX_RETRIES = 1\n",
    "# --------------------------------\n",
    "\n",
    "if not os.path.exists(INPUT_XLSX):\n",
    "    raise FileNotFoundError(f\"Input file not found: {INPUT_XLSX}. Put your file at this path and re-run.\")\n",
    "\n",
    "# --- utility functions ---\n",
    "def text_of(elem):\n",
    "    return elem.get_text(\" \", strip=True) if elem else \"\"\n",
    "\n",
    "def normalize_mileage(raw):\n",
    "    if not raw:\n",
    "        return \"\"\n",
    "    s = str(raw).strip()\n",
    "    s = s.replace(\"\\xa0\",\" \").replace(\"\\n\",\" \").strip()\n",
    "    # try to capture number + unit (common)\n",
    "    m = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|kpl|km/kg|km/kwh|km/l|km|mpg)', s, flags=re.I)\n",
    "    if m:\n",
    "        val = m.group(1)\n",
    "        unit = m.group(2).lower()\n",
    "        # normalize unit names\n",
    "        unit = unit.replace(\"kpl\",\"kmpl\").replace(\"km/l\",\"kmpl\")\n",
    "        return f\"{val} {unit}\"\n",
    "    # tries like \"18.5\" then search for unit nearby\n",
    "    m2 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)', s)\n",
    "    if m2:\n",
    "        # if no unit, just return number\n",
    "        return m2.group(1)\n",
    "    return s\n",
    "\n",
    "def normalize_transmission(raw):\n",
    "    if not raw:\n",
    "        return \"\"\n",
    "    s = str(raw)\n",
    "    for t in [\"AMT\",\"CVT\",\"DCT\",\"AT\",\"MT\",\"Manual\",\"Automatic\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', s, flags=re.I):\n",
    "            # canonicalize\n",
    "            if t.upper() in (\"AMT\",\"CVT\",\"DCT\",\"AT\",\"MT\"):\n",
    "                return t.upper()\n",
    "            return t.title()\n",
    "    # last resort: find words\n",
    "    if re.search(r'\\bmanual\\b', s, flags=re.I):\n",
    "        return \"Manual\"\n",
    "    if re.search(r'\\bautomatic\\b', s, flags=re.I):\n",
    "        return \"Automatic\"\n",
    "    return s.strip()\n",
    "\n",
    "def extract_mileage_from_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # 1) direct patterns e.g. \"18.5 kmpl\"\n",
    "    m = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|kpl|km/kg|km/kwh|km/l|km|mpg)\\b', text, flags=re.I)\n",
    "    if m:\n",
    "        unit = m.group(2).lower().replace(\"kpl\",\"kmpl\").replace(\"km/l\",\"kmpl\")\n",
    "        return f\"{m.group(1)} {unit}\"\n",
    "    # 2) near 'mileage' keyword: capture window +/- 60 chars\n",
    "    for keyword in [\"mileage\",\"avg. mileage\",\"avg mileage\",\"city mileage\",\"claimed mileage\",\"average mileage\"]:\n",
    "        idx = text.lower().find(keyword)\n",
    "        if idx != -1:\n",
    "            start = max(0, idx-60)\n",
    "            end = min(len(text), idx+80)\n",
    "            ctx = text[start:end]\n",
    "            m2 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|kpl|km/kg|km/kwh|km/l|km|mpg)\\b', ctx, flags=re.I)\n",
    "            if m2:\n",
    "                unit = m2.group(2).lower().replace(\"kpl\",\"kmpl\").replace(\"km/l\",\"kmpl\")\n",
    "                return f\"{m2.group(1)} {unit}\"\n",
    "            # number only\n",
    "            m3 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)', ctx)\n",
    "            if m3:\n",
    "                return m3.group(1)\n",
    "    # 3) any number+unit elsewhere\n",
    "    m4 = re.search(r'([\\d]{1,3}(?:\\.\\d+)?)\\s*(kmpl|kpl|km/kg|km/kwh|km/l|km|mpg)\\b', text, flags=re.I)\n",
    "    if m4:\n",
    "        unit = m4.group(2).lower().replace(\"kpl\",\"kmpl\").replace(\"km/l\",\"kmpl\")\n",
    "        return f\"{m4.group(1)} {unit}\"\n",
    "    return \"\"\n",
    "\n",
    "def extract_trans_from_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # look for label/context words\n",
    "    for t in [\"Manual\",\"Automatic\",\"AMT\",\"CVT\",\"DCT\",\"AT\",\"MT\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', text, flags=re.I):\n",
    "            return normalize_transmission(t)\n",
    "    # also search near keywords 'transmission' or 'gearbox'\n",
    "    idx = text.lower().find(\"transmission\")\n",
    "    if idx == -1:\n",
    "        idx = text.lower().find(\"gearbox\")\n",
    "    if idx != -1:\n",
    "        start = max(0, idx-40)\n",
    "        end = min(len(text), idx+80)\n",
    "        ctx = text[start:end]\n",
    "        for t in [\"Manual\",\"Automatic\",\"AMT\",\"CVT\",\"DCT\",\"AT\",\"MT\"]:\n",
    "            if re.search(r'\\b' + re.escape(t) + r'\\b', ctx, flags=re.I):\n",
    "                return normalize_transmission(t)\n",
    "        # fallback to any word in ctx\n",
    "        m = re.search(r'\\b(Manual|Automatic|AMT|CVT|DCT|AT|MT)\\b', ctx, flags=re.I)\n",
    "        if m:\n",
    "            return normalize_transmission(m.group(1))\n",
    "    return \"\"\n",
    "\n",
    "# ----------------- load dataset -----------------\n",
    "df = pd.read_excel(INPUT_XLSX)\n",
    "print(f\"Loaded {len(df)} rows from {INPUT_XLSX}\")\n",
    "\n",
    "# identify rows that need fixing:\n",
    "# Criteria: mileage empty OR transmission empty OR mileage looks like URL/junk (contains 'http' or '/')\n",
    "def mileage_is_bad(val):\n",
    "    if not val or str(val).strip() == \"\":\n",
    "        return True\n",
    "    s = str(val).lower()\n",
    "    if \"http\" in s or \"/\" in s and len(s) > 10:   # simplistic junk heuristics\n",
    "        return True\n",
    "    # if it's non-numeric and non-unit, mark for check\n",
    "    if not re.search(r'\\d', s):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def transmission_is_bad(val):\n",
    "    if not val or str(val).strip() == \"\":\n",
    "        return True\n",
    "    s = str(val)\n",
    "    if re.search(r'http|\\/', s):\n",
    "        return True\n",
    "    # ok if contains known token\n",
    "    if re.search(r'\\b(Manual|Automatic|AMT|CVT|DCT|AT|MT)\\b', s, flags=re.I):\n",
    "        return False\n",
    "    return False  # conservative: if present assume ok\n",
    "\n",
    "# build list of indices to fix\n",
    "to_fix_idx = []\n",
    "for i, row in df.iterrows():\n",
    "    mismatch = False\n",
    "    if mileage_is_bad(row.get(\"mileage\", \"\")):\n",
    "        mismatch = True\n",
    "    if transmission_is_bad(row.get(\"transmission\", \"\")):\n",
    "        mismatch = True\n",
    "    # we will only attempt to fix those that have a valid detail_page URL\n",
    "    if mismatch and row.get(\"detail_page\"):\n",
    "        to_fix_idx.append(i)\n",
    "\n",
    "print(f\"Rows flagged for repair: {len(to_fix_idx)} (will visit detail pages)\")\n",
    "\n",
    "if len(to_fix_idx) == 0:\n",
    "    print(\"No rows need fixing. Exiting.\")\n",
    "else:\n",
    "    # Setup Selenium (headful or headless)\n",
    "    opts = Options()\n",
    "    if HEADLESS:\n",
    "        opts.add_argument(\"--headless=new\")\n",
    "    opts.add_argument(\"--no-sandbox\")\n",
    "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    opts.add_argument(\"--window-size=1200,900\")\n",
    "    opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)\n",
    "\n",
    "    updated = 0\n",
    "    try:\n",
    "        for batch_i, idx in enumerate(to_fix_idx, start=1):\n",
    "            row = df.loc[idx]\n",
    "            url = str(row.get(\"detail_page\")).strip()\n",
    "            if not url:\n",
    "                continue\n",
    "            # polite jitter\n",
    "            time.sleep(random.uniform(*DELAY_BETWEEN))\n",
    "            # fetch page\n",
    "            success = False\n",
    "            for attempt in range(MAX_RETRIES+1):\n",
    "                try:\n",
    "                    driver.get(url)\n",
    "                    # let JS run and content load\n",
    "                    time.sleep(1.0 + random.random()*0.8)\n",
    "                    page_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                    page_text = page_soup.get_text(\" \", strip=True)\n",
    "                    success = True\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    if attempt < MAX_RETRIES:\n",
    "                        time.sleep(0.6)\n",
    "                        continue\n",
    "                    else:\n",
    "                        success = False\n",
    "            if not success:\n",
    "                print(f\"[{batch_i}/{len(to_fix_idx)}] Failed to load: {url}\")\n",
    "                continue\n",
    "\n",
    "            # MULTIPLE extraction strategies, most-specific -> fallback\n",
    "            new_mileage = \"\"\n",
    "            new_trans = \"\"\n",
    "\n",
    "            # Strategy A: labeled dt/dd or table tr (common structure)\n",
    "            # dt/dd\n",
    "            try:\n",
    "                dts = page_soup.find_all(\"dt\")\n",
    "                if dts:\n",
    "                    for dt in dts:\n",
    "                        label = text_of(dt).lower()\n",
    "                        if \"mile\" in label:\n",
    "                            dd = dt.find_next_sibling(\"dd\")\n",
    "                            if dd:\n",
    "                                cand = text_of(dd)\n",
    "                                if cand:\n",
    "                                    new_mileage = extract_mileage_from_text(cand) or normalize_mileage(cand)\n",
    "                        if \"trans\" in label or \"gear\" in label:\n",
    "                            dd = dt.find_next_sibling(\"dd\")\n",
    "                            if dd:\n",
    "                                new_trans = extract_trans_from_text(text_of(dd)) or normalize_transmission(text_of(dd))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Strategy B: table rows <tr><th>Label</th><td>Value</td>\n",
    "            if not new_mileage or not new_trans:\n",
    "                try:\n",
    "                    for tr in page_soup.find_all(\"tr\"):\n",
    "                        th = tr.find([\"th\",\"td\"])\n",
    "                        tlabel = text_of(th).lower() if th else \"\"\n",
    "                        tvals = [text_of(x) for x in tr.find_all(\"td\")]\n",
    "                        tval = tvals[0] if tvals else \"\"\n",
    "                        if not new_mileage and (\"mileage\" in tlabel or \"avg\" in tlabel and \"mileage\" in tlabel):\n",
    "                            new_mileage = extract_mileage_from_text(tval) or normalize_mileage(tval)\n",
    "                        if not new_trans and (\"transmission\" in tlabel or \"gearbox\" in tlabel or \"gear\" in tlabel):\n",
    "                            new_trans = extract_trans_from_text(tval) or normalize_transmission(tval)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Strategy C: look for elements with class/id containing keywords\n",
    "            if not new_mileage:\n",
    "                try:\n",
    "                    mileage_nodes = page_soup.find_all(attrs={\"class\": re.compile(r\"mile|mileage|avg-mile|avgMileage\", flags=re.I)})\n",
    "                    for n in mileage_nodes:\n",
    "                        cand = text_of(n)\n",
    "                        cand_val = extract_mileage_from_text(cand) or normalize_mileage(cand)\n",
    "                        if cand_val:\n",
    "                            new_mileage = cand_val\n",
    "                            break\n",
    "                except Exception:\n",
    "                    pass\n",
    "            if not new_trans:\n",
    "                try:\n",
    "                    trans_nodes = page_soup.find_all(attrs={\"class\": re.compile(r\"trans|gear|gearbox\", flags=re.I)})\n",
    "                    for n in trans_nodes:\n",
    "                        cand = text_of(n)\n",
    "                        cand_val = extract_trans_from_text(cand) or normalize_transmission(cand)\n",
    "                        if cand_val:\n",
    "                            new_trans = cand_val\n",
    "                            break\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Strategy D: meta / data- attributes (rare)\n",
    "            if not new_mileage:\n",
    "                try:\n",
    "                    mtag = page_soup.find(\"meta\", attrs={\"name\": re.compile(r\"mileage\", flags=re.I)})\n",
    "                    if mtag and mtag.get(\"content\"):\n",
    "                        cand = mtag.get(\"content\")\n",
    "                        new_mileage = extract_mileage_from_text(cand) or normalize_mileage(cand)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Strategy E: near-title meta-line (many Cardekho detail pages show compact specs after title)\n",
    "            if not new_mileage or not new_trans:\n",
    "                try:\n",
    "                    htag = page_soup.find([\"h1\",\"h2\"])\n",
    "                    if htag:\n",
    "                        nxt = htag.find_next()\n",
    "                        checks = 0\n",
    "                        while nxt and checks < 10:\n",
    "                            txt = text_of(nxt)\n",
    "                            if txt and ((\"kms\" in txt.lower()) or (\"kmpl\" in txt.lower()) or (\"mileage\" in txt.lower()) or (\"transmission\" in txt.lower()) or (\"gear\" in txt.lower())):\n",
    "                                if not new_mileage:\n",
    "                                    new_mileage = extract_mileage_from_text(txt) or normalize_mileage(txt)\n",
    "                                if not new_trans:\n",
    "                                    new_trans = extract_trans_from_text(txt) or normalize_transmission(txt)\n",
    "                                break\n",
    "                            nxt = nxt.find_next()\n",
    "                            checks += 1\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Strategy F: page-wide regex fallback (last resort)\n",
    "            if not new_mileage:\n",
    "                new_mileage = extract_mileage_from_text(page_text)\n",
    "            if not new_trans:\n",
    "                new_trans = extract_trans_from_text(page_text)\n",
    "\n",
    "            # Final normalization\n",
    "            new_mileage = normalize_mileage(new_mileage)\n",
    "            new_trans = normalize_transmission(new_trans)\n",
    "\n",
    "            # If still empty, try card-level existing values as fallback (do not overwrite good existing)\n",
    "            existing_mileage = df.at[idx, \"mileage\"] if \"mileage\" in df.columns else \"\"\n",
    "            existing_trans = df.at[idx, \"transmission\"] if \"transmission\" in df.columns else \"\"\n",
    "            if not new_mileage and existing_mileage and not mileage_is_bad(existing_mileage):\n",
    "                new_mileage = existing_mileage\n",
    "            if not new_trans and existing_trans and existing_trans.strip():\n",
    "                new_trans = existing_trans\n",
    "\n",
    "            # write back if changed\n",
    "            changed = False\n",
    "            if new_mileage and (str(df.at[idx, \"mileage\"]) != new_mileage):\n",
    "                df.at[idx, \"mileage\"] = new_mileage\n",
    "                changed = True\n",
    "            if new_trans and (str(df.at[idx, \"transmission\"]) != new_trans):\n",
    "                df.at[idx, \"transmission\"] = new_trans\n",
    "                changed = True\n",
    "\n",
    "            if changed:\n",
    "                updated += 1\n",
    "                print(f\"[{batch_i}/{len(to_fix_idx)}] Updated idx={idx}: mileage='{new_mileage}' transmission='{new_trans}'\")\n",
    "            else:\n",
    "                print(f\"[{batch_i}/{len(to_fix_idx)}] No new data for idx={idx}\")\n",
    "\n",
    "            # checkpointing\n",
    "            if updated and updated % CHECKPOINT_EVERY == 0:\n",
    "                df.to_csv(OUTPUT_CSV, index=False)\n",
    "                df.to_excel(OUTPUT_XLSX, index=False)\n",
    "                print(f\"Checkpoint saved after {updated} updates.\")\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # final save\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    df.to_excel(OUTPUT_XLSX, index=False)\n",
    "    print(f\"Done. Updated {updated} rows. Saved cleaned file to:\\n - {OUTPUT_XLSX}\\n - {OUTPUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18e43ca-0cc9-4c36-91ac-213ca9b31908",
   "metadata": {},
   "source": [
    "5th stage of scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ecededb-6397-451f-972f-f925ecddeea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected total_listings=504, per_page_guess=66, total_pages=8\n",
      "Collected 491 card-level rows, detail links: 473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_20916\\15208835.py:461: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Temp\\ipykernel_20916\\15208835.py:476: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 detail pages...\n",
      "Processed 200 detail pages...\n",
      "Processed 300 detail pages...\n",
      "Processed 400 detail pages...\n",
      "Saved 474 rows to cardekho_used_cars_indore_price_fixed.csv and cardekho_used_cars_indore_price_fixed.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "cardekho_with_price_fix.py\n",
    "\n",
    "Improved scraper for CarDekho used cars (Hyderabad) with robust price extraction.\n",
    "Only mileage logic improved — rest unchanged.\n",
    "Requires: selenium, webdriver-manager, beautifulsoup4, pandas, openpyxl\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ---------------------------\n",
    "# Path to uploaded file (local). Use this path if you want to read the previously saved file.\n",
    "# Downstream systems can convert this local path into a downloadable URL if needed.\n",
    "UPLOADED_FILE_PATH = \"cardekho_used_cars_indore_price_fixed_cleaned.xlsx\"\n",
    "# ---------------------------\n",
    "\n",
    "# -------- CONFIG ----------\n",
    "START_URL = \"https://www.cardekho.com/used-cars+in+indore\"\n",
    "OUTPUT_CSV = \"cardekho_used_cars_indore_price_fixed.csv\"\n",
    "OUTPUT_XLSX = \"cardekho_used_cars_indore_price_fixed.xlsx\"\n",
    "\n",
    "HEADLESS = True\n",
    "MAX_PAGES_OVERRIDE = None\n",
    "MAX_SCROLLS = 40\n",
    "SCROLL_PAUSE = 0.7\n",
    "PAGE_PAUSE = (0.6, 1.4)\n",
    "VISIT_DETAIL_PAGES = True\n",
    "DETAIL_PAUSE = (0.6, 1.2)\n",
    "MAX_DETAIL_RETRIES = 1\n",
    "\n",
    "BRANDS = [\n",
    "    \"Maruti\", \"Hyundai\", \"Tata\", \"Honda\", \"Toyota\", \"Mahindra\", \"Kia\",\n",
    "    \"BMW\", \"Audi\", \"Mercedes-Benz\", \"Mercedes\", \"Renault\", \"MG\", \"Skoda\",\n",
    "    \"Volkswagen\", \"Ford\", \"Nissan\", \"Jeep\", \"Volvo\", \"Land Rover\", \"Jaguar\",\n",
    "    \"Isuzu\", \"Datsun\", \"Chevrolet\", \"Opel\"\n",
    "]\n",
    "# --------------------------\n",
    "\n",
    "def text_of(elem):\n",
    "    return elem.get_text(\" \", strip=True) if elem else \"\"\n",
    "\n",
    "def guess_brand_and_model(name):\n",
    "    if not name:\n",
    "        return \"\", \"\"\n",
    "    for b in BRANDS:\n",
    "        if b.lower() in name.lower():\n",
    "            model = re.sub(re.escape(b), \"\", name, flags=re.IGNORECASE).strip()\n",
    "            model = re.sub(r'^[\\-\\:\\–\\—\\s]+', '', model)\n",
    "            return b, model or name\n",
    "    parts = name.split()\n",
    "    return (parts[0], \" \".join(parts[1:]) if len(parts) > 1 else \"\") if parts else (\"\",\"\")\n",
    "\n",
    "def extract_kms(text):\n",
    "    m = re.search(r'([\\d,\\.]+)\\s*(?:kms|km)\\b', text, flags=re.I)\n",
    "    if m:\n",
    "        return m.group(1).replace(\",\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "def extract_fuel(text):\n",
    "    for f in [\"Petrol\", \"Diesel\", \"CNG\", \"LPG\", \"Electric\", \"Hybrid\"]:\n",
    "        if re.search(r'\\b' + re.escape(f) + r'\\b', text, flags=re.I):\n",
    "            return f\n",
    "    return \"\"\n",
    "\n",
    "# ----------------------\n",
    "# IMPROVED MILEAGE LOGIC\n",
    "# ----------------------\n",
    "\n",
    "# convert mpg to kmpl factor\n",
    "_MPG_TO_KMPL = 0.425144\n",
    "\n",
    "def _try_parse_number(s):\n",
    "    \"\"\"Return float or None for first numeric group found.\"\"\"\n",
    "    if not s:\n",
    "        return None\n",
    "    s2 = str(s).replace(\",\", \"\").replace(\"\\xa0\",\" \").strip()\n",
    "    m = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)', s2)\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return float(m.group(1))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_mileage(text):\n",
    "    \"\"\"\n",
    "    Robust mileage extraction that:\n",
    "     - prefers explicit units (kmpl, km/l, kpl)\n",
    "     - converts mpg -> kmpl\n",
    "     - ignores pure distance values like '120 km' (treat as invalid)\n",
    "     - returns standardized string like '18.5 kmpl' or '' if not found\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    s = str(text).replace(\"\\xa0\",\" \").strip()\n",
    "    low = s.lower()\n",
    "\n",
    "    # 1) explicit kmpl / km/l / kpl patterns\n",
    "    m = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)\\s*(km\\s*/\\s*l|kmpl|kpl|kmperlitre|km per litre)\\b', low, flags=re.I)\n",
    "    if m:\n",
    "        num = float(m.group(1))\n",
    "        # format number: remove .0 if integer else keep up to 2 decimals\n",
    "        num_fmt = int(num) if num.is_integer() else round(num, 2)\n",
    "        return f\"{num_fmt} kmpl\"\n",
    "\n",
    "    # 2) mpg -> convert to kmpl\n",
    "    m_mpg = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)\\s*mpg\\b', low, flags=re.I)\n",
    "    if m_mpg:\n",
    "        mpg = float(m_mpg.group(1))\n",
    "        kmpl = round(mpg * _MPG_TO_KMPL, 2)\n",
    "        kmpl_fmt = int(kmpl) if float(kmpl).is_integer() else kmpl\n",
    "        return f\"{kmpl_fmt} kmpl\"\n",
    "\n",
    "    # 3) patterns like \"18.5 kmpl\" without spaces or with units in mixed-case\n",
    "    m2 = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)\\s*(kmpl|kpl|km/l)\\b', low, flags=re.I)\n",
    "    if m2:\n",
    "        num = float(m2.group(1))\n",
    "        num_fmt = int(num) if num.is_integer() else round(num, 2)\n",
    "        return f\"{num_fmt} kmpl\"\n",
    "\n",
    "    # 4) look for 'mileage' keyword and numbers near it\n",
    "    for keyword in (\"mileage\", \"avg. mileage\", \"avg mileage\", \"claimed mileage\", \"claimed fuel economy\"):\n",
    "        idx = low.find(keyword)\n",
    "        if idx != -1:\n",
    "            window = low[max(0, idx-50): idx+80]\n",
    "            m3 = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)\\s*(kmpl|kpl|km/l|mpg)?', window, flags=re.I)\n",
    "            if m3:\n",
    "                num = float(m3.group(1))\n",
    "                unit = m3.group(2)\n",
    "                if unit and \"mpg\" in unit:\n",
    "                    kmpl = round(num * _MPG_TO_KMPL, 2)\n",
    "                    kmpl_fmt = int(kmpl) if float(kmpl).is_integer() else kmpl\n",
    "                    return f\"{kmpl_fmt} kmpl\"\n",
    "                # if unit absent, only accept if number plausible for kmpl\n",
    "                if not unit:\n",
    "                    if num <= 50:  # treat as kmpl\n",
    "                        num_fmt = int(num) if float(num).is_integer() else round(num, 2)\n",
    "                        return f\"{num_fmt} kmpl\"\n",
    "                else:\n",
    "                    # if unit is kmpl-like handled above; fallback\n",
    "                    num_fmt = int(num) if float(num).is_integer() else round(num, 2)\n",
    "                    return f\"{num_fmt} kmpl\"\n",
    "\n",
    "    # 5) generic number+unit elsewhere on page\n",
    "    m4 = re.search(r'([0-9]{1,3}(?:\\.[0-9]+)?)\\s*(kmpl|kpl|km/l|mpg)\\b', low, flags=re.I)\n",
    "    if m4:\n",
    "        val = float(m4.group(1))\n",
    "        unit = m4.group(2)\n",
    "        if 'mpg' in unit:\n",
    "            kmpl = round(val * _MPG_TO_KMPL, 2)\n",
    "            kmpl_fmt = int(kmpl) if float(kmpl).is_integer() else kmpl\n",
    "            return f\"{kmpl_fmt} kmpl\"\n",
    "        num_fmt = int(val) if val.is_integer() else round(val, 2)\n",
    "        return f\"{num_fmt} kmpl\"\n",
    "\n",
    "    # 6) numeric-only fallback: if page has a single small number (<50) assume kmpl\n",
    "    num = _try_parse_number(s)\n",
    "    if num is not None and num <= 50:\n",
    "        num_fmt = int(num) if float(num).is_integer() else round(num, 2)\n",
    "        return f\"{num_fmt} kmpl\"\n",
    "\n",
    "    # 7) otherwise likely a distance or invalid — return empty\n",
    "    return \"\"\n",
    "\n",
    "# helper used by the fallback detail extraction (kept unchanged)\n",
    "def extract_mileage_from_text(text):\n",
    "    # reuse improved extract_mileage\n",
    "    return extract_mileage(text)\n",
    "\n",
    "def extract_transmission(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    for t in [\"Manual\",\"Automatic\",\"CVT\",\"AMT\",\"DCT\",\"AT\",\"MT\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', text, flags=re.I):\n",
    "            if t.upper() in (\"AT\",\"AMT\",\"CVT\",\"DCT\",\"MT\"):\n",
    "                return t.upper()\n",
    "            return t.title()\n",
    "    return \"\"\n",
    "\n",
    "# ----------------------\n",
    "# existing other helpers unchanged\n",
    "# ----------------------\n",
    "\n",
    "def extract_price_from_soup(soup):\n",
    "    # 1. meta tags\n",
    "    meta_selectors = [\n",
    "        ('meta', {'property': 'og:price:amount'}),\n",
    "        ('meta', {'itemprop': 'price'}),\n",
    "        ('meta', {'name': 'price'}),\n",
    "    ]\n",
    "    for tag, attrs in meta_selectors:\n",
    "        mtag = soup.find(tag, attrs=attrs)\n",
    "        if mtag:\n",
    "            val = mtag.get('content') or mtag.get('value') or \"\"\n",
    "            if val:\n",
    "                if re.search(r'[\\d]', val) and '₹' not in val:\n",
    "                    return \"₹ \" + val.strip()\n",
    "                return val.strip()\n",
    "\n",
    "    # 2. attributes that often store price\n",
    "    for attr in ('data-price', 'data-offer-price', 'data-srp', 'data-amount', 'data-price-value'):\n",
    "        el = soup.find(attrs={attr: True})\n",
    "        if el:\n",
    "            val = el.get(attr)\n",
    "            if val:\n",
    "                if re.search(r'[\\d]', val) and '₹' not in val:\n",
    "                    return \"₹ \" + val.strip()\n",
    "                return val.strip()\n",
    "\n",
    "    # 3. elements with class or id containing 'price' or 'amount'\n",
    "    px = soup.find(lambda tag: tag.name in (\"div\",\"span\",\"p\",\"strong\") and (\n",
    "        tag.get(\"class\") or tag.get(\"id\")\n",
    "    ) and re.search(r'price|amount|selling|srp|finalPrice|carPrice|actual-price', \" \".join((tag.get(\"class\") or []) + [tag.get(\"id\") or \"\"]), flags=re.I))\n",
    "    if px:\n",
    "        txt = text_of(px)\n",
    "        pr = find_rupee_in_text(txt)\n",
    "        if pr:\n",
    "            return pr\n",
    "        if txt:\n",
    "            return txt.strip()\n",
    "\n",
    "    # 4. any visible text near top with rupee sign\n",
    "    top_region = \"\"\n",
    "    head_candidates = soup.find_all([\"header\", \"section\", \"div\"], limit=6)\n",
    "    for c in head_candidates:\n",
    "        t = text_of(c)\n",
    "        if '₹' in t:\n",
    "            top_region = t\n",
    "            break\n",
    "    if not top_region:\n",
    "        top_region = soup.get_text(\" \", strip=True)\n",
    "\n",
    "    pr = find_rupee_in_text(top_region)\n",
    "    if pr:\n",
    "        return pr\n",
    "\n",
    "    # 5. fallback regex on whole page (Lakh/Crore)\n",
    "    p2 = re.search(r'[\\d\\.,]+\\s*(?:Lakh|lakh|Lakhs|lakhs|Crore|crore|Cr)\\b', soup.get_text(\" \", strip=True))\n",
    "    if p2:\n",
    "        return p2.group(0).strip()\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def find_rupee_in_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    m = re.search(r'₹\\s*[\\d\\.,\\sA-Za-z]+', text)\n",
    "    if m:\n",
    "        return m.group(0).strip()\n",
    "    m2 = re.search(r'[\\d\\.,]+\\s*(Lakh|lakh|Lakhs|lakhs|Crore|crore|Cr)\\b', text)\n",
    "    if m2:\n",
    "        return m2.group(0).strip()\n",
    "    return \"\"\n",
    "\n",
    "def extract_price_from_text(text):\n",
    "    p = find_rupee_in_text(text)\n",
    "    return p\n",
    "\n",
    "def extract_year(text):\n",
    "    m = re.search(r'\\b(19|20)\\d{2}\\b', text)\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    "# ----------------------\n",
    "# main scraping flow (unchanged)\n",
    "# ----------------------\n",
    "\n",
    "def main():\n",
    "    chrome_opts = Options()\n",
    "    if HEADLESS:\n",
    "        chrome_opts.add_argument(\"--headless=new\")\n",
    "    chrome_opts.add_argument(\"--no-sandbox\")\n",
    "    chrome_opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_opts.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_opts)\n",
    "\n",
    "    try:\n",
    "        driver.get(START_URL)\n",
    "        time.sleep(2.0)\n",
    "        soup0 = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        text0 = soup0.get_text(\" \", strip=True)\n",
    "\n",
    "        total_listings = None\n",
    "        m = re.search(r'([\\d,]{2,})\\s+Second Hand Cars in Indore', text0, flags=re.I)\n",
    "        if not m:\n",
    "            m = re.search(r'of\\s+([\\d,]+)\\s+results', text0, flags=re.I)\n",
    "        if m:\n",
    "            total_listings = int(m.group(1).replace(\",\", \"\"))\n",
    "\n",
    "        per_page_guess = max(1, len(soup0.find_all(\"h3\")))\n",
    "        estimated_pages = math.ceil(total_listings / per_page_guess) if total_listings else None\n",
    "        total_pages = int(estimated_pages) if estimated_pages else 200\n",
    "        if MAX_PAGES_OVERRIDE:\n",
    "            total_pages = MAX_PAGES_OVERRIDE\n",
    "\n",
    "        print(f\"Detected total_listings={total_listings}, per_page_guess={per_page_guess}, total_pages={total_pages}\")\n",
    "\n",
    "        rows = []\n",
    "        seen_keys = set()\n",
    "        detail_links = []\n",
    "\n",
    "        for p in range(1, total_pages + 1):\n",
    "            page_url = START_URL.rstrip(\"/\") + \"?page=\" + str(p)\n",
    "            try:\n",
    "                driver.get(page_url)\n",
    "            except Exception:\n",
    "                time.sleep(1.0)\n",
    "                driver.get(page_url)\n",
    "\n",
    "            # scroll aggressively\n",
    "            last_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            sc = 0\n",
    "            while sc < MAX_SCROLLS:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(SCROLL_PAUSE)\n",
    "                new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_h == last_h:\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight-400);\")\n",
    "                    time.sleep(0.4)\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    time.sleep(0.4)\n",
    "                    new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                    if new_h == last_h:\n",
    "                        break\n",
    "                last_h = new_h\n",
    "                sc += 1\n",
    "\n",
    "            page_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            titles = page_soup.find_all(\"h3\")\n",
    "            for h in titles:\n",
    "                title = text_of(h)\n",
    "                if not title:\n",
    "                    continue\n",
    "\n",
    "                container = h\n",
    "                card_text = \"\"\n",
    "                link = \"\"\n",
    "                for _ in range(6):\n",
    "                    if container is None:\n",
    "                        break\n",
    "                    card_text = text_of(container)\n",
    "                    if \"₹\" in card_text or re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I):\n",
    "                        a = container.find(\"a\", href=True)\n",
    "                        if a:\n",
    "                            href = a[\"href\"]\n",
    "                            link = href if \"cardekho.com\" in href else urljoin(page_url, href)\n",
    "                            link = link.split(\"#\")[0].split(\"?utm\")[0]\n",
    "                        break\n",
    "                    container = container.parent\n",
    "\n",
    "                if not card_text:\n",
    "                    parent = h.parent\n",
    "                    card_text = text_of(parent) if parent else title\n",
    "\n",
    "                if (\"₹\" not in card_text) and (re.search(r'\\b\\d+\\s*(?:kms|km)\\b', card_text, flags=re.I) is None):\n",
    "                    continue\n",
    "\n",
    "                price_card = extract_price_from_text(card_text)\n",
    "                key = (title + \"||\" + (price_card or \"\")).strip()\n",
    "                if key in seen_keys:\n",
    "                    continue\n",
    "                seen_keys.add(key)\n",
    "\n",
    "                kms = extract_kms(card_text)\n",
    "                fuel = extract_fuel(card_text)\n",
    "                year = extract_year(title) or extract_year(card_text)\n",
    "                brand = \"\"\n",
    "                model = \"\"\n",
    "                try:\n",
    "                    brand, model = guess_brand_and_model(title)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                rows.append({\n",
    "                    \"Car_name\": title,\n",
    "                    \"brand\": brand,\n",
    "                    \"model\": model,\n",
    "                    \"kms_driven\": kms,\n",
    "                    \"mileage\": \"\",             # will be filled from detail page if available\n",
    "                    \"transmission\": \"\",\n",
    "                    \"fuel_type\": fuel,\n",
    "                    \"year_of_manufacture\": year,\n",
    "                    \"price\": price_card,\n",
    "                    \"detail_page\": link\n",
    "                })\n",
    "\n",
    "                if link:\n",
    "                    detail_links.append(link)\n",
    "\n",
    "            time.sleep(random.uniform(*PAGE_PAUSE))\n",
    "\n",
    "            if total_listings and len(seen_keys) >= total_listings:\n",
    "                print(\"Reached detected total listings; stopping page scan.\")\n",
    "                break\n",
    "\n",
    "            if p % 10 == 0:\n",
    "                print(f\"Scanned page {p}; rows so far: {len(rows)}\")\n",
    "\n",
    "        print(f\"Collected {len(rows)} card-level rows, detail links: {len(set(detail_links))}\")\n",
    "\n",
    "        # Now ensure price/mileage/transmission are filled: visit detail pages for any row missing price/mileage/trans\n",
    "        if VISIT_DETAIL_PAGES and detail_links:\n",
    "            unique_detail_links = []\n",
    "            seen_dl = set()\n",
    "            for u in detail_links:\n",
    "                if u and u not in seen_dl:\n",
    "                    seen_dl.add(u)\n",
    "                    unique_detail_links.append(u)\n",
    "\n",
    "            # map link -> price/mileage/transmission\n",
    "            detail_map = {}\n",
    "\n",
    "            for i, dl in enumerate(unique_detail_links):\n",
    "                # polite pause\n",
    "                if i > 0:\n",
    "                    time.sleep(random.uniform(*DETAIL_PAUSE))\n",
    "                attempt = 0\n",
    "                success = False\n",
    "                while attempt <= MAX_DETAIL_RETRIES and not success:\n",
    "                    try:\n",
    "                        driver.get(dl)\n",
    "                        time.sleep(1.0 + random.random()*0.8)\n",
    "                        dsoup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "                        # price from many possible places\n",
    "                        price_val = extract_price_from_soup(dsoup)\n",
    "                        if not price_val:\n",
    "                            price_val = extract_price_from_text(dsoup.get_text(\" \", strip=True))\n",
    "\n",
    "                        # mileage and transmission extraction now uses improved functions\n",
    "                        page_text = dsoup.get_text(\" \", strip=True)\n",
    "                        # try meta-line near title for quick values\n",
    "                        h_tag = dsoup.find([\"h1\",\"h2\"])\n",
    "                        meta_line = \"\"\n",
    "                        if h_tag:\n",
    "                            nxt = h_tag.find_next()\n",
    "                            checks = 0\n",
    "                            while nxt and checks < 8:\n",
    "                                t = text_of(nxt)\n",
    "                                if t and ((\"kms\" in t.lower()) or (\"₹\" in t) or re.search(r'\\b\\d+\\s*(?:kmpl|km/kg|km/kwh|km/l|kpl)\\b', t, flags=re.I)):\n",
    "                                    meta_line = t\n",
    "                                    break\n",
    "                                nxt = nxt.find_next()\n",
    "                                checks += 1\n",
    "\n",
    "                        # mileage: improved extraction\n",
    "                        mileage_val = \"\"\n",
    "                        mnode = dsoup.find(text=re.compile(r'\\bMileage\\b|\\bAvg\\.?\\s*Mileage\\b', flags=re.I))\n",
    "                        if mnode:\n",
    "                            try:\n",
    "                                parent = mnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    mileage_val = text_of(sib)\n",
    "                            except:\n",
    "                                mileage_val = \"\"\n",
    "                        if not mileage_val:\n",
    "                            # check meta_line then page_text using improved extract_mileage\n",
    "                            mileage_val = extract_mileage(meta_line or page_text) or extract_mileage(page_text)\n",
    "\n",
    "                        # transmission\n",
    "                        trans_val = \"\"\n",
    "                        tnode = dsoup.find(text=re.compile(r'\\bTransmission\\b|\\bGearbox\\b', flags=re.I))\n",
    "                        if tnode:\n",
    "                            try:\n",
    "                                parent = tnode.parent\n",
    "                                sib = parent.find_next_sibling()\n",
    "                                if sib:\n",
    "                                    trans_val = text_of(sib)\n",
    "                            except:\n",
    "                                trans_val = \"\"\n",
    "                        if not trans_val:\n",
    "                            trans_val = extract_transmission(meta_line or page_text)\n",
    "\n",
    "                        # normalize mileage into consistent 'X kmpl' format (handled by extract_mileage)\n",
    "                        mileage_clean = extract_mileage(mileage_val or \"\")\n",
    "                        detail_map[dl] = {\n",
    "                            \"price\": price_val or \"\",\n",
    "                            \"mileage\": mileage_clean or \"\",\n",
    "                            \"transmission\": trans_val or \"\"\n",
    "                        }\n",
    "                        success = True\n",
    "                    except Exception as e:\n",
    "                        attempt += 1\n",
    "                        if attempt > MAX_DETAIL_RETRIES:\n",
    "                            detail_map[dl] = {\"price\": \"\", \"mileage\": \"\", \"transmission\": \"\"}\n",
    "                            success = True\n",
    "                        else:\n",
    "                            time.sleep(0.8)\n",
    "\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print(f\"Processed {i+1} detail pages...\")\n",
    "\n",
    "            # merge into rows\n",
    "            for r in rows:\n",
    "                link = r.get(\"detail_page\", \"\")\n",
    "                if link and link in detail_map:\n",
    "                    if not r.get(\"price\"):\n",
    "                        r[\"price\"] = detail_map[link][\"price\"]\n",
    "                    # set mileage/transmission from detail\n",
    "                    if detail_map[link].get(\"mileage\"):\n",
    "                        r[\"mileage\"] = detail_map[link][\"mileage\"]\n",
    "                    if detail_map[link].get(\"transmission\"):\n",
    "                        r[\"transmission\"] = detail_map[link][\"transmission\"]\n",
    "\n",
    "        # final normalization\n",
    "        df = pd.DataFrame(rows, columns=[\n",
    "            \"Car_name\",\"brand\",\"model\",\"kms_driven\",\"mileage\",\"transmission\",\"fuel_type\",\"year_of_manufacture\",\"price\",\"detail_page\"\n",
    "        ])\n",
    "        df[\"kms_driven\"] = df[\"kms_driven\"].fillna(\"\").astype(str).apply(lambda x: re.sub(r'[^\\d\\.]', '', x))\n",
    "        df[\"mileage\"] = df[\"mileage\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"transmission\"] = df[\"transmission\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "        df[\"year_of_manufacture\"] = df[\"year_of_manufacture\"].fillna(\"\").astype(str).apply(lambda x: (re.search(r'\\b(19|20)\\d{2}\\b', x).group(0) if re.search(r'\\b(19|20)\\d{2}\\b', x) else \"\"))\n",
    "        df[\"price\"] = df[\"price\"].fillna(\"\").astype(str).apply(lambda x: x.strip())\n",
    "        df[\"fuel_type\"] = df[\"fuel_type\"].fillna(\"\").astype(str).apply(lambda x: x.strip().title())\n",
    "\n",
    "        # dedupe\n",
    "        if \"detail_page\" in df.columns and df[\"detail_page\"].str.len().sum() > 0:\n",
    "            df = df.drop_duplicates(subset=[\"detail_page\"]).reset_index(drop=True)\n",
    "        else:\n",
    "            df = df.drop_duplicates(subset=[\"Car_name\",\"price\"]).reset_index(drop=True)\n",
    "\n",
    "        # save\n",
    "        df.to_csv(OUTPUT_CSV, index=False)\n",
    "        df.to_excel(OUTPUT_XLSX, index=False)\n",
    "        print(f\"Saved {len(df)} rows to {OUTPUT_CSV} and {OUTPUT_XLSX}\")\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# helpers used in detail extraction (note: improved extract_mileage used above)\n",
    "def extract_mileage_fallback(text):\n",
    "    # kept for compatibility; call improved extractor\n",
    "    return extract_mileage(text)\n",
    "\n",
    "def extract_transmission(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    for t in [\"Manual\",\"Automatic\",\"CVT\",\"AMT\",\"DCT\",\"AT\",\"MT\"]:\n",
    "        if re.search(r'\\b' + re.escape(t) + r'\\b', text, flags=re.I):\n",
    "            if t.upper() in (\"AT\",\"AMT\",\"CVT\",\"DCT\",\"MT\"):\n",
    "                return t.upper()\n",
    "            return t.title()\n",
    "    return \"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe1f14e-587d-4801-99c5-b985bc5a157c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
